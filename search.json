[{"path":"/articles/FishSET_FunctionList.html","id":"reproducibility","dir":"Articles","previous_headings":"","what":"Reproducibility","title":"FishSET R package functions","text":"FishSET designed aim reproducibility. function calls logged dated file. Log files stored Logs folder. log call functionID list parameters supplies (args). logged functions includs kwargs, optional arguments, output, message. message section used save text output function call users may want reference later, number number rows missing data. example, function call returns following log entry: Log entries written JSON. Future version FishSET include function read log files rerun function calls current updated data. Logging built FishSET functions. However, possible start new log file using log_reset. New log files started day. User-created functions, likelihoods, can saved future use logged using log_func_model. ###Logging FishSET app, tab Notes sections saved Output folder. Comments, observations, thoughts typed user section saved dated text files. Additional pre-build messages also saved, output data evaluation functions. Finally, FishSET package includes Notebook template report writing.","code":"filter_table(dat = 'pcodmaindatatable', project = 'pcod', x = 'PERFORMANCE_Code', exp = 'PERFORMANCE_Code==1') {           \"functionID\": \"filter_table\",           \"args\": [             \"pcodMainDataTable\",             \"pcod\",             \"PERFORMANCE_Code\",             \"PERFORMANCE_Code==1\"           ],           \"kwargs\": [],           \"output\": \"\",           \"msg\": [             {               \"dataframe\": \"pcodMainDataTable\",               \"vector\": \"PERFORMANCE_Code\",               \"FilterFunction\": \"PERFORMANCE_Code==1\"             }           ]         } `log_reset` `log_func_model`"},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"FishSET GUI Quickstart Guide","text":"FishSET set statistical programming data management tools developed improve fishery modeling. tools standardize data management organization, enable use location choice models provide input fishery management, provide various modeling visualization tools. FishSET toolbox provided set R functions can run R console FishSET Graphical User Interface (FishSET GUI).","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"fishset-gui","dir":"Articles","previous_headings":"","what":"FishSET GUI","title":"FishSET GUI Quickstart Guide","text":"FishSET GUI user-friendly interface guides users steps necessary run discrete choice models. FishSET GUI requires knowledge coding R programming language steps prepare run discrete choice models can run graphical user interface apart writing report. See ***** details writing report. FishSET GUI divided tabs guide users steps creation, uploading exploring data developing evaluating models. Tabs can navigated order. data automatically saved SQL database called FishSET database first loaded. database housed projects directory withing FishSET R package directory. Modified versions data can saved FishSET database Data Quality Evaluation Compute New Variables tabs. Plots table outputs saved output folder within projects directory. Function calls, including chosen parameters, saved Logs folder within projects directory. Quickstart Guide subtab provides assistance using FishSET GUI. documents details use FishSET GUI. Details backgroud functions found FishSET Help Manual available FishSET WEBSITE. questions comments please contact: document walks steps : Installing R R Studio Installing loading FishSET package Opening FishSET GUI Using FishSET GUI Using Report template generate report.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"installing-r","dir":"Articles","previous_headings":"FishSET GUI","what":"Installing R","title":"FishSET GUI Quickstart Guide","text":"use FishSET GUI, users must first install R RStudio. R can installed >.RStudio . Installation files R RStudio platform specific. Install recent version R RStudio available. Default settings need changed . details see FishSET Help Manual.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"installing-the-fishset-package","dir":"Articles","previous_headings":"FishSET GUI","what":"Installing the FishSET package","title":"FishSET GUI Quickstart Guide","text":"FishSET provided compressed file can installed directly FishSET GitHUB site locally saved file location. recommend installing directly GitHUB site. details see FishSET Manual. Open RStudio Install devtools package (package necessary install build FishSET) RStudio Console paste following codeinstall.packages(\"devtools\")library(devtools) Install FishSET package install FishSET GitHUB RStudio Console paste following codedevtools::install_github(\"name/FishSET\")library(FishSET) install FishSET local file directorydevtools::install_local(\"PATH//Directory/Containing/FishSET\")library(FishSET) GITHUB SITE FILLED See FishSET Help Manual experience issues installing devtools FishSET packages.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"opening-the-fishset-gui","dir":"Articles","previous_headings":"FishSET GUI","what":"Opening the FishSET GUI","title":"FishSET GUI Quickstart Guide","text":"open FishSET GUI type paste following script RStudio console: run_fishset_gui()","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"using-the-fishset-gui","dir":"Articles","previous_headings":"FishSET GUI","what":"Using the FishSET GUI","title":"FishSET GUI Quickstart Guide","text":"FishSET GUI divided tabs. tabs ordered suggested order steps build run discrete choice model used specific order. Next detail purpose tab use tabs.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"functionality-available-across-all-tabs","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Functionality available across all tabs","title":"FishSET GUI Quickstart Guide","text":"Save plot table buttons Optional buttons save output user-specified location. Tables, plots, notes automatically saved Output folder projects directory generated. buttons used want save output location projects directory. Refresh data Resets primary data recently saved version FishSET database. refresh specific saved version data table, go Upload data tab. Unsaved changes data table lost data refreshed. Close app Closes FishSET GUI. preferred method close FishSET GUI. Notes Write observations, comments, notes Notes box. Press Save notes save notes Output folder. Running R expressions Located bottom land-hand panel. Enter run R code.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"information","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Information","title":"FishSET GUI Quickstart Guide","text":"Information tab four subtabs: Background * Details purpose FishSET. * Provides general information FishSET. Quickstart Guide * Brief detail use FishSET GUI tabs. Alaska Details * Information Alaskan fisheries. FishSET Background * Links partners.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"upload-data","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Upload Data","title":"FishSET GUI Quickstart Guide","text":"Upload Data tab used load data (primary, port, spatial, gridded, auxiliary) FishSET database local file directory. Data files types: Primary (Required) Contains main data model. Port (Required) Contains latitude longitude locations ports. Spatial (Required) Spatial data set defining boundaries fishing zones. Auxiliary (Optional) Contains additional data links primary data. Gridded (Optional) Contains additional data varies two dimensions. See FishSET Manual details different required optional data tables. Steps upload data: Select fill project name. primary, port, auxiliary, gridded data files select : Upload new file local file directory Browse file directory location. Load data FishSET database Choose table. spatial data files, option : Browse file directory location. load data, click Load Data button. Merge auxiliary data primary data: * Check Merge auxiliary table. * Select Main table keys Auxiliary table keys. column names merge two data tables . including confidentiality checks: * Click blue Confidentiality button. * Check Check confidentiality box. * Select vessel identifier column, select column name containing identifier unique observational units. * Select Rule (n: rule n k: majority allocation). * Select Threshold value 3 rule n 90% majority allocation. * Click Save repeat adding confidentiality rule. * Click Close button. See FishSET Manual details uploading data merging data.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"data-quality-evaluation","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Data Quality Evaluation","title":"FishSET GUI Quickstart Guide","text":"Data Quality Evaluation tab used identify correct common data quality issues erroneous outliers missing values. Variable class Check change variable classes. Classes numeric, character, factor, date. Summary table View minimum, median, mean, maximum, . missing, . unique observations, . 0s. Outliers View tables plots assess outliers exist. Choose variable assess. Select Method subset data : none 5_95_quant (remove values outside 5th 95th quantiles) 25_75_quant (remove values outside 25th 75th quantiles) mean_2SD (remove values outside 2 standard deviations mean) mean_3SD (remove values outside 3 standard deviations mean) median_2SD (remove values outside 2 standard deviations median) median_3SD (remove values outside 3 standard deviations median) Select Distribution data: Normal Lognormal Exponential Weibull Poisson Negative binomial NAs Displays table variables containing missing values. Remove replace NAs: Remove NAs removes entire row data containing NAs. Replace NAs mean values replaces NAs. NaNs Displays table variables containing non-numbers. Remove replace NaNs: Remove NaNs removes entire row data containing NaNs. Replace NaNs mean values replaces NaNs. Unique observations Checks rows dataset unique. remove non-unique rows, select Remove non-unique rows. Empty variables Returns list variables empty. remove, press Remove empty variables. Latitude Longitude units Returns first six rows latitude longitude variables. Checks whether values decimal degree sign correct. Select variable action make corrections. See Recommended data quality check steps Cleaning Data Quality section FishSET manual details.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"data-exploration","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Data Exploration","title":"FishSET GUI Quickstart Guide","text":"Data Exploration tab used view explore loaded data. Select view data tables plots. Tables Select data file type view. Edit cells: Double click cell edit. Filter table: Add apply filters boxes column names first row data. Remove variables: Click anywhere column highlight column. Multiple columns can selected time. Press Remove data dataset remove variables dataset. Changes applied saved Save FishSET database button pressed. Plots Temporal Displays three plots selected variable. first data variable data set used x-axis. Spatial Two plots shown. first can zoomed . Individual points can identified hovering . Fill additional options left-hand panel show Getis-Ord Moran’s statistics. NOTE: spatial check must completed can run models. x-y Plot selected x variable selected y variable. details see Data Exploreation section FishSET Manual.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"fleet-assignment-and-summary","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Fleet Assignment and Summary","title":"FishSET GUI Quickstart Guide","text":"Fleet Assignment Summary tab used define fleets explore data fleet level. two subtabs, fleet assignment fleet summary.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"fleet-assignment","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI > Fleet Assignment and Summary","what":"Fleet assignment","title":"FishSET GUI Quickstart Guide","text":"Define fleets apply fleet definitions primary dataset. Select task (left-hand panel), select Define Fleets. Expression Builder Select variable, operator, value create expression. Select Add expression expand expression needed. Select Insert expression insert expression Fleet Definition Table. Fleet Definition Table insert specific cell, click Select cell, choose cell, select Insert expression. enter fleet name, double-click definition table. create new expression, click Reset expression. edit definition table, double-click cell. Press Ctrl+Enter save changes. Click Save table FishSET database button save table. Select Fleet Assignment Select task (left-hand panel). Load fleet definition table. * Select available fleet tables. tables shown desired table shown, press Refresh saved tables. * Press Load table table now main panel. Repeat previous steps loaded table desired table. Press Assign fleets button assign vessels defined fleets.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"fleet-summary","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI > Fleet Assignment and Summary","what":"Fleet Summary","title":"FishSET GUI Quickstart Guide","text":"Functions: Vessel count View number vessels fleet /group. Species catch Aggregate species catch time period. Rolling catch Rolling catch (specify window size summary statistic). Weekly catch View catch variable summarized weeks. Weekly effort View mean weekly catch per unit effort. Bycatch Compare average CPUE catch total/share total catch one species. Trip length View trip duration. Density plot View density plot. Plotting options: View table /plot. Subset Subset date. Subset variable. Group Select grouping variable time period. Split Select variable time period split plot . Plot options Change format, adjust axes, etc. Adjust table (wide <-> long). Populate additional function-specific options. Click Run function button run function display output. details see Fleet group summaries section Exploratory data analysis chapter FishSET Manual.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"simple-analyses","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Simple Analyses","title":"FishSET GUI Quickstart Guide","text":"Simple Analyses tab used view correlation simple linear regression among selected variables. Select show correlations simple linear regression. Option left-hand panel. Correlations Select variables include correlation test. remove variable, click press Delete Backspace. add variables back , click empty space click desired variable. Table shows correlation values. Correlation matrix plot: Color strength represents strength correlation. Red positively correlated. Blue negatively correlated. Linear regression Select response variable. Select explanatory variable.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"compute-new-variables","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Compute New Variables","title":"FishSET GUI Quickstart Guide","text":"Compute New Variables tab used transform derive new variables. Steps: Select Create variables based desired broad categories. Select function. Populate options. Press Run Function button. new variable added end table. Save finalized dataset moving modeling functions. save FishSET database, click Save final table FishSET DB. save local file directory, select file format Export data : box click Download data. Function details can found Exploratory Data Analysis section FishSET Manual. Functions: Arithmetic Numeric functions (add, subtract, multiply, divide two variables) Catch per unit Data transformations Within-group percentage Within-group lagged difference Within-group running sum Coded variable based quartiles Dummy variable policy dates area/zone closures Nominal ID Create distinct haul trip ID Create fishery season identifier Spatial Assign observations zones Distance two points Midpoint location (lon/lat) haul Zone choice go next made Temporal Change time unit (convert extract) Duration time two temporal variables Trip-level Collapse data haul-level trip-level Calculate trip distance Calculate trip centroid","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"map-viewer","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Map Viewer","title":"FishSET GUI Quickstart Guide","text":"Map Viewer tab used view spatial distribution hauls. Required: Spatial data file. Zone identifier variable primary dataset. Choices: Area variable (data) Variable primary data containing zone identifier ZoneID. Area variable (map) Name property spatial data file identifies zones. Links Area variable (data) . Numeric variables (required) Points map color coded based numeric variable value. Multiple numeric variables can included one plotted time . Temporal variables (required) Used scatter plot. Temporal variable plotted numeric variable. Multiple temporal variables can included one plotted time . ID variables (recommended) Categorical variables grouping plots. Multiple ID variables can included one plotted time . Location point path map show hauls individual points paths? Points Longitude point Latitude point Path Starting longitude Starting latitude Ending longitude Ending latitude","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"define-alternative-fishing-choices","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Define Alternative Fishing Choices","title":"FishSET GUI Quickstart Guide","text":"Define Alternative Fishing Choices tab used define distance matrix observed fishing locations alternative fishing locations calculated. Steps: distance matrix come : Primary haul- trip-level data Gridded data file. data comes primary dataset: Define alternative fishing choices calculated : occurrence alternative locations. Select distance units. Select minimum number hauls required zone included. Press Save choices. data comes gridded data file: Load data See Data section Model Development chapter FishSET Manual details.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"expected-catchrevenue","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Expected Catch/Revenue","title":"FishSET GUI Quickstart Guide","text":"Expected Catch/Revenue tab used calculate expected catch revenue matrix alternative fishing zones (zones fishing happened ). catch variable required. Include price value variable want expected revenue. Steps: Select catch variable. Select price value variable calculating expected revenue. Price multiplied catch produce revenue. revenue variable exists dataset, can used Catch Variable. matrix required run conditional logit model . Decide whether account potential catch differs groups. Select Fleet (group) column name containing group identifier. Decide whether temporal patterns catch taken account. taking temporal patterns account select: Temporal variable Time lags Window averaging Populate options Decide hand empty expected catch values. Press Run expected catch/revenue function. Four expected catch expected revenue matrices generated saved FishSET database based predefined window size lags days years user-defined arguments: Selected temporal arguments. Expected catch/revenue based previous two days (short-term) catch. Expected catch/revenue based previous seven days (medium-term) catch. Expected catch/revenue based previous years (long-term) catch. See Data section Model Development chapter FishSET Manual details.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"models","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Models","title":"FishSET GUI Quickstart Guide","text":"Models tab used define model parameters, run models, compare output. Steps: Select likelihood function. Select optimization method. Select variables include model. Select optimization methods. Select initial parameter values. Initial parameter values can defined come parameter values previous model. number required parameter values auto populate. See function documentation order parameters. Parameter starting values within bounds variable data. Press Save model add new model. model appear table. models defined, repeat steps specified. Models can removed using table. done specifying models, press Run model(s). models may take several minutes run. models completed, tables Compare models subtab populated. Use tables assess convergence, fit, select preferred model future analyses . See Model Development section FishSET manual details model choices, including likelihood functions, optimization method, initial parameter estimates.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"bookmark-choices","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI","what":"Bookmark Choices","title":"FishSET GUI Quickstart Guide","text":"Bookmark Choices tabs used store choices actions made FishSET GUI enable choices actions reloaded later date.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"bookmark-subtab","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI > Bookmark Choices","what":"Bookmark subtab","title":"FishSET GUI Quickstart Guide","text":"Restore selections made FishSET GUI. Data reloaded. Got Upload Data tab load data. Previous actions, deriving variables, rerun .","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"rerun-logged-function-subtab","dir":"Articles","previous_headings":"FishSET GUI > Using the FishSET GUI > Bookmark Choices","what":"Rerun logged function subtab","title":"FishSET GUI Quickstart Guide","text":"Rerun previous actions, including loading data, data corrections, modifying deriving variables.","code":""},{"path":"/articles/FishSET_GUI_Quickstart_Guide.html","id":"generating-reports","dir":"Articles","previous_headings":"FishSET GUI","what":"Generating reports","title":"FishSET GUI Quickstart Guide","text":"FishSET includes report template guides users process writing reproducible report inserting output FishSET GUI report. report written FishSET GUI. must opened R console. Steps: Open RStudio Locate report template file location. RStudio Console paste system.file('rmd', 'report_template.Rmd', package='FishSET') Open template Press Ctrl+O RStudio click File -> Open File. Browse file click Open. Resave report template * Click File. Select Save .... Provide informative project-specific name. Begin writing template provides guidance format build (knit) document. Example functions insert figures, tables, notes provided. Details using report template Reporting chapter FishSET Manual.","code":""},{"path":"/articles/scallop-example.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Scallop Example","text":"vignette example exploratory data analysis using FishSET. utilizes range FishSET functions importing upload data, performing quality assessment/quality control, summarizing visualizing data.","code":""},{"path":"/articles/scallop-example.html","id":"packages","dir":"Articles","previous_headings":"","what":"Packages","title":"Scallop Example","text":"","code":"library(FishSET) #> The legacy packages maptools, rgdal, and rgeos, underpinning the sp package, #> which was just loaded, will retire in October 2023. #> Please refer to R-spatial evolution reports for details, especially #> https://r-spatial.org/r/2023/05/15/evolution4.html. #> It may be desirable to make the sf package available; #> package maintainers should consider adding sf to Suggests:. #> The sp package is now running under evolution status 2 #>      (status 2 uses the sf package in place of rgdal) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following object is masked from 'package:FishSET': #>  #>     select_vars #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(tidyr) library(ggplot2) #> Warning: package 'ggplot2' was built under R version 4.3.2 library(maps)"},{"path":"/articles/scallop-example.html","id":"project-setup","dir":"Articles","previous_headings":"","what":"Project Setup","title":"Scallop Example","text":"chunk defines location FishSET Folder. temporary directory used vignette example; actual use, set folderpath location temporary.","code":"folderpath <- tempdir()  proj <- \"scallop\""},{"path":"/articles/scallop-example.html","id":"data-import","dir":"Articles","previous_headings":"","what":"Data Import","title":"Scallop Example","text":"Upload northeast scallop data FishSET package.  data contains 10000 rows 20 variables.  View upload ten minute squares map wind turbine closure areas FishSET package.    Assign regulatory zones (scallopTenMNSQRSpatTable) closure areas (scallopWindCloseSpatTable) working environment.","code":"load_maindata(dat = FishSET::scallop, project = proj) #> Table saved to database #>  #> ! Data saved to database as scallopMainDataTable20240528 (raw) and scallopMainDataTable (working).  #> Table is also in the working environment. ! plot_spat(FishSET::tenMNSQR) plot_spat(FishSET::windLease) load_spatial(spat = FishSET::tenMNSQR, project = proj, name = \"TenMNSQR\") #> Writing layer `scallopTenMNSQRSpatTable' to data source  #>   `C:\\Users\\pcarvalho\\AppData\\Local\\Temp\\RtmpekJ7VO/scallop/data/spat/scallopTenMNSQRSpatTable.geojson' using driver `GeoJSON' #> Writing 5267 features with 9 fields and geometry type Polygon. #> Writing layer `scallopTenMNSQRSpatTable20240528' to data source  #>   `C:\\Users\\pcarvalho\\AppData\\Local\\Temp\\RtmpekJ7VO/scallop/data/spat/scallopTenMNSQRSpatTable20240528.geojson' using driver `GeoJSON' #> Writing 5267 features with 9 fields and geometry type Polygon. #> Spatial table saved to project folder as scallopTenMNSQRSpatTable  load_spatial(spat = FishSET::windLease, project = proj, name = \"WindClose\") #> Writing layer `scallopWindCloseSpatTable' to data source  #>   `C:\\Users\\pcarvalho\\AppData\\Local\\Temp\\RtmpekJ7VO/scallop/data/spat/scallopWindCloseSpatTable.geojson' using driver `GeoJSON' #> Writing 32 features with 1 fields and geometry type Multi Polygon. #> Writing layer `scallopWindCloseSpatTable20240528' to data source  #>   `C:\\Users\\pcarvalho\\AppData\\Local\\Temp\\RtmpekJ7VO/scallop/data/spat/scallopWindCloseSpatTable20240528.geojson' using driver `GeoJSON' #> Writing 32 features with 1 fields and geometry type Multi Polygon. #> Spatial table saved to project folder as scallopWindCloseSpatTable scallopTenMNSQRSpatTable <- table_view(\"scallopTenMNSQRSpatTable\", proj) #> Reading layer `scallopTenMNSQRSpatTable' from data source  #>   `C:\\Users\\pcarvalho\\AppData\\Local\\Temp\\RtmpekJ7VO\\scallop\\data\\spat\\scallopTenMNSQRSpatTable.geojson'  #>   using driver `GeoJSON' #> Simple feature collection with 5267 features and 9 fields #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: -77 ymin: 33 xmax: -64 ymax: 46.00139 #> Geodetic CRS:  NAD83 scallopWindCloseSpatTable <- table_view(\"scallopWindCloseSpatTable\", proj) #> Reading layer `scallopWindCloseSpatTable' from data source  #>   `C:\\Users\\pcarvalho\\AppData\\Local\\Temp\\RtmpekJ7VO\\scallop\\data\\spat\\scallopWindCloseSpatTable.geojson'  #>   using driver `GeoJSON' #> Simple feature collection with 32 features and 1 field #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: -75.90347 ymin: 36.14111 xmax: -70.02155 ymax: 41.71859 #> Geodetic CRS:  WGS 84"},{"path":"/articles/scallop-example.html","id":"fleet-assignment","dir":"Articles","previous_headings":"Data Import","what":"Fleet assignment","title":"Scallop Example","text":"Assign observations either “Access Area” “Days Sea” fleets.","code":"fleet_tab <-    data.frame(     condition = c('`Plan Code` == \"SES\" & `Program Code` == \"SAA\"',                   '`Plan Code` == \"SES\" & `Program Code` == \"SCA\"'),     fleet = c(\"Access Area\", \"Days at Sea\")) # save fleet table to FishSET DB fleet_table(scallopMainDataTable,              project = proj,             table = fleet_tab, save = TRUE) #> Table saved to fishset_db database #>                                        condition       fleet #> 1 `Plan Code` == \"SES\" & `Program Code` == \"SAA\" Access Area #> 2 `Plan Code` == \"SES\" & `Program Code` == \"SCA\" Days at Sea # grab tab name fleet_tab_name <- list_tables(proj, type = \"fleet\") # create fleet column scallopMainDataTable <-    fleet_assign(scallopMainDataTable, project = proj,                 fleet_tab = fleet_tab_name)"},{"path":"/articles/scallop-example.html","id":"bin-gears","dir":"Articles","previous_headings":"Data Import","what":"Bin Gears","title":"Scallop Example","text":"data contain several types fishing gear. simplicity, GEARCODE column re-binned include three categories: \"DREDGE\", \"TRAWL-BOTTOM\", \"\".","code":"scallopMainDataTable$GEARCODE_OLD <- scallopMainDataTable$GEARCODE #Anything with \"DREDGE\" in the GEARCODE will be rebinned to \"DREDGE\"  pat_match <- \"*DREDGE*\" reg_pat <- glob2rx(pat_match) scallopMainDataTable$GEARCODE[grep(reg_pat, scallopMainDataTable$GEARCODE)] <- 'DREDGE' #Look at the GEARCODE NOW, there should be 'DREDGE', 'TRAWL-BOTTOM', and some funky stuff table(scallopMainDataTable$GEARCODE) #>  #>       DREDGE        OTHER TRAWL-BOTTOM  #>         9916            1           83 scallopMainDataTable$GEARCODE[!(scallopMainDataTable$GEARCODE %in% c('DREDGE','TRAWL-BOTTOM'))] <- 'OTHER'"},{"path":"/articles/scallop-example.html","id":"operating-profit","dir":"Articles","previous_headings":"Data Import","what":"Operating Profit","title":"Scallop Example","text":"Calculate operating profit subtracting 2020 trip costs aggregated revenues 2020 dollars.","code":"scallopMainDataTable <-    scallopMainDataTable %>%    mutate(OPERATING_PROFIT_2020 = DOLLAR_ALL_SP_2020_OBSCURED - TRIP_COST_WINSOR_2020_DOL)"},{"path":"/articles/scallop-example.html","id":"summary-table","dir":"Articles","previous_headings":"Data Import","what":"Summary Table","title":"Scallop Example","text":"","code":"summary_stats(scallopMainDataTable, proj) %>%    pretty_tab_sb()"},{"path":[]},{"path":"/articles/scallop-example.html","id":"na-check","dir":"Articles","previous_headings":"QAQC","what":"NA Check","title":"Scallop Example","text":"","code":"na_filter(scallopMainDataTable,            project = proj,            replace = FALSE, remove = FALSE,            rep.value = NA, over_write = FALSE) #> The following columns contain NAs: previous_port_lat, previous_port_lon, NAME, ZoneID. Consider using na_filter to replace or remove NAs."},{"path":"/articles/scallop-example.html","id":"nan-check","dir":"Articles","previous_headings":"QAQC","what":"NaN Check","title":"Scallop Example","text":"","code":"nan_filter(scallopMainDataTable,             project = proj,             replace = FALSE, remove = FALSE,             rep.value = NA, over_write = FALSE) #> No NaNs found."},{"path":"/articles/scallop-example.html","id":"unique-rows","dir":"Articles","previous_headings":"QAQC","what":"Unique Rows","title":"Scallop Example","text":"","code":"unique_filter(scallopMainDataTable, project = proj, remove = FALSE) #> Unique filter check for scallopMainDataTable dataset on 20240528  #> Each row is a unique choice occurrence. No further action required."},{"path":"/articles/scallop-example.html","id":"empty-variables","dir":"Articles","previous_headings":"QAQC","what":"Empty Variables","title":"Scallop Example","text":"“Empty” variables contain NAs.","code":"empty_vars_filter(scallopMainDataTable, project = proj, remove = FALSE) #> Empty vars check for scallopMainDataTable dataset on 20240528  #> No empty variables identified."},{"path":"/articles/scallop-example.html","id":"lonlat-format","dir":"Articles","previous_headings":"QAQC","what":"Lon/Lat Format","title":"Scallop Example","text":"","code":"degree(scallopMainDataTable, project = proj,        lat = \"DDLAT\", lon = \"DDLON\",         latsign = NULL, lonsign = NULL,        replace = FALSE) #> Latitude and longitude variables in decimal degrees. No further action required."},{"path":"/articles/scallop-example.html","id":"spatial-qaqc","dir":"Articles","previous_headings":"QAQC","what":"Spatial QAQC","title":"Scallop Example","text":"","code":"spat_qaqc_out <- spatial_qaqc(dat = scallopMainDataTable,                                project = proj,                               spat = scallopTenMNSQRSpatTable,                                lon.dat = \"DDLON\",                                lat.dat = \"DDLAT\") #> Warning: Spatial reference EPSG codes for the spatial and primary datasets do #> not match. The detected projection in the spatial file will be used unless epsg #> is specified. #> Warning: 10 observations (0.1%) occur on land. #> Warning: 35 observations (0.4%) occur on boundary line between regulatory zones. #> 10 observations (0.1%) occur on land. #> 35 observations (0.4%) occur on boundary line between regulatory zones.  spat_qaqc_out$dataset <- NULL # drop dataset  spat_qaqc_out$spatial_summary %>%   pretty_lab(cols = \"n\") %>%   pretty_tab() spat_qaqc_out[2:4] #> $land_plot #>  #> $boundary_plot #>  #> $expected_plot"},{"path":[]},{"path":"/articles/scallop-example.html","id":"landing-year","dir":"Articles","previous_headings":"Data Creation","what":"Landing Year","title":"Scallop Example","text":"","code":"scallopMainDataTable <-    scallopMainDataTable %>%    mutate(DB_LANDING_YEAR = as.numeric(format(date_parser(DATE_TRIP), \"%Y\")))"},{"path":"/articles/scallop-example.html","id":"finagle-landed_obscured-to-thousands-of-pounds","dir":"Articles","previous_headings":"Data Creation","what":"Finagle LANDED_OBSCURED to Thousands of Pounds","title":"Scallop Example","text":"","code":"scallopMainDataTable$LANDED_OBSCURED <- scallopMainDataTable$LANDED_OBSCURED / 1000"},{"path":"/articles/scallop-example.html","id":"cpue","dir":"Articles","previous_headings":"Data Creation","what":"CPUE","title":"Scallop Example","text":"Create CPUE variable using TRIP_LENGTH LANDED_OBSCURED. Filter infinite values.","code":"scallopMainDataTable <-    cpue(scallopMainDataTable, proj,        xWeight = \"LANDED_OBSCURED\",        xTime = \"TRIP_LENGTH\",         name = \"CPUE\") #> Warning: xWeight must a measurement of mass. CPUE calculated. #> Warning: xTime should be a measurement of time. Use the create_duration #> function. CPUE calculated.  scallopMainDataTable <-    scallopMainDataTable %>%    filter(!is.infinite(CPUE))"},{"path":"/articles/scallop-example.html","id":"cpue-percent-rank","dir":"Articles","previous_headings":"Data Creation > CPUE","what":"CPUE Percent Rank","title":"Scallop Example","text":"Add percent rank column filter outliers.","code":"outlier_table(scallopMainDataTable, proj, x = \"CPUE\") %>%    pretty_lab() %>%    pretty_tab() scallopMainDataTable <-    scallopMainDataTable %>%    mutate(CPUE_p = percent_rank(CPUE))"},{"path":"/articles/scallop-example.html","id":"vpue","dir":"Articles","previous_headings":"Data Creation","what":"VPUE","title":"Scallop Example","text":"revenue instead meat pounds.","code":"scallopMainDataTable <-    cpue(scallopMainDataTable, proj,        xWeight = \"DOLLAR_OBSCURED\",        xTime = \"TRIP_LENGTH\",         name = \"VPUE\") #> Warning: xWeight must a measurement of mass. CPUE calculated. #> Warning: xTime should be a measurement of time. Use the create_duration #> function. CPUE calculated.  scallopMainDataTable <-    scallopMainDataTable %>%    filter(!is.infinite(VPUE))"},{"path":"/articles/scallop-example.html","id":"vpue-percent-rank","dir":"Articles","previous_headings":"Data Creation > VPUE","what":"VPUE Percent Rank","title":"Scallop Example","text":"Add percent rank column filter outliers.","code":"outlier_table(scallopMainDataTable, proj, x = \"VPUE\") %>%    pretty_lab() %>%    pretty_tab() scallopMainDataTable <-    scallopMainDataTable %>%    mutate(VPUE_p = percent_rank(VPUE))"},{"path":"/articles/scallop-example.html","id":"fleet-tabulation","dir":"Articles","previous_headings":"Data Creation","what":"Fleet Tabulation","title":"Scallop Example","text":"","code":"scallopMainDataTable %>%    count(fleet) %>%    mutate(perc = round(n/sum(n) * 100, 1)) %>%    pretty_lab(cols = \"n\") %>%    pretty_tab()"},{"path":"/articles/scallop-example.html","id":"zone-assignment","dir":"Articles","previous_headings":"Data Creation","what":"Zone Assignment","title":"Scallop Example","text":"Assign observation regulatory zone.","code":"scallopMainDataTable <-    assignment_column(scallopMainDataTable, project = proj,                     spat = scallopTenMNSQRSpatTable,                      lon.dat = \"DDLON\",                     lat.dat = \"DDLAT\",                      cat = \"TEN_ID\",                     name = \"ZONE_ID\",                     closest.pt = FALSE,                     hull.polygon = FALSE) #> Warning: Projection does not match. The detected projection in the spatial file #> will be used unless epsg is specified. #> Warning: At least one observation assigned to multiple regulatory zones. #> Assigning observations to nearest polygon."},{"path":"/articles/scallop-example.html","id":"closure-area-assignment","dir":"Articles","previous_headings":"Data Creation","what":"Closure Area Assignment","title":"Scallop Example","text":"Assign observation closure area. observation NA occur within closure area.  62 observations (0.62%) occurred inside closure area.  Observations inside/outside closures fleet.  Observations inside/outside closures year.  Observations inside/outside closures year fleet.","code":"scallopMainDataTable <-    assignment_column(scallopMainDataTable, project = proj,                     spat = scallopWindCloseSpatTable,                      lon.dat = \"DDLON\",                     lat.dat = \"DDLAT\",                      cat = \"NAME\",                     name = \"closeID\",                     closest.pt = FALSE,                     hull.polygon = FALSE)   scallopMainDataTable <-    scallopMainDataTable %>%    mutate(in_closure = !is.na(closeID)) agg_helper(scallopMainDataTable,             value = \"in_closure\",             count = TRUE,             fun = NULL) %>%    pivot_wider(names_from = \"in_closure\", values_from = \"n\") %>%    rename(\"Outside Closure(s)\" = \"FALSE\", \"Inside Closure(s)\" = \"TRUE\") %>%    pretty_lab() %>%    pretty_tab() agg_helper(scallopMainDataTable, group = \"fleet\",              value = \"in_closure\", count = TRUE, fun = NULL) %>%    pivot_wider(names_from = \"in_closure\", values_from = \"n\") %>%    rename(\"Outside Closure(s)\" = \"FALSE\", \"Inside Closure(s)\" = \"TRUE\") %>%    pretty_lab() %>%    pretty_tab() agg_helper(scallopMainDataTable, value = \"in_closure\",              group = \"DB_LANDING_YEAR\",              count = TRUE, fun = NULL) %>%    pivot_wider(names_from = \"in_closure\", values_from = \"n\",               values_fill = 0) %>%    arrange(DB_LANDING_YEAR) %>%    rename(\"Outside closure(s)\" = \"FALSE\", \"Inside closure(s)\" = \"TRUE\") %>%    pretty_lab(ignore = \"DB_LANDING_YEAR\") %>%    pretty_tab() agg_helper(scallopMainDataTable, value = \"in_closure\",              group = c(\"DB_LANDING_YEAR\", \"fleet\"),              count = TRUE, fun = NULL) %>%    pivot_wider(names_from = \"in_closure\", values_from = \"n\",               values_fill = 0) %>%    arrange(DB_LANDING_YEAR) %>%    rename(\"Outside closure(s)\" = \"FALSE\", \"Inside closure(s)\" = \"TRUE\") %>%    pretty_lab(ignore = \"DB_LANDING_YEAR\") %>%    pretty_tab_sb(width = \"60%\")"},{"path":[]},{"path":"/articles/scallop-example.html","id":"frequency","dir":"Articles","previous_headings":"Zone Summary","what":"Frequency","title":"Scallop Example","text":"number observations zone.  Percent observations zone.  Zone frequency (Access Area fleet).  Zone frequency (Days Sea fleet).","code":"zone_out <- zone_summary(scallopMainDataTable, project = proj,                          spat = scallopTenMNSQRSpatTable,                          zone.dat = \"ZONE_ID\",                          zone.spat = \"TEN_ID\",                          output = \"tab_plot\",                          count = TRUE,                          breaks = NULL, n.breaks = 10,                          na.rm = TRUE) #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$plot zone_out$table %>%   pretty_lab(cols = \"n\") %>%   pretty_tab_sb(width = \"40%\") zone_out <-    zone_summary(scallopMainDataTable,                project = proj,                spat = scallopTenMNSQRSpatTable,                zone.dat = \"ZONE_ID\",                zone.spat = \"TEN_ID\",                output = \"tab_plot\",                count = TRUE, fun = \"percent\",                breaks = c(seq(.2, .5, .1), seq(1, 2, .5)),                 na.rm = TRUE) #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$plot zone_out$table %>%    pretty_lab(ignore = \"ZONE_ID\") %>%    pretty_tab_sb(width = \"40%\") zone_out <-    scallopMainDataTable %>%      filter(fleet == \"Access Area\") %>%      zone_summary(project = proj,                  spat = scallopTenMNSQRSpatTable,                   zone.dat = \"ZONE_ID\",                  zone.spat = \"TEN_ID\",                  output = \"tab_plot\",                  count = TRUE,                  breaks = NULL, n.breaks = 10,                   na.rm = TRUE) #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$plot zone_out$table %>%    pretty_lab(cols = \"n\") %>%    pretty_tab_sb(width = \"40%\") zone_out <-    scallopMainDataTable %>%      filter(fleet == \"Days at Sea\") %>%      zone_summary(project = proj,                  spat = scallopTenMNSQRSpatTable,                  zone.dat = \"ZONE_ID\",                  zone.spat = \"TEN_ID\",                  output = \"tab_plot\",                  count = TRUE,                  breaks = NULL, n.breaks = 10,                   na.rm = TRUE) #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$plot zone_out$table %>%    pretty_lab(cols = \"n\") %>%    pretty_tab_sb(width = \"40%\")"},{"path":"/articles/scallop-example.html","id":"catch","dir":"Articles","previous_headings":"Zone Summary","what":"Catch","title":"Scallop Example","text":"Total catch (meats).  Average catch (meats).  Percent total catch (meat).","code":"zone_out <-    zone_summary(scallopMainDataTable,                 project = proj,                spat = scallopTenMNSQRSpatTable,                 zone.dat = \"ZONE_ID\",                zone.spat = \"TEN_ID\",                count = FALSE,                var = \"LANDED_OBSCURED\", fun = \"sum\",                breaks = c(1e3, 1e4, 5e4, 1e5, seq(1e6, 1.3e7, 2e6)),                output = \"tab_plot\", na.rm = TRUE) #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$plot zone_out$table %>%    pretty_lab(cols = \"LANDED_OBSCURED\") %>%    pretty_tab_sb(width = \"40%\") zone_out <-    zone_summary(scallopMainDataTable,                project = proj,                spat = scallopTenMNSQRSpatTable,                 zone.dat = \"ZONE_ID\",                zone.spat = \"TEN_ID\",                count = FALSE,                var = \"LANDED_OBSCURED\", fun = \"mean\",                breaks = c(1e3, 5e3, seq(1e4, 4e4, 5e3)),                output = \"tab_plot\", na.rm = TRUE) #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$plot zone_out$table %>%    pretty_lab(cols = \"LANDED_OBSCURED\") %>%    pretty_tab_sb(width = \"40%\") zone_out <-    zone_summary(scallopMainDataTable, project = proj,                spat = scallopTenMNSQRSpatTable,                zone.dat = \"ZONE_ID\",                zone.spat = \"TEN_ID\",                count = FALSE,                var = \"LANDED_OBSCURED\", fun = \"percent\",                breaks = seq(0, 2, .2),                bin_colors = c(\"white\", fishset_viridis(10)),                output = \"tab_plot\", na.rm = TRUE) #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$plot zone_out$table %>%    pretty_lab(cols = c(\"LANDED_OBSCURED\", \"LANDED_OBSCURED_perc\"), type = \"scientific\") %>%   pretty_tab_sb(width = \"60%\")"},{"path":"/articles/scallop-example.html","id":"trip-length","dir":"Articles","previous_headings":"Zone Summary","what":"Trip Length","title":"Scallop Example","text":"Average trip length Access Area Days Sea fleet.","code":"zone_out <-    zone_summary(scallopMainDataTable, project = proj,                spat = scallopTenMNSQRSpatTable,                 zone.dat = \"ZONE_ID\",                zone.spat = \"TEN_ID\",                count = FALSE,                var = \"TRIP_LENGTH\", fun = \"mean\",                breaks = seq(2, 16, 2),                output = \"tab_plot\", na.rm = TRUE) #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$plot zone_out$table %>%    pretty_lab(cols = \"TRIP_LENGTH\", type = \"decimal\") %>%    pretty_tab_sb(width = \"40%\")"},{"path":"/articles/scallop-example.html","id":"cpue-1","dir":"Articles","previous_headings":"Zone Summary","what":"CPUE","title":"Scallop Example","text":"Average CPUE Access Area Days Sea fleets.","code":"zone_out <-    scallopMainDataTable %>%      filter(CPUE_p >= .025 & CPUE_p <= .975) %>%     zone_summary(project = proj,                  spat = scallopTenMNSQRSpatTable,                   zone.dat = \"ZONE_ID\",                  zone.spat = \"TEN_ID\",                  count = FALSE,                  var = \"CPUE\", fun = \"mean\",                  na.rm = TRUE, output = \"tab_plot\") #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode... zone_out$plot zone_out$table %>%    pretty_lab(cols = \"CPUE\") %>%   pretty_tab_sb(width = \"50%\")"},{"path":"/articles/scallop-example.html","id":"vpue-1","dir":"Articles","previous_headings":"Zone Summary","what":"VPUE","title":"Scallop Example","text":"Average VPUE Access Area Days Sea fleets.","code":"zone_out <-  scallopMainDataTable %>%    filter(VPUE_p >= .025 & VPUE_p <= .975) %>%    zone_summary(project = proj,                spat = scallopTenMNSQRSpatTable,                 zone.dat = \"ZONE_ID\",                zone.spat = \"TEN_ID\",                count = FALSE,                var = \"VPUE\", fun = \"mean\",                breaks = seq(5e3, 3.5e4, 5e3),                na.rm = TRUE, output = \"tab_plot\") #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode... zone_out$plot zone_out$table %>%    pretty_lab(cols = \"VPUE\") %>%   pretty_tab_sb(width = \"50%\")"},{"path":"/articles/scallop-example.html","id":"closure-summary","dir":"Articles","previous_headings":"","what":"Closure Summary","title":"Scallop Example","text":"Number observations closure areas.  Percent observations closure areas.  Percent total revenue closure area.  Percent total revenue fleet.  Average meat catch per closure area.  Average meat catch fleet.","code":"zone_out <-    zone_summary(scallopMainDataTable, project = proj,                spat = scallopWindCloseSpatTable,                 zone.dat = \"closeID\",                zone.spat = \"NAME\",                count = TRUE,                na.rm = TRUE, dat.center = FALSE,                 output = \"tab_plot\") #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$table %>%    pretty_lab() %>%    pretty_tab_sb(width = \"40%\") zone_out$plot zone_out <-    zone_summary(scallopMainDataTable, project = proj,                spat = scallopWindCloseSpatTable,                 zone.dat = \"closeID\",                zone.spat = \"NAME\",                fun = \"percent\",                count = TRUE,                na.rm = TRUE, dat.center = FALSE,                 output = \"tab_plot\") #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$table %>%    pretty_lab() %>%    pretty_tab_sb(width = \"40%\") zone_out$plot zone_out <-    zone_summary(scallopMainDataTable, project = proj,                spat = scallopWindCloseSpatTable,                zone.dat = \"closeID\",                zone.spat = \"NAME\",                var = \"DOLLAR_OBSCURED\",                fun = \"percent\",                count = FALSE,                 na.rm = TRUE, dat.center = FALSE,                output = \"tab_plot\") #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$table %>%    pretty_lab() %>%    pretty_tab_sb(width = \"70%\") zone_out$plot zone_out <-    zone_summary(scallopMainDataTable, project = proj,                spat = scallopWindCloseSpatTable,                zone.dat = \"closeID\",                zone.spat = \"NAME\",                var = \"DOLLAR_OBSCURED\", group = \"fleet\",                fun = \"percent\",                count = FALSE,                 na.rm = TRUE, dat.center = FALSE,                output = \"tab_plot\") #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode... #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$table %>%    pretty_lab() %>%    pretty_tab_sb(width = \"70%\") zone_out$plot #> [[1]] #>  #> [[2]] zone_out <-    zone_summary(scallopMainDataTable, project = proj,                spat = scallopWindCloseSpatTable,                 zone.dat = \"closeID\",                zone.spat = \"NAME\",                var = \"LANDED_OBSCURED\",                fun = \"mean\",                count = FALSE,                na.rm = TRUE, dat.center = FALSE,                 output = \"tab_plot\") #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$table %>%    pretty_lab() %>%    pretty_tab_sb(width = \"50%\") zone_out$plot zone_out <-    zone_summary(scallopMainDataTable, project = proj,                spat = scallopWindCloseSpatTable,                 zone.dat = \"closeID\",                zone.spat = \"NAME\",                var = \"LANDED_OBSCURED\", group = \"fleet\",                fun = \"mean\",                count = FALSE,                na.rm = TRUE, dat.center = FALSE,                 output = \"tab_plot\") #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode... #> A line object has been specified, but lines is not in the mode #> Adding lines to the mode...  zone_out$table %>%    pretty_lab() %>%    pretty_tab_sb(width = \"60%\") zone_out$plot #> [[1]] #>  #> [[2]]"},{"path":[]},{"path":"/articles/scallop-example.html","id":"pounds","dir":"Articles","previous_headings":"Outliers","what":"POUNDS","title":"Scallop Example","text":"","code":"outlier_table(scallopMainDataTable, proj,               x = \"LANDED_OBSCURED\") %>%    pretty_lab() %>%    pretty_tab() outlier_plot(scallopMainDataTable, proj,              x = \"LANDED_OBSCURED\",               dat.remove = \"none\",              x.dist = \"normal\",              output.screen = TRUE) #> TableGrob (3 x 2) \"arrange\": 4 grobs #>   z     cells    name                grob #> 1 1 (2-2,1-1) arrange      gtable[layout] #> 2 2 (2-2,2-2) arrange      gtable[layout] #> 3 3 (3-3,1-1) arrange      gtable[layout] #> 4 4 (1-1,1-2) arrange text[GRID.text.379] outlier_plot(scallopMainDataTable, proj,              x = \"LANDED_OBSCURED\",               dat.remove = \"mean_3SD\",              x.dist = \"normal\",              output.screen = TRUE) #> TableGrob (3 x 2) \"arrange\": 4 grobs #>   z     cells    name                grob #> 1 1 (2-2,1-1) arrange      gtable[layout] #> 2 2 (2-2,2-2) arrange      gtable[layout] #> 3 3 (3-3,1-1) arrange      gtable[layout] #> 4 4 (1-1,1-2) arrange text[GRID.text.488]"},{"path":"/articles/scallop-example.html","id":"temporal-plots","dir":"Articles","previous_headings":"","what":"Temporal Plots","title":"Scallop Example","text":"","code":"temp_plot(scallopMainDataTable, proj,           var.select = \"LANDED_OBSCURED\",           len.fun = \"percent\",           agg.fun = \"sum\",           date.var = \"DATE_TRIP\",           pages = \"multi\") #> $scatter_plot #>  #> $unique_plot #>  #> $agg_plot temp_plot(scallopMainDataTable, proj,           var.select = \"TRIP_LENGTH\",           len.fun = \"percent\",           agg.fun = \"sum\",           date.var = \"DATE_TRIP\",           pages = \"multi\") #> $scatter_plot #>  #> $unique_plot #>  #> $agg_plot temp_plot(scallopMainDataTable, proj,           var.select = \"DOLLAR_OBSCURED\",           len.fun = \"percent\",           agg.fun = \"sum\",           date.var = \"DATE_TRIP\",           pages = \"multi\") #> $scatter_plot #>  #> $unique_plot #>  #> $agg_plot"},{"path":"/articles/scallop-example.html","id":"scatter-plots","dir":"Articles","previous_headings":"","what":"Scatter Plots","title":"Scallop Example","text":"Trip length meat catch.   Trip length revenue.   Trip length trip cost (Winsor).","code":"xy_plot(scallopMainDataTable, proj,         var1 = \"TRIP_LENGTH\", var2 = \"LANDED_OBSCURED\",         regress = FALSE, alpha = .3) xy_plot(scallopMainDataTable, proj,         var1 = \"TRIP_LENGTH\", var2 = \"DOLLAR_OBSCURED\",         regress = FALSE, alpha = .3) xy_plot(scallopMainDataTable, proj,         var1 = \"TRIP_LENGTH\", var2 = \"TRIP_COST_WINSOR_2020_DOL\",         regress = FALSE, alpha = .3)"},{"path":"/articles/scallop-example.html","id":"correlation-matrix","dir":"Articles","previous_headings":"","what":"Correlation Matrix","title":"Scallop Example","text":"","code":"corr_outs <-   corr_out(scallopMainDataTable, proj,            variables = \"all\",            method = \"pearson\",             show_coef = FALSE) #> Warning: No variance found in fleetAssignPlaceholder. Removed from correlation #> test  corr_outs$plot corr_outs$table %>%    pretty_tab_sb(width = \"100%\")"},{"path":"/articles/scallop-example.html","id":"active-vessels","dir":"Articles","previous_headings":"","what":"Active Vessels","title":"Scallop Example","text":"vessel count year.   vessel count fleet.  vessel count year fleet.   vessel count gearcode.","code":"ves_out <-    vessel_count(scallopMainDataTable, proj,                v_id = \"PERMIT.y\",                date = \"DATE_TRIP\",                period = \"year\", type = \"line\") #> Joining with `by = join_by(DATE_TRIP)` #> Warning: Setting row names on a tibble is deprecated.  ves_out$table %>% pretty_tab() ves_out$plot ves_out <-    vessel_count(scallopMainDataTable, proj,                v_id = \"PERMIT.y\",                group = \"fleet\",                output = \"table\") #> Joining with `by = join_by(fleet)` #> Warning: Setting row names on a tibble is deprecated.  ves_out$table %>% pretty_tab() #> Warning: Unknown or uninitialised column: `table`. ves_out$plot  #> Warning: Unknown or uninitialised column: `plot`. #> NULL ves_out <-    vessel_count(scallopMainDataTable, proj,                v_id = \"PERMIT.y\",                group = \"fleet\",                date = \"DATE_TRIP\",                period = \"year\", type = \"line\") #> Joining with `by = join_by(fleet, DATE_TRIP)` #> Warning: Setting row names on a tibble is deprecated.  ves_out$table %>%    pretty_lab(cols = \"PERMIT.y\") %>%    pretty_tab_sb(width = \"40%\") ves_out$plot ves_out <-    vessel_count(scallopMainDataTable, proj,                v_id = \"PERMIT.y\",                group = \"GEARCODE\", tran = \"log\") #> Joining with `by = join_by(GEARCODE)` #> Warning: Setting row names on a tibble is deprecated.  ves_out$table %>%    pretty_lab() %>%    pretty_tab() ves_out$plot"},{"path":"/articles/scallop-example.html","id":"catch-1","dir":"Articles","previous_headings":"","what":"Catch","title":"Scallop Example","text":"Total meat catch year.   Total meat catch fleet.   Total meat catch year fleet.","code":"catch_out <-  species_catch(scallopMainDataTable, proj,               species = \"LANDED_OBSCURED\",               date = \"DATE_TRIP\",                period = \"year\",               fun = \"sum\",               type = \"line\", format_lab = \"decimal\") #> Joining with `by = join_by(DATE_TRIP)`  catch_out$table %>%    pretty_lab(cols = \"LANDED_OBSCURED\") %>%   pretty_tab() catch_out$plot catch_out <-    species_catch(scallopMainDataTable, proj,                 species = \"LANDED_OBSCURED\",                 group = \"fleet\",                 fun = \"sum\",                 type = \"bar\", format_lab = \"decimal\") #> Joining with `by = join_by(fleet)`  catch_out$table %>%    pretty_lab(cols = \"LANDED_OBSCURED\") %>%   pretty_tab() catch_out$plot catch_out <-    species_catch(scallopMainDataTable, proj,                 species = \"LANDED_OBSCURED\",                 date = \"DATE_TRIP\",                  period = \"year\",                 group = \"fleet\",                 fun = \"sum\",                 type = \"line\", format_lab = \"decimal\") #> Joining with `by = join_by(fleet, DATE_TRIP)`  catch_out$table %>%    pretty_lab(cols = \"LANDED_OBSCURED\") %>%   pretty_tab_sb(width = \"40%\") catch_out$plot"},{"path":"/articles/scallop-example.html","id":"cpue-2","dir":"Articles","previous_headings":"","what":"CPUE","title":"Scallop Example","text":"Average CPUE year.   Average CPUE year fleet.","code":"cpue_out <-    species_catch(scallopMainDataTable, proj,                 species = \"CPUE\",                 date = \"DATE_TRIP\",                  period = \"year\",                 fun = \"mean\", type = \"line\") #> Joining with `by = join_by(DATE_TRIP)`  cpue_out$table %>%    pretty_lab(cols = \"CPUE\") %>%   pretty_tab() cpue_out$plot cpue_out <-    species_catch(scallopMainDataTable, proj,                 species = \"CPUE\",                 date = \"DATE_TRIP\",                  period = \"year\",                 group = \"fleet\",                 fun = \"mean\", type = \"line\") #> Joining with `by = join_by(fleet, DATE_TRIP)`  cpue_out$table %>%    pretty_lab(cols = \"CPUE\") %>%   pretty_tab_sb(width = \"40%\") cpue_out$plot"},{"path":"/articles/scallop-example.html","id":"vpue-2","dir":"Articles","previous_headings":"","what":"VPUE","title":"Scallop Example","text":"Average VPUE year.   Average VPUE year fleet.   Average VPUE gearcode.","code":"vpue_out <-    species_catch(scallopMainDataTable, proj,                 species = \"VPUE\",                 date = \"DATE_TRIP\",                  period = \"year\",                 fun = \"mean\", type = \"line\") #> Joining with `by = join_by(DATE_TRIP)`  vpue_out$table %>%    pretty_lab(cols = \"VPUE\") %>%   pretty_tab() vpue_out$plot vpue_out <-    species_catch(scallopMainDataTable, proj,                 species = \"VPUE\",                 date = \"DATE_TRIP\",                  period = \"year\",                 group = \"fleet\",                 fun = \"mean\", type = \"line\") #> Joining with `by = join_by(fleet, DATE_TRIP)`  vpue_out$table %>%    pretty_lab(cols = \"VPUE\") %>%   pretty_tab_sb(width = \"40%\") vpue_out$plot vpue_out <-    species_catch(scallopMainDataTable, proj,                 species = \"VPUE\",                 group = \"GEARCODE\",                 fun = \"mean\", type = \"line\") #> Joining with `by = join_by(GEARCODE)`  vpue_out$table %>%  pretty_lab() %>%   pretty_tab() vpue_out$plot + angled_theme()"},{"path":[]},{"path":"/articles/scallop-example.html","id":"landed_obscured","dir":"Articles","previous_headings":"Distributions","what":"LANDED_OBSCURED","title":"Scallop Example","text":"KDE, ECDF, CDF meat catch.   KDE, ECDF, CDF meat catch fleet.   KDE meat catch year.","code":"density_plot(scallopMainDataTable, proj,              var = \"LANDED_OBSCURED\",               type = \"all\", tran = \"log\") density_plot(scallopMainDataTable, proj,              var = \"LANDED_OBSCURED\",              group = \"fleet\", position = \"stack\",               type = \"all\", tran = \"log\", pages = \"multi\") density_plot(scallopMainDataTable, proj,              var = \"LANDED_OBSCURED\",               facet_by = \"DB_LANDING_YEAR\",              filter_by = \"DB_LANDING_YEAR\",              filter_value = 2007:2013,              type = \"kde\", bw = 1.5,               tran = \"log\", scale = \"free_y\") +    angled_theme() density_plot(scallopMainDataTable, proj,              var = \"LANDED_OBSCURED\",               facet_by = \"DB_LANDING_YEAR\",              filter_by = \"DB_LANDING_YEAR\",              filter_value = 2014:2019,              type = \"kde\", bw = 1.5,               tran = \"log\", scale = \"free_y\") +    angled_theme()"},{"path":"/articles/scallop-mod-example.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Scallop Conditional Logit Model Example","text":"example conditional logit model using scallop data FishSET package.","code":""},{"path":"/articles/scallop-mod-example.html","id":"packages","dir":"Articles","previous_headings":"Introduction","what":"Packages","title":"Scallop Conditional Logit Model Example","text":"","code":"library(FishSET) ## The legacy packages maptools, rgdal, and rgeos, underpinning the sp package, ## which was just loaded, will retire in October 2023. ## Please refer to R-spatial evolution reports for details, especially ## https://r-spatial.org/r/2023/05/15/evolution4.html. ## It may be desirable to make the sf package available; ## package maintainers should consider adding sf to Suggests:. ## The sp package is now running under evolution status 2 ##      (status 2 uses the sf package in place of rgdal)"},{"path":"/articles/scallop-mod-example.html","id":"load-data","dir":"Articles","previous_headings":"Introduction","what":"Load Data","title":"Scallop Conditional Logit Model Example","text":"analysis uses three FishSET’s example datasets: scallop dataframe contains anonymized scallop data Northeast, scallop_ports table ports location, tenMNSQR spatial dataframe Northeastern ten minute squares. scallop dataframe contains random sample 10,000 trips vessels Limited Access Days--Sea fleet declared either Access Area Open area Days--Sea fishing trip. Noise added fishing locations, landing quantities, value catch. Permit, Operator, trip identifiers also anonymized.  Load dataset FishSET. Rescale Landed weight thousands meat pounds Dollar value thousands Real dollars. Note: running chunk may get pop-asking identify location new FishSET folder existing folder.","code":"data(\"scallop\") data('scallop_ports') data(\"tenMNSQR\") scallop$LANDED_thousands<-scallop$LANDED_OBSCURED/1000 scallop$DOLLAR_2020_thousands<-scallop$DOLLAR_2020_OBSCURED/1000  vars_to_keep <- c('TRIPID', 'PERMIT.y', 'DATE_TRIP', 'DDLON', 'DDLAT', 'ZoneID',                    'LANDED_thousands', 'DOLLAR_2020_thousands', 'port_lon', 'port_lat',                   'previous_port_lon', 'previous_port_lat') scallop <- scallop[vars_to_keep] load_maindata(scallop, project = \"scallopMod\", over_write = TRUE) ## Table saved to database ##  ## ! Data saved to database as scallopModMainDataTable20240528 (raw) and scallopModMainDataTable (working).  ## Table is also in the working environment. ! load_port(dat = scallop_ports, port_name = \"port_name\", project = \"scallopMod\") ## Port table saved to database load_spatial(spat = tenMNSQR, name = \"TenMnSqr\", project = \"scallopMod\") ## Writing layer `scallopModTenMnSqrSpatTable' to data source  ##   `C:\\Users\\pcarvalho\\AppData\\Local\\Temp\\RtmpQ72qeo/scallopMod/data/spat/scallopModTenMnSqrSpatTable.geojson' using driver `GeoJSON' ## Writing 5267 features with 9 fields and geometry type Polygon. ## Writing layer `scallopModTenMnSqrSpatTable20240528' to data source  ##   `C:\\Users\\pcarvalho\\AppData\\Local\\Temp\\RtmpQ72qeo/scallopMod/data/spat/scallopModTenMnSqrSpatTable20240528.geojson' using driver `GeoJSON' ## Writing 5267 features with 9 fields and geometry type Polygon. ## Spatial table saved to project folder as scallopModTenMnSqrSpatTable scallopModTenMnSqrSpatTable <- table_view('scallopModTenMnSqrSpatTable', \"scallopMod\") ## Reading layer `scallopModTenMnSqrSpatTable' from data source  ##   `C:\\Users\\pcarvalho\\AppData\\Local\\Temp\\RtmpQ72qeo\\scallopMod\\data\\spat\\scallopModTenMnSqrSpatTable.geojson'  ##   using driver `GeoJSON' ## Simple feature collection with 5267 features and 9 fields ## Geometry type: POLYGON ## Dimension:     XY ## Bounding box:  xmin: -77 ymin: 33 xmax: -64 ymax: 46.00139 ## Geodetic CRS:  NAD83"},{"path":"/articles/scallop-mod-example.html","id":"qaqc","dir":"Articles","previous_headings":"Introduction","what":"QAQC","title":"Scallop Conditional Logit Model Example","text":"summary_stats() useful way find NAs data.  Remove NAs calling na_filter(). case, three variables important modeling filtered: ZoneID, previous_port_lon, previous_port_lat.  Plot number observations zone.  Check sparsity.","code":"summary_stats(scallopModMainDataTable, project = \"scallopMod\") ##              TRIPID        PERMIT.y            DDLON            DDLAT ## 1   Min.   :    6     Min.   :  1      Min.   :-76       Min.   :35   ## 2   Median :18836     Median :218      Median :-73       Median :40   ## 3   Mean   :19076     Mean   :236      Mean   :-72       Mean   :40   ## 4   Max.   :38503     Max.   :456      Max.   :-66       Max.   :43   ## 5           NA's: 0         NA's: 0          NA's: 0          NA's: 0 ## 6 Unique Obs: 10000 Unique Obs: 130 Unique Obs: 2212 Unique Obs: 2039 ## 7        No. 0's: 0      No. 0's: 0       No. 0's: 0       No. 0's: 0 ##             ZoneID  LANDED_thousands DOLLAR_2020_thousands      port_lon ## 1 Min.   :357223    Min.   : 0.022         Min.   :  0.2   Min.   :-76   ## 2 Median :406712    Median :15.639         Median :146.7   Median :-71   ## 3 Mean   :400612    Mean   :14.822         Mean   :152.0   Mean   :-73   ## 4 Max.   :427066    Max.   :76.507         Max.   :721.7   Max.   :-71   ## 5          NA's: 5           NA's: 0               NA's: 0       NA's: 0 ## 6  Unique Obs: 469 Unique Obs: 10000     Unique Obs: 10000 Unique Obs: 6 ## 7      No. 0's: NA        No. 0's: 0            No. 0's: 0    No. 0's: 0 ##        port_lat previous_port_lon previous_port_lat         DATE_TRIP ## 1  Min.   :37       Min.   :-77        Min.   :35   First: 2007-05-01 ## 2  Median :42       Median :-71        Median :42                  NA ## 3  Mean   :40       Mean   :-73        Mean   :40                  NA ## 4  Max.   :42       Max.   :-70        Max.   :44                  NA ## 5       NA's: 0          NA's: 18          NA's: 18           NA's: 0 ## 6 Unique Obs: 6    Unique Obs: 41    Unique Obs: 41  Unique Obs: 3539 ## 7    No. 0's: 0       No. 0's: NA       No. 0's: NA      No. Empty: 0 scallopModMainDataTable <-    na_filter(scallopModMainDataTable,             project = \"scallopMod\",              x = c(\"ZoneID\", \"previous_port_lon\", \"previous_port_lat\"),             remove = TRUE) ## The following columns contain NAs: ZoneID, previous_port_lon, previous_port_lat. Consider using na_filter to replace or remove NAs. ## The entire row will be removed from the dataframe. zone_summary(dat = scallopModMainDataTable,               spat = scallopModTenMnSqrSpatTable,               project = \"scallopMod\",              zone.dat = \"ZoneID\",              zone.spat = \"TEN_ID\",              output = \"tab_plot\") ## A line object has been specified, but lines is not in the mode ## Adding lines to the mode... ## $table ## # A tibble: 468 × 2 ##    ZoneID     n ##    <chr>  <int> ##  1 416956   242 ##  2 387323   229 ##  3 406962   225 ##  4 387313   223 ##  5 387332   198 ##  6 387322   193 ##  7 387341   188 ##  8 406923   177 ##  9 406961   172 ## 10 387463   160 ## # ℹ 458 more rows ##  ## $plot sparsetable(scallopModMainDataTable, 'scallopMod',              timevar = 'DATE_TRIP',              zonevar = 'ZoneID',             var = 'LANDED_thousands') ##           387321 387464 397242 387313 397231 407226 397241 397364 426756 407245 ## daily       0.98   0.95   1.00   0.94   0.97   0.98   0.99   0.98   1.00   0.98 ## weekly      0.94   0.84   0.98   0.80   0.89   0.93   0.96   0.94   0.99   0.92 ## biweekly    0.88   0.75   0.97   0.73   0.83   0.88   0.92   0.89   0.99   0.86 ## monthly     0.77   0.64   0.95   0.62   0.69   0.79   0.85   0.82   0.97   0.78 ## quarterly   0.60   0.46   0.87   0.46   0.44   0.56   0.62   0.63   0.92   0.54 ## yearly      0.31   0.23   0.62   0.15   0.00   0.08   0.23   0.23   0.69   0.15 ##           406611 406761 416741 407236 387454 407366 387452 397213 397363 387322 ## daily       0.99   0.98   0.99   0.99   0.97   0.99   0.99   0.97   0.99   0.94 ## weekly      0.97   0.95   0.95   0.95   0.87   0.94   0.94   0.89   0.96   0.83 ## biweekly    0.95   0.92   0.93   0.92   0.81   0.90   0.91   0.83   0.91   0.72 ## monthly     0.92   0.86   0.89   0.87   0.70   0.82   0.86   0.71   0.84   0.62 ## quarterly   0.83   0.69   0.77   0.73   0.52   0.56   0.75   0.48   0.67   0.46 ## yearly      0.54   0.38   0.38   0.46   0.31   0.15   0.54   0.15   0.38   0.31 ##           387341 416966 397351 387312 397356 407246 387462 387455 397365 397354 ## daily       0.95   0.96   0.98   0.98   0.98   0.99   0.97   0.96   0.97   0.99 ## weekly      0.83   0.83   0.90   0.92   0.92   0.96   0.91   0.87   0.91   0.96 ## biweekly    0.73   0.74   0.84   0.86   0.88   0.93   0.86   0.80   0.85   0.93 ## monthly     0.62   0.58   0.72   0.77   0.80   0.86   0.78   0.72   0.73   0.85 ## quarterly   0.50   0.33   0.44   0.56   0.56   0.71   0.62   0.54   0.52   0.62 ## yearly      0.23   0.00   0.00   0.31   0.23   0.31   0.38   0.31   0.15   0.15 ##           406741 387463 426736 397341 406751 407254 397366 377241 397361 407215 ## daily       0.98   0.95   0.99   0.99   0.98   0.99   0.98   1.00   0.99   0.99 ## weekly      0.94   0.85   0.97   0.95   0.95   0.97   0.95   1.00   0.95   0.94 ## biweekly    0.89   0.77   0.95   0.92   0.92   0.95   0.92   1.00   0.92   0.90 ## monthly     0.81   0.67   0.90   0.85   0.86   0.89   0.85   0.99   0.84   0.80 ## quarterly   0.56   0.52   0.79   0.63   0.75   0.75   0.69   0.98   0.65   0.63 ## yearly      0.15   0.31   0.54   0.38   0.31   0.38   0.38   0.92   0.15   0.15 ##           397355 397214 406961 397325 387342 407362 387354 397226 387314 357223 ## daily       0.98   0.98   0.95   0.99   0.97   1.00   1.00   1.00   0.97   1.00 ## weekly      0.92   0.92   0.82   0.98   0.91   1.00   1.00   1.00   0.90   1.00 ## biweekly    0.87   0.84   0.71   0.96   0.86   1.00   1.00   1.00   0.84   1.00 ## monthly     0.81   0.73   0.55   0.92   0.75   0.99   0.99   0.99   0.75   0.99 ## quarterly   0.62   0.48   0.21   0.83   0.58   0.98   0.98   0.98   0.56   0.98 ## yearly      0.23   0.31   0.00   0.62   0.31   0.92   0.92   0.92   0.23   0.92 ##           397346 387453 397243 397223 387331 416956 417226 377366 407334 406811 ## daily       0.96   0.98   1.00   0.97   0.97   0.93   1.00   1.00   1.00   0.97 ## weekly      0.86   0.94   1.00   0.91   0.87   0.77   1.00   1.00   0.99   0.89 ## biweekly    0.79   0.90   0.99   0.84   0.79   0.67   0.99   1.00   0.98   0.82 ## monthly     0.65   0.82   0.99   0.75   0.63   0.53   0.99   0.99   0.96   0.68 ## quarterly   0.42   0.67   0.96   0.52   0.38   0.23   0.96   0.98   0.88   0.48 ## yearly      0.08   0.46   0.85   0.15   0.08   0.08   0.85   0.92   0.62   0.00 ##           406612 387351 407264 387052 397352 407131 406841 406953 406962 416945 ## daily       1.00   0.99   1.00   1.00   0.98   0.99   1.00   0.98   0.95   0.99 ## weekly      1.00   0.94   0.99   1.00   0.92   0.97   0.99   0.94   0.87   0.95 ## biweekly    0.99   0.90   0.98   1.00   0.85   0.95   0.99   0.90   0.80   0.91 ## monthly     0.99   0.84   0.95   0.99   0.76   0.90   0.97   0.82   0.70   0.82 ## quarterly   0.96   0.65   0.88   0.98   0.42   0.79   0.94   0.69   0.62   0.58 ## yearly      0.85   0.38   0.62   0.92   0.15   0.46   0.77   0.38   0.23   0.23 ##           406964 406963 416825 416826 416835 416946 396811 416845 416836 406831 ## daily       1.00   0.98   0.97   0.97   0.98   0.99   1.00   1.00   0.99   1.00 ## weekly      0.99   0.92   0.92   0.92   0.95   0.97   1.00   0.99   0.97   0.99 ## biweekly    0.99   0.87   0.87   0.88   0.94   0.95   1.00   0.98   0.96   0.98 ## monthly     0.98   0.78   0.80   0.84   0.91   0.90   0.99   0.95   0.92   0.97 ## quarterly   0.94   0.67   0.67   0.73   0.83   0.75   0.98   0.88   0.87   0.92 ## yearly      0.85   0.31   0.38   0.46   0.69   0.38   0.92   0.54   0.77   0.77 ##           416846 407112 406952 407363 416816 397336 406721 406951 416935 407326 ## daily       1.00   0.99   0.98   1.00   0.96   0.97   0.99   0.96   1.00   1.00 ## weekly      1.00   0.95   0.92   1.00   0.90   0.90   0.98   0.85   1.00   1.00 ## biweekly    0.99   0.92   0.88   0.99   0.85   0.83   0.96   0.74   0.99   0.99 ## monthly     0.99   0.84   0.82   0.98   0.78   0.69   0.93   0.57   0.99   0.98 ## quarterly   0.98   0.67   0.71   0.94   0.62   0.46   0.83   0.29   0.94   0.94 ## yearly      0.92   0.31   0.23   0.77   0.31   0.15   0.54   0.00   0.85   0.85 ##           416742 407113 407216 416955 387363 407244 416731 397326 416834 377353 ## daily       1.00   0.99   0.99   0.98   1.00   0.99   0.99   0.99   0.98   1.00 ## weekly      1.00   0.96   0.95   0.91   1.00   0.96   0.97   0.95   0.94   1.00 ## biweekly    0.99   0.93   0.92   0.85   1.00   0.93   0.96   0.92   0.90   0.99 ## monthly     0.99   0.88   0.84   0.75   0.99   0.88   0.93   0.84   0.84   0.99 ## quarterly   0.96   0.71   0.65   0.56   0.98   0.69   0.85   0.69   0.75   0.96 ## yearly      0.85   0.31   0.23   0.15   0.92   0.31   0.54   0.46   0.46   0.85 ##           406742 387311 426746 406712 406732 387335 416853 397232 397345 396841 ## daily       0.99   0.99   0.98   0.99   0.98   1.00   1.00   0.98   0.98   1.00 ## weekly      0.97   0.96   0.93   0.98   0.93   1.00   1.00   0.93   0.94   1.00 ## biweekly    0.96   0.92   0.89   0.96   0.89   1.00   0.99   0.88   0.89   1.00 ## monthly     0.91   0.84   0.83   0.92   0.82   0.99   0.99   0.80   0.82   0.99 ## quarterly   0.83   0.63   0.62   0.81   0.62   0.98   0.96   0.60   0.60   0.98 ## yearly      0.46   0.23   0.08   0.46   0.23   0.92   0.85   0.15   0.31   0.92 ##           406862 406812 406632 416954 406722 397334 406733 387343 416711 387352 ## daily       0.99   0.98   1.00   0.99   0.99   1.00   0.99   0.99   1.00   0.99 ## weekly      0.98   0.93   1.00   0.97   0.97   0.98   0.97   0.98   0.98   0.98 ## biweekly    0.96   0.88   1.00   0.95   0.94   0.96   0.96   0.96   0.97   0.96 ## monthly     0.93   0.78   0.99   0.90   0.89   0.93   0.92   0.92   0.95   0.92 ## quarterly   0.83   0.56   0.98   0.79   0.77   0.85   0.85   0.85   0.88   0.85 ## yearly      0.54   0.15   0.92   0.46   0.31   0.69   0.54   0.46   0.54   0.54 ##           387461 397252 397344 406813 397211 397233 406861 416861 416944 416933 ## daily       1.00   1.00   0.99   0.99   0.99   1.00   1.00   1.00   0.98   0.99 ## weekly      0.99   1.00   0.96   0.97   0.96   1.00   1.00   0.99   0.94   0.97 ## biweekly    0.98   1.00   0.93   0.95   0.92   0.99   0.99   0.98   0.91   0.94 ## monthly     0.96   0.99   0.86   0.88   0.84   0.99   0.99   0.96   0.85   0.89 ## quarterly   0.88   0.98   0.73   0.69   0.65   0.96   0.96   0.92   0.67   0.73 ## yearly      0.62   0.92   0.38   0.23   0.23   0.85   0.85   0.77   0.15   0.46 ##           397222 406851 406731 407352 397221 407214 406823 387366 397353 397215 ## daily       0.99   1.00   0.99   1.00   0.99   0.99   0.99   1.00   0.99   0.99 ## weekly      0.97   1.00   0.96   1.00   0.96   0.97   0.98   1.00   0.95   0.97 ## biweekly    0.94   0.99   0.93   1.00   0.93   0.95   0.96   1.00   0.91   0.94 ## monthly     0.88   0.99   0.88   0.99   0.86   0.91   0.91   0.99   0.82   0.89 ## quarterly   0.77   0.96   0.75   0.98   0.69   0.77   0.81   0.98   0.63   0.75 ## yearly      0.31   0.85   0.15   0.92   0.31   0.46   0.46   0.92   0.38   0.46 ##           387353 416815 397316 397212 397216 406822 387333 407235 387332 387323 ## daily       1.00   0.99   1.00   0.99   1.00   0.99   0.96   0.99   0.94   0.93 ## weekly      0.99   0.95   0.98   0.97   1.00   0.97   0.85   0.96   0.80   0.80 ## biweekly    0.99   0.92   0.96   0.94   0.99   0.95   0.79   0.93   0.72   0.72 ## monthly     0.97   0.89   0.92   0.88   0.99   0.92   0.71   0.87   0.59   0.59 ## quarterly   0.90   0.85   0.85   0.71   0.96   0.81   0.52   0.71   0.38   0.40 ## yearly      0.69   0.69   0.54   0.31   0.85   0.38   0.15   0.38   0.08   0.15 ##           407365 407263 397335 407265 407256 416756 377425 397331 407224 416712 ## daily       0.98   1.00   0.99   1.00   1.00   0.99   1.00   0.99   0.99   1.00 ## weekly      0.93   0.99   0.96   0.98   1.00   0.98   0.99   0.98   0.95   0.99 ## biweekly    0.88   0.98   0.92   0.97   0.99   0.97   0.97   0.96   0.90   0.99 ## monthly     0.78   0.95   0.84   0.93   0.99   0.94   0.94   0.91   0.80   0.97 ## quarterly   0.60   0.87   0.71   0.87   0.98   0.83   0.88   0.81   0.58   0.90 ## yearly      0.23   0.46   0.38   0.46   0.85   0.46   0.69   0.54   0.08   0.77 ##           397264 387443 387324 377134 407234 407356 407355 407336 387154 407335 ## daily       1.00   1.00   0.99   1.00   0.99   0.98   0.99   0.99   1.00   1.00 ## weekly      1.00   0.99   0.94   1.00   0.96   0.94   0.95   0.97   1.00   0.99 ## biweekly    1.00   0.99   0.90   1.00   0.92   0.89   0.90   0.94   1.00   0.98 ## monthly     0.99   0.97   0.82   0.99   0.86   0.81   0.83   0.91   0.99   0.95 ## quarterly   0.98   0.90   0.69   0.98   0.63   0.63   0.65   0.81   0.98   0.87 ## yearly      0.92   0.77   0.38   0.92   0.23   0.38   0.38   0.54   0.92   0.69 ##           387466 407345 397342 417014 407316 387465 416843 417016 416854 397466 ## daily       0.99   0.99   0.99   1.00   1.00   0.97   1.00   1.00   1.00   1.00 ## weekly      0.96   0.97   0.98   1.00   1.00   0.91   0.99   0.99   0.99   0.99 ## biweekly    0.93   0.94   0.96   1.00   0.99   0.85   0.98   0.99   0.99   0.99 ## monthly     0.87   0.90   0.94   0.99   0.99   0.78   0.95   0.97   0.97   0.98 ## quarterly   0.77   0.75   0.85   0.98   0.96   0.65   0.88   0.92   0.92   0.94 ## yearly      0.46   0.46   0.62   0.92   0.85   0.38   0.62   0.77   0.85   0.85 ##           397343 416656 426726 417026 407225 396741 416934 397321 387446 387442 ## daily       0.99   1.00   1.00   1.00   0.99   1.00   1.00   1.00   0.99   1.00 ## weekly      0.98   1.00   1.00   1.00   0.95   1.00   1.00   0.99   0.97   1.00 ## biweekly    0.96   1.00   0.99   0.99   0.91   1.00   0.99   0.98   0.95   0.99 ## monthly     0.92   0.99   0.99   0.99   0.82   0.99   0.98   0.96   0.90   0.99 ## quarterly   0.79   0.98   0.96   0.94   0.60   0.98   0.94   0.92   0.79   0.96 ## yearly      0.54   0.92   0.85   0.85   0.23   0.92   0.77   0.62   0.54   0.85 ##           407346 406843 406723 397312 406833 406941 407255 397333 416746 387023 ## daily       0.98   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      0.93   1.00   0.99   1.00   0.99   0.99   0.99   0.99   1.00   0.99 ## biweekly    0.89   0.99   0.98   0.99   0.98   0.99   0.98   0.97   1.00   0.99 ## monthly     0.82   0.98   0.96   0.98   0.95   0.97   0.95   0.95   0.99   0.98 ## quarterly   0.67   0.94   0.88   0.94   0.90   0.92   0.90   0.87   0.98   0.94 ## yearly      0.38   0.77   0.62   0.77   0.62   0.69   0.69   0.54   0.92   0.85 ##           387262 407344 377453 387456 387444 407213 377441 377442 377451 377431 ## daily       1.00   1.00   1.00   0.97   1.00   1.00   0.99   0.98   0.99   1.00 ## weekly      1.00   1.00   1.00   0.89   1.00   1.00   0.96   0.93   0.97   0.99 ## biweekly    0.99   1.00   0.99   0.84   0.99   1.00   0.94   0.89   0.95   0.98 ## monthly     0.99   0.99   0.99   0.78   0.99   0.99   0.89   0.82   0.90   0.96 ## quarterly   0.96   0.98   0.96   0.62   0.96   0.98   0.73   0.65   0.77   0.92 ## yearly      0.85   0.92   0.85   0.38   0.85   0.92   0.54   0.31   0.54   0.77 ##           397362 377423 377434 377322 377213 387436 367413 377332 407354 387213 ## daily       0.98   0.99   0.99   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      0.94   0.97   0.96   1.00   1.00   0.99   1.00   0.99   0.99   0.99 ## biweekly    0.89   0.95   0.93   1.00   1.00   0.99   1.00   0.99   0.97   0.99 ## monthly     0.80   0.89   0.88   0.99   0.99   0.97   0.99   0.97   0.94   0.97 ## quarterly   0.56   0.79   0.73   0.98   0.98   0.94   0.98   0.92   0.87   0.94 ## yearly      0.15   0.62   0.62   0.92   0.92   0.85   0.92   0.69   0.62   0.77 ##           377433 407333 377432 397315 397332 387315 377362 377012 416766 387345 ## daily       0.98   1.00   0.99   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      0.94   1.00   0.96   0.99   1.00   0.99   1.00   1.00   0.99   1.00 ## biweekly    0.91   1.00   0.94   0.99   0.99   0.98   1.00   1.00   0.98   0.99 ## monthly     0.86   0.99   0.91   0.97   0.99   0.95   0.99   0.99   0.96   0.99 ## quarterly   0.77   0.98   0.83   0.94   0.96   0.92   0.98   0.98   0.88   0.96 ## yearly      0.54   0.92   0.69   0.77   0.85   0.77   0.92   0.92   0.62   0.85 ##           416744 416765 416616 416626 407053 416635 416615 416625 416755 416751 ## daily       1.00   1.00   0.98   0.98   1.00   0.98   0.99   0.99   1.00   1.00 ## weekly      1.00   0.99   0.94   0.94   1.00   0.93   0.97   0.98   1.00   1.00 ## biweekly    1.00   0.98   0.91   0.92   1.00   0.91   0.96   0.96   0.99   1.00 ## monthly     0.99   0.97   0.88   0.88   0.99   0.84   0.92   0.91   0.99   0.99 ## quarterly   0.98   0.92   0.75   0.81   0.98   0.79   0.87   0.83   0.96   0.98 ## yearly      0.92   0.69   0.38   0.54   0.92   0.54   0.62   0.54   0.85   0.92 ##           406842 416636 416726 406954 406711 416862 377435 377422 387425 416844 ## daily       1.00   0.99   1.00   0.99   1.00   1.00   1.00   1.00   1.00   0.99 ## weekly      1.00   0.97   1.00   0.95   1.00   0.98   0.99   0.99   1.00   0.97 ## biweekly    0.99   0.96   1.00   0.93   0.99   0.97   0.99   0.99   0.99   0.95 ## monthly     0.99   0.92   0.99   0.90   0.98   0.95   0.97   0.97   0.98   0.89 ## quarterly   0.98   0.85   0.98   0.83   0.94   0.88   0.94   0.92   0.96   0.75 ## yearly      0.92   0.62   0.92   0.69   0.77   0.62   0.77   0.69   0.85   0.38 ##           377312 387416 377444 387445 377446 416722 407212 377461 407361 387441 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      1.00   1.00   0.99   1.00   1.00   1.00   1.00   0.99   1.00   1.00 ## biweekly    1.00   1.00   0.99   0.99   0.99   0.99   0.99   0.99   0.99   1.00 ## monthly     0.99   0.99   0.97   0.99   0.99   0.99   0.99   0.98   0.99   0.99 ## quarterly   0.98   0.98   0.92   0.96   0.96   0.96   0.96   0.96   0.98   0.98 ## yearly      0.92   0.92   0.69   0.85   0.85   0.85   0.85   0.85   0.92   0.92 ##           387344 367322 387336 377443 377424 377452 407364 387423 387233 416923 ## daily       1.00   1.00   1.00   1.00   0.99   0.99   0.99   1.00   1.00   1.00 ## weekly      1.00   1.00   1.00   0.98   0.97   0.98   0.97   0.99   1.00   0.98 ## biweekly    0.99   0.99   0.99   0.98   0.96   0.97   0.95   0.99   1.00   0.96 ## monthly     0.99   0.99   0.99   0.95   0.93   0.95   0.89   0.97   0.99   0.92 ## quarterly   0.96   0.96   0.96   0.90   0.90   0.88   0.75   0.94   0.98   0.77 ## yearly      0.85   0.85   0.85   0.77   0.77   0.69   0.54   0.77   0.92   0.38 ##           377321 397456 387325 417366 397436 387334 357561 377352 387211 416913 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      1.00   1.00   0.99   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## biweekly    1.00   1.00   0.99   1.00   1.00   0.99   1.00   1.00   1.00   1.00 ## monthly     0.99   0.99   0.98   0.99   0.99   0.98   0.99   0.99   0.99   0.99 ## quarterly   0.98   0.98   0.94   0.98   0.98   0.96   0.98   0.98   0.98   0.98 ## yearly      0.92   0.92   0.85   0.92   0.92   0.85   0.92   0.92   0.92   0.92 ##           407023 406942 387346 407122 407012 397464 407262 407111 397313 397311 ## daily       1.00   1.00   1.00   0.99   1.00   1.00   0.99   1.00   1.00   1.00 ## weekly      1.00   0.99   1.00   0.98   1.00   1.00   0.98   0.99   1.00   1.00 ## biweekly    0.99   0.99   1.00   0.96   0.99   1.00   0.95   0.98   1.00   1.00 ## monthly     0.99   0.97   0.99   0.93   0.98   0.99   0.92   0.96   0.99   0.99 ## quarterly   0.98   0.92   0.98   0.83   0.96   0.98   0.79   0.92   0.98   0.98 ## yearly      0.92   0.77   0.92   0.54   0.85   0.92   0.46   0.77   0.92   0.92 ##           407021 407261 407253 406956 407242 387225 417146 397322 377454 377456 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      1.00   1.00   0.99   0.99   1.00   1.00   0.99   1.00   1.00   1.00 ## biweekly    1.00   0.99   0.99   0.98   1.00   0.99   0.99   0.99   1.00   1.00 ## monthly     0.99   0.99   0.97   0.96   0.99   0.99   0.97   0.98   0.99   0.99 ## quarterly   0.98   0.96   0.92   0.90   0.98   0.96   0.92   0.94   0.98   0.98 ## yearly      0.92   0.85   0.69   0.69   0.92   0.85   0.77   0.77   0.92   0.92 ##           357352 407325 377462 407252 407266 397462 397224 387362 416833 406821 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   0.99   1.00   1.00   1.00 ## weekly      1.00   1.00   1.00   0.98   1.00   1.00   0.96   1.00   1.00   0.98 ## biweekly    1.00   0.99   1.00   0.97   0.99   0.99   0.93   1.00   1.00   0.98 ## monthly     0.99   0.98   0.99   0.93   0.99   0.99   0.86   0.99   0.99   0.96 ## quarterly   0.98   0.94   0.98   0.87   0.96   0.96   0.71   0.98   0.98   0.88 ## yearly      0.92   0.85   0.92   0.69   0.85   0.85   0.46   0.92   0.92   0.77 ##           397446 416965 357331 386961 416634 406816 416614 416624 416764 377411 ## daily       1.00   0.99   1.00   1.00   0.99   1.00   1.00   0.99   1.00   1.00 ## weekly      1.00   0.97   1.00   1.00   0.96   1.00   0.99   0.97   1.00   1.00 ## biweekly    1.00   0.94   1.00   1.00   0.94   0.99   0.99   0.96   1.00   1.00 ## monthly     0.99   0.89   0.99   0.99   0.89   0.99   0.97   0.93   0.99   0.99 ## quarterly   0.98   0.73   0.98   0.98   0.81   0.96   0.92   0.83   0.98   0.98 ## yearly      0.92   0.38   0.92   0.92   0.62   0.85   0.85   0.62   0.92   0.92 ##           397236 407243 407232 377346 387241 367444 377364 406766 417064 416645 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   0.99 ## weekly      1.00   0.98   1.00   1.00   1.00   1.00   1.00   1.00   1.00   0.98 ## biweekly    1.00   0.97   1.00   1.00   1.00   1.00   1.00   1.00   1.00   0.96 ## monthly     0.99   0.94   0.99   0.99   0.99   0.99   0.99   0.99   0.99   0.94 ## quarterly   0.98   0.87   0.98   0.98   0.98   0.98   0.98   0.98   0.98   0.88 ## yearly      0.92   0.69   0.92   0.92   0.92   0.92   0.92   0.92   0.92   0.69 ##           416936 416916 416724 406725 416852 396961 406826 406635 367261 357364 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      1.00   1.00   1.00   1.00   0.99   1.00   1.00   1.00   1.00   1.00 ## biweekly    0.99   1.00   1.00   1.00   0.99   1.00   0.99   0.99   1.00   1.00 ## monthly     0.98   0.99   0.99   0.99   0.98   0.99   0.99   0.99   0.99   0.99 ## quarterly   0.94   0.98   0.98   0.98   0.96   0.98   0.96   0.96   0.98   0.98 ## yearly      0.77   0.92   0.92   0.92   0.85   0.92   0.85   0.85   0.92   0.92 ##           416866 406932 416646 417015 367641 427056 416814 416943 416856 417013 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   0.99   1.00   1.00 ## weekly      1.00   1.00   1.00   1.00   1.00   0.99   1.00   0.97   1.00   0.99 ## biweekly    1.00   1.00   1.00   1.00   0.99   0.98   1.00   0.95   1.00   0.98 ## monthly     0.99   0.99   0.99   0.99   0.99   0.97   0.99   0.91   0.99   0.97 ## quarterly   0.98   0.98   0.98   0.98   0.96   0.90   0.98   0.79   0.98   0.92 ## yearly      0.92   0.92   0.92   0.92   0.85   0.62   0.92   0.69   0.92   0.69 ##           416942 406756 416963 406746 407353 416644 406944 407121 416721 417024 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   0.98   0.99   1.00   1.00 ## weekly      1.00   1.00   1.00   1.00   1.00   1.00   0.94   0.97   0.99   1.00 ## biweekly    1.00   1.00   1.00   1.00   1.00   0.99   0.91   0.95   0.99   0.99 ## monthly     0.99   0.99   0.99   0.99   0.99   0.99   0.89   0.92   0.97   0.99 ## quarterly   0.98   0.98   0.98   0.98   0.98   0.98   0.85   0.85   0.92   0.96 ## yearly      0.92   0.92   0.92   0.92   0.92   0.92   0.77   0.54   0.77   0.85 ##           406853 406631 416962 407466 407054 407132 407233 407114 417126 406966 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      1.00   1.00   1.00   1.00   1.00   1.00   1.00   0.99   1.00   0.99 ## biweekly    0.99   0.99   1.00   1.00   1.00   1.00   1.00   0.99   1.00   0.99 ## monthly     0.98   0.99   0.99   0.99   0.99   0.99   0.99   0.97   0.99   0.98 ## quarterly   0.94   0.98   0.98   0.98   0.98   0.98   0.98   0.94   0.98   0.96 ## yearly      0.77   0.92   0.92   0.92   0.92   0.92   0.92   0.69   0.92   0.77 ##           407014 417154 407223 416813 406943 407133 416922 407123 407136 416951 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      1.00   1.00   0.99   1.00   0.99   1.00   1.00   0.99   1.00   1.00 ## biweekly    0.99   1.00   0.99   1.00   0.99   1.00   0.99   0.99   1.00   1.00 ## monthly     0.99   0.99   0.97   0.99   0.97   0.99   0.99   0.97   0.99   0.99 ## quarterly   0.96   0.98   0.90   0.98   0.92   0.98   0.96   0.92   0.98   0.98 ## yearly      0.85   0.92   0.69   0.92   0.85   0.92   0.92   0.77   0.92   0.92 ##           407115 387411 407031 416745 407251 416842 407241 416924 417164 416921 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      0.99   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## biweekly    0.99   0.99   0.99   1.00   1.00   0.99   1.00   1.00   1.00   0.99 ## monthly     0.98   0.98   0.99   0.99   0.99   0.99   0.99   0.99   0.99   0.99 ## quarterly   0.96   0.94   0.96   0.98   0.98   0.96   0.98   0.98   0.98   0.96 ## yearly      0.85   0.77   0.85   0.92   0.92   0.85   0.92   0.92   0.92   0.92 ##           416953 426725 387361 407151 406621 387655 406662 387214 407055 407051 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      1.00   1.00   0.99   0.99   1.00   1.00   1.00   1.00   1.00   1.00 ## biweekly    1.00   1.00   0.99   0.98   0.99   1.00   1.00   0.99   0.99   1.00 ## monthly     0.99   0.99   0.98   0.95   0.98   0.99   0.99   0.99   0.99   0.99 ## quarterly   0.98   0.98   0.96   0.87   0.96   0.98   0.98   0.96   0.96   0.98 ## yearly      0.92   0.92   0.92   0.77   0.85   0.92   0.92   0.85   0.92   0.92 ##           407161 427065 387422 387326 397324 427043 427066 387265 426961 397323 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      1.00   0.99   1.00   0.99   1.00   1.00   0.99   1.00   1.00   1.00 ## biweekly    0.99   0.99   1.00   0.99   0.99   1.00   0.99   1.00   1.00   0.99 ## monthly     0.99   0.97   0.99   0.97   0.98   0.99   0.97   0.99   0.99   0.99 ## quarterly   0.96   0.96   0.98   0.96   0.96   0.98   0.96   0.98   0.98   0.96 ## yearly      0.85   0.85   0.92   0.85   0.92   0.92   0.92   0.92   0.92   0.85 ##           427054 406734 387264 377323 406713 387355 407124 387224 387234 377311 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      0.99   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## biweekly    0.99   1.00   1.00   1.00   1.00   0.99   0.99   1.00   1.00   1.00 ## monthly     0.99   0.99   0.99   0.99   0.99   0.99   0.99   0.99   0.99   0.99 ## quarterly   0.96   0.98   0.98   0.98   0.98   0.96   0.98   0.98   0.98   0.98 ## yearly      0.85   0.92   0.92   0.92   0.92   0.85   0.92   0.92   0.92   0.92 ##           387212 406743 407141 377242 417136 397234 407143 417156 417055 417116 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## weekly      1.00   1.00   0.99   1.00   1.00   1.00   1.00   1.00   1.00   1.00 ## biweekly    0.99   0.99   0.99   1.00   0.99   1.00   1.00   1.00   0.99   1.00 ## monthly     0.99   0.99   0.97   0.99   0.99   0.99   0.99   0.99   0.99   0.99 ## quarterly   0.96   0.96   0.94   0.98   0.96   0.98   0.98   0.98   0.96   0.98 ## yearly      0.85   0.85   0.85   0.92   0.85   0.92   0.92   0.92   0.92   0.92 ##           417166 387426 427044 427055 387356 387451 397256 406923 387244 387222 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   0.96   1.00   1.00 ## weekly      1.00   1.00   1.00   1.00   1.00   1.00   1.00   0.91   1.00   1.00 ## biweekly    1.00   1.00   0.99   1.00   0.99   1.00   1.00   0.89   1.00   1.00 ## monthly     0.99   0.99   0.99   0.99   0.99   0.99   0.99   0.88   0.99   0.99 ## quarterly   0.98   0.98   0.98   0.98   0.96   0.98   0.98   0.83   0.98   0.98 ## yearly      0.92   0.92   0.92   0.92   0.92   0.92   0.92   0.77   0.92   0.92 ##           387112 416743 407153 357322 387223 406825 406814 406933 406863 406753 ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   0.97   1.00   1.00 ## weekly      1.00   1.00   1.00   1.00   1.00   1.00   0.99   0.93   1.00   1.00 ## biweekly    1.00   1.00   1.00   1.00   1.00   1.00   0.99   0.92   1.00   0.99 ## monthly     0.99   0.99   0.99   0.99   0.99   0.99   0.98   0.90   0.99   0.99 ## quarterly   0.98   0.98   0.98   0.98   0.98   0.98   0.94   0.87   0.98   0.96 ## yearly      0.92   0.92   0.92   0.92   0.92   0.92   0.85   0.85   0.92   0.92 ##           406911 406745 406934 416824 406752 406935 406913 416865 417135 406924 ## daily       1.00   1.00   0.98   0.99   1.00   1.00   0.99   1.00   1.00   0.98 ## weekly      1.00   1.00   0.95   0.98   0.99   0.99   0.96   1.00   1.00   0.96 ## biweekly    1.00   1.00   0.92   0.96   0.99   0.99   0.95   1.00   1.00   0.95 ## monthly     0.99   0.99   0.90   0.95   0.98   0.98   0.94   0.99   0.99   0.93 ## quarterly   0.98   0.98   0.88   0.90   0.94   0.98   0.92   0.98   0.98   0.92 ## yearly      0.92   0.92   0.85   0.85   0.85   0.92   0.85   0.92   0.92   0.92 ##           406945 387122 406914 387263 426946 387433 406925 406955 All_zones ## daily       1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00         0 ## weekly      0.99   1.00   1.00   1.00   1.00   1.00   1.00   1.00         0 ## biweekly    0.99   1.00   0.99   1.00   1.00   1.00   1.00   1.00         0 ## monthly     0.97   0.99   0.99   0.99   0.99   0.99   0.99   0.99         0 ## quarterly   0.96   0.98   0.98   0.98   0.98   0.98   0.98   0.98         0 ## yearly      0.92   0.92   0.92   0.92   0.92   0.92   0.92   0.92         0 sparsplot('scallopMod') ## `geom_smooth()` using formula = 'y ~ x' ## `geom_smooth()` using formula = 'y ~ x'"},{"path":"/articles/scallop-mod-example.html","id":"create-centroids","dir":"Articles","previous_headings":"Introduction","what":"Create Centroids","title":"Scallop Conditional Logit Model Example","text":"centroid table needed create distance matrix. can used choice occasion alternative choice. simplest way create zonal centroid table passing create_centroid(), saves centroids FishSET database.","code":"create_centroid(spat = scallopModTenMnSqrSpatTable,                 project = \"scallopMod\",                 spatID = \"TEN_ID\",                 type = \"zonal centroid\",                 output = \"centroid table\") ## Warning: st_centroid assumes attributes are constant over geometries ## Warning in find_centroid(spat = spatdat, project = project, spatID = spatID, : ## Duplicate centroids found for at least one zone. Using first centroid. ## Geographic centroid saved to fishSET database ## # A tibble: 4,537 × 3 ##    ZoneID cent.lon cent.lat ##     <dbl>    <dbl>    <dbl> ##  1      0    -73.3     45.8 ##  2 336411    -64.9     33.9 ##  3 336412    -64.7     33.9 ##  4 336413    -64.6     33.9 ##  5 336414    -64.4     33.9 ##  6 336415    -64.2     33.9 ##  7 336416    -64.1     33.9 ##  8 336421    -64.9     33.7 ##  9 336422    -64.7     33.7 ## 10 336423    -64.6     33.7 ## # ℹ 4,527 more rows"},{"path":"/articles/scallop-mod-example.html","id":"alternative-choice","dir":"Articles","previous_headings":"Introduction","what":"Alternative Choice","title":"Scallop Conditional Logit Model Example","text":"example, alternative choice list use longitude latitude disembarking port (previous_port_lon previous_port_lat) choice occasion zonal centroid fishing areas alternative. minimum haul haul requirement set 90.  plot visualizes zone frequency accounting minimum haul requirement alternative choice list.","code":"create_alternative_choice(dat = scallopModMainDataTable,                           project = \"scallopMod\",                           occasion = \"lon-lat\",                           occasion_var = c(\"previous_port_lon\", \"previous_port_lat\"),                           alt_var = \"zonal centroid\",                           zoneID = \"ZoneID\",                           zone.cent.name = \"scallopModZoneCentroid\",                           min.haul = 90                           ) ## Alternative choice list saved to FishSET database z_ind <- which(alt_choice_list('scallopMod')$dataZoneTrue == 1)  zOut <-    zone_summary(scallopModMainDataTable[z_ind, ],                 spat = scallopModTenMnSqrSpatTable,                 project = \"scallopMod\",                zone.dat = \"ZoneID\",                zone.spat = \"TEN_ID\",                output = \"tab_plot\") ## A line object has been specified, but lines is not in the mode ## Adding lines to the mode... pretty_tab(zOut$tab) zOut$plot"},{"path":"/articles/scallop-mod-example.html","id":"expected-catch","dir":"Articles","previous_headings":"Introduction","what":"Expected Catch","title":"Scallop Conditional Logit Model Example","text":"code chunk creates two different expected catch matrices: one using window seven days, lag one window 14 days, lag two. named user1 user2 respectively.  data must checked common data quality issues can used modeling functions (.e. make_model_design() discretefish_subroutine()). check_model_data() saves new version primary data suffix _final added indicate table “final” state ready used modeling.","code":"# user1 expected catch matrix create_expectations(dat = scallopModMainDataTable,                     project = \"scallopMod\",                     catch = \"LANDED_thousands\",                      temp.var = \"DATE_TRIP\",                     temp.window = 7,                     temp.lag = 1,                     year.lag = 0,                     temporal = 'daily',                     empty.catch = NA,                     empty.expectation = 1e-04,                     default.exp = FALSE,                     replace.output = TRUE) ## Expected catch/revenue matrix saved to FishSET database # user2 expected catch matrix create_expectations(dat = scallopModMainDataTable,                     project = \"scallopMod\",                     catch = \"LANDED_thousands\",                      temp.var = \"DATE_TRIP\",                     temporal = \"daily\",                     temp.window = 14,                     temp.lag = 2,                     empty.catch = NA,                     empty.expectation = 1e-04,                     default.exp = FALSE,                     replace.output = FALSE) ## Expected catch/revenue matrix saved to FishSET database check_model_data(scallopModMainDataTable,                   project = \"scallopMod\",                   uniqueID = \"TRIPID\",                  latlon = c(\"DDLON\",\"DDLAT\"))"},{"path":"/articles/scallop-mod-example.html","id":"model-design","dir":"Articles","previous_headings":"Introduction","what":"Model Design","title":"Scallop Conditional Logit Model Example","text":"model design file run two conditional logit models, using one expected catch matrices created earlier (specified using 'individual' expectcatchmodels argument).","code":"make_model_design(project = \"scallopMod\",                   catchID = \"LANDED_thousands\",                   likelihood = \"logit_c\",                   initparams = c(0, 0),                   vars1 = NULL,                   vars2 = NULL,                   mod.name = 'lz',                    expectcatchmodels = list('individual')                   ) ## Warning: CRS is not specfied, distance matrix will be created using WGS 84 ## (4326). ## Model design file done"},{"path":"/articles/scallop-mod-example.html","id":"run-models","dir":"Articles","previous_headings":"Introduction","what":"Run Models","title":"Scallop Conditional Logit Model Example","text":"Use discretefish_subroutine() run models model design file.  Use model_params() see model output. user1 user2 expected catch parameters V1 travel distance parameter. reasonably specified model find positive coefficients user1 user2 negative coefficiencts V1. lz.exp1.exp2:  Compare model fit.","code":"discretefish_subroutine(project = \"scallopMod\", explorestarts = FALSE) ## 3 initial parameter values should be specified ## initial  value 807521.840187  ## iter   2 value 288722.921375 ## iter   3 value 279354.295467 ## iter   4 value 279273.182976 ## iter   5 value 138489.248628 ## iter   6 value 98290.376655 ## iter   7 value 50850.645393 ## iter   8 value 15181.408957 ## iter   9 value 14583.948698 ## iter  10 value 11474.221219 ## iter  11 value 11367.619835 ## iter  12 value 10937.786756 ## iter  13 value 10751.748190 ## iter  14 value 10689.222081 ## iter  15 value 10685.096229 ## iter  16 value 10685.073162 ## iter  17 value 10685.038918 ## iter  18 value 10685.038770 ## iter  19 value 10685.016218 ## iter  20 value 10685.016039 ## iter  20 value 10685.016038 ## iter  21 value 10685.013144 ## iter  21 value 10685.013144 ## iter  21 value 10685.013144 ## final  value 10685.013144  ## converged ##               [,1]          [,2]          [,3] ## [1,]  7.437669e-06 -5.165320e-06 -9.695235e-09 ## [2,] -5.165320e-06  7.231852e-06 -6.044901e-09 ## [3,] -9.695235e-09 -6.044901e-09  4.278647e-08 ## [1] 7.437669e-06 7.231852e-06 4.278647e-08 model_params(\"scallopMod\", output = 'print') model_fit_summary(\"scallopMod\")"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lisa Pfeiffer. Author, maintainer. Paul G Carvalho. Author. Anna Abelman. Author. Min-Yang Lee. Author. Melanie Harsch. Author. Bryce McManus. Author. Alan Haynie. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Alan Haynie, Melanie Harsch Bryce McManus (2021). FishSET: Spatial Economics Toolbox Fisheries. R package version 0.1.8. Haynie, ., M. Harsch, . B. McManus (2021) Introduction FishSET0.1.8. NOAA Fisheries, Alaska Fisheries Science Center, 7600 Sand Point Way NE, Seattle, WA 98115","code":"@Manual{,   title = {FishSET: Spatial Economics Toolbox for Fisheries},   author = {Alan Haynie and Melanie Harsch and Bryce McManus},   year = {2021},   note = {R package version 0.1.8}, } @Manual{,   title = {Introduction to FishSET0.1.8},   author = {Alan Haynie and Melanie Harsch and Bryce McManus},   year = {2021},   note = {R package version 0.1.8}, }"},{"path":"/index.html","id":"fishset-","dir":"","previous_headings":"","what":"Spatial Economics Toolbox for Fisheries","title":"Spatial Economics Toolbox for Fisheries","text":"Contact nmfs.fishset@noaa.gov questions regarding FishSET R package report issues.","code":""},{"path":"/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Spatial Economics Toolbox for Fisheries","text":"Spatial Economics Toolbox Fisheries (FishSET) set tools developed R package organizing visualizing data; developing, improving disseminating modeling best practices; simulating policy scenarios explore welfare consequences management decisions.","code":""},{"path":"/index.html","id":"github-install","dir":"","previous_headings":"","what":"GitHub Install","title":"Spatial Economics Toolbox for Fisheries","text":"Run following lines code R:","code":"# Install the package (see troubleshooting section below if this doesn't work) install.packages(\"pak\")  pak::pak(\"noaa-nwfsc/FishSET\")"},{"path":"/index.html","id":"local-install","dir":"","previous_headings":"","what":"Local Install","title":"Spatial Economics Toolbox for Fisheries","text":"team phasing local installs, team provide local install user install GitHub. install, run following lines R (remember replace path install_local() function actual file path computer): Directories: FishSET functions call data files SQLite FishSET database save output (log function calls, plot output, table output, notes, function messages) “Logs” folder “output” folder. FishSET database output folders assumed FishSET package directory. , location needs specified. Use loc specify directory location database loc2 specify location Log file. example, loc <- getwd().","code":"install.packages(\"devtools\") library(devtools) devtools::install_local(\"PATH/TO/Directory/Containing/FishSET\")"},{"path":"/index.html","id":"documentation-and-tutorials","dir":"","previous_headings":"","what":"Documentation and Tutorials","title":"Spatial Economics Toolbox for Fisheries","text":"Refer FishSET R Package User Manual package information, quickstart guides, troubleshooting tips.","code":""},{"path":"/index.html","id":"issues-and-bug-reports","dir":"","previous_headings":"","what":"Issues and Bug Reports","title":"Spatial Economics Toolbox for Fisheries","text":"Add issues GitHub https://github.com/noaa-nwfsc/FishSET/issues. contact nmfs.fishset@noaa.gov.","code":""},{"path":"/index.html","id":"id_-citation-","dir":"","previous_headings":"","what":"Citation","title":"Spatial Economics Toolbox for Fisheries","text":"use FishSET results publications, please cite package: Alan Haynie, Melanie Harsch, Bryce McManus, Allen Chen, Min-Yang Lee, Anna Abelman, Paul Carvalho, Lisa Pfeiffer (2024). FishSET: Spatial Economics Toolbox Fisheries. R package version 1.0.1.","code":""},{"path":"/index.html","id":"troubleshooting","dir":"","previous_headings":"","what":"Troubleshooting","title":"Spatial Economics Toolbox for Fisheries","text":"Run following line code, run remotes::install_github error appear last package installation interrupted, updated version R, probably situations aware . Locate delete “…/00LOCK-[packagename]” “[packagename]” folders library folder, displayed error message (can also done using unlink() function R), attempt reinstall problem package using install.packages(). FishSET problem package, follow steps install . first options work, try adding “–-lock” install options: “install.packages(INSTALL_opts = ‘–-lock’)” still doesn’t work, try using pacman::p_unlock(lib.lock=path_to_directory)","code":""},{"path":"/index.html","id":"disclaimer","dir":"","previous_headings":"","what":"Disclaimer","title":"Spatial Economics Toolbox for Fisheries","text":"repository scientific product official communication National Oceanic Atmospheric Administration, United States Department Commerce. NOAA GitHub project code provided ‘’ basis user assumes responsibility use. claims Department Commerce Department Commerce bureaus stemming use GitHub project governed applicable Federal law. reference specific commercial products, processes, services service mark, trademark, manufacturer, otherwise, constitute imply endorsement, recommendation favoring Department Commerce. Department Commerce seal logo, seal logo DOC bureau, shall used manner imply endorsement commercial product activity DOC United States Government.","code":""},{"path":"/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Spatial Economics Toolbox for Fisheries","text":"content created U.S. Government employees part official duties. content subject copyright United States (17 U.S.C. §105) public domain within United States America. Additionally, copyright waived worldwide MIT License.  U.S. Department Commerce | National Oceanographic Atmospheric Administration | NOAA Fisheries","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"License","title":"License","text":"project work United States government US federal employees Department Commerce part official duties. Software code created U.S. Government employees subject copyright United States (17 U.S.C. §105). United States/Department Commerce reserves rights seek obtain copyright protection countries United States Software authored entirety Department Commerce. end, Department Commerce hereby grants Recipient royalty-free, nonexclusive license use, copy, create derivative works Software outside United States. Additionally, waive copyright related rights work worldwide MIT License.","code":""},{"path":"/LICENSE.html","id":"mit-license","dir":"","previous_headings":"","what":"MIT License","title":"License","text":"Copyright (c) 2024 NWFSC FRAM Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/reference/aboutUI.html","id":null,"dir":"Reference","previous_headings":"","what":"UIs for entering general metadata — aboutUI","title":"UIs for entering general metadata — aboutUI","text":"UIs entering general metadata","code":""},{"path":"/reference/aboutUI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"UIs for entering general metadata — aboutUI","text":"","code":"aboutUI(id)"},{"path":"/reference/aboutUI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"UIs for entering general metadata — aboutUI","text":"id ID string matches corresponding server functions:  metaCreateLoadServ metaEditLoadServ  metaSaveServ.","code":""},{"path":"/reference/aboutUI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"UIs for entering general metadata — aboutUI","text":"module used metadata_gui function    FishSET app. creates text boxes general metadata.   include author, date created, confidentiality, date modified, version,    general description, source, collection method, intended use.","code":""},{"path":"/reference/accumarray.html","id":null,"dir":"Reference","previous_headings":"","what":"Accumarray function — accumarray","title":"Accumarray function — accumarray","text":"Accumarray function","code":""},{"path":"/reference/accumarray.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Accumarray function — accumarray","text":"","code":"accumarray(subs, val, sz = NULL, func = sum, fillval = 0)"},{"path":"/reference/accumarray.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Accumarray function — accumarray","text":"subs subs val val sz sz func set sum fillval set 0","code":""},{"path":"/reference/add_polygon.html","id":null,"dir":"Reference","previous_headings":"","what":"Add polygon to spatial data — add_polygon","title":"Add polygon to spatial data — add_polygon","text":"Add polygon spatial data","code":""},{"path":"/reference/add_polygon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add polygon to spatial data — add_polygon","text":"","code":"add_polygon(poly, spat, spat.id, new.id = NULL, combine = FALSE)"},{"path":"/reference/add_polygon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add polygon to spatial data — add_polygon","text":"poly valid polygon add spatial data. spat Spatial dataset add polygon . spat.id ID column spat. new.id ID new polygon. combine Whether use combine_zone. turn  intersections poly spat new polygons.  Note new polygon IDs derived spat new.id  used.","code":""},{"path":[]},{"path":"/reference/add_prompter.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper for prompter::add_prompt() — add_prompter","title":"Wrapper for prompter::add_prompt() — add_prompter","text":"Wrapper prompter::add_prompt()","code":""},{"path":"/reference/add_prompter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper for prompter::add_prompt() — add_prompter","text":"","code":"add_prompter(   ui_element,   position = \"bottom\",   message = NULL,   type = NULL,   size = NULL,   permanent = FALSE,   rounded = FALSE,   animate = TRUE,   bounce = FALSE,   arrow = TRUE,   shadow = TRUE )"},{"path":"/reference/add_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Add removed variables back into dataset - non-interactive version — add_vars","title":"Add removed variables back into dataset - non-interactive version — add_vars","text":"Add columns removed primary dataset back primary dataset.","code":""},{"path":"/reference/add_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add removed variables back into dataset - non-interactive version — add_vars","text":"","code":"add_vars(working_dat, raw_dat, vars, project)"},{"path":"/reference/add_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add removed variables back into dataset - non-interactive version — add_vars","text":"working_dat Primary data containing information hauls trips. Table FishSET database contains string `MainDataTable`. raw_dat Unmodified raw version primary dataset. character specifying table FishSET database containing string ‘MainDataTable’ date table created. vars Character string, variables raw_dat add back working_dat. project Character, name project. Parameter used generate meaningful table names FishSET database.","code":""},{"path":"/reference/add_vars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add removed variables back into dataset - non-interactive version — add_vars","text":"Add variables back dataset removed. removed variables obtained raw_dat merged working data based row identifier. row identifier created variable removed using select_vars function. row identifier used match raw data variables working_dat.","code":""},{"path":"/reference/add_vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add removed variables back into dataset - non-interactive version — add_vars","text":"","code":"if (FALSE) { add_vars(pcodMainDataTable, \"pcodMainDataTable20200410\", \"pollock\") }"},{"path":"/reference/add_vars_gui.html","id":null,"dir":"Reference","previous_headings":"","what":"Add removed variables back into dataset — add_vars_gui","title":"Add removed variables back into dataset — add_vars_gui","text":"Add columns removed primary dataset back primary dataset.","code":""},{"path":"/reference/add_vars_gui.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add removed variables back into dataset — add_vars_gui","text":"","code":"add_vars_gui(working_dat, raw_dat, project)"},{"path":"/reference/add_vars_gui.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add removed variables back into dataset — add_vars_gui","text":"working_dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. raw_dat Unmodified raw version primary dataset. character specifying table FishSET database containing string ‘MainDataTable’ date table created. project String, name project.","code":""},{"path":"/reference/add_vars_gui.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add removed variables back into dataset — add_vars_gui","text":"Opens interactive table allows users select variables added back working dataset.  removed variables obtained raw_dat merged working data based row identifier. row identifier created variable removed using select_vars function. row identifier used match raw data variables working_dat.","code":""},{"path":"/reference/add_vars_gui.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add removed variables back into dataset — add_vars_gui","text":"","code":"if (FALSE) { select_vars_gui(pcodMainDataTable) add_vars_gui(pcodMainDataTable, 'pcodMainDataTable20100101', 'pcod') }"},{"path":"/reference/agg_helper.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregating function — agg_helper","title":"Aggregating function — agg_helper","text":"Aggregating function","code":""},{"path":"/reference/agg_helper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregating function — agg_helper","text":"","code":"agg_helper(   dataset,   value,   period = NULL,   group = NULL,   within_group = NULL,   fun = \"sum\",   count = FALSE,   format_tab = \"decimal\" )"},{"path":"/reference/agg_helper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregating function — agg_helper","text":"dataset `MainDataTable` aggregate. value String, name variable aggregate. period String, name period variable aggregate . Primarily  internal use. Places temporal variables right-end summary table. group String, name grouping variable(s) aggregate . within_group String, name grouping variable(s) calculating within group percentages. fun = \"percent\" period  group required. fun String, function name aggregate . Also accepts anonymous functions. calculate percentage, set fun = \"percent\"; return  percent total within_group = NULL. count Logical, TRUE returns number observations period /group. format_tab String. Options include \"decimal\" (default),  \"scientific\", \"PrettyNum\" (rounds two decimal places   uses commas).","code":""},{"path":"/reference/agg_helper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregating function — agg_helper","text":"","code":"if (FALSE) {  # total catch by port agg_helper(pollockMainDataTable, value = \"OFFICIAL_TOTAL_CATCH_MT\",             group = \"PORT_CODE\", fun = \"sum\")  # count permits agg_helper(pollockMainDataTable, value = \"PERMIT\", count = TRUE, fun = NULL)  # count permits by gear type agg_helper(pollockMainDataTable, value = \"PERMIT\", group = \"GEAR_TYPE\",            count = TRUE, fun = NULL)  # percent of total by gear type agg_helper(pollockMainDataTable, value = \"PERMIT\", group = \"GEAR_TYPE\",            count = TRUE, fun = \"percent\")   # within group percentage           agg_helper(pollockMainDataTable, value = \"OFFICIAL_TOTAL_CATCH_MT\",             fun = \"percent\", group = c(\"PORT_CODE\", \"GEAR_TYPE\"),             within_group = \"PORT_CODE\") }"},{"path":"/reference/alt_choice_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Alternative Choice List — alt_choice_list","title":"Get Alternative Choice List — alt_choice_list","text":"Returns Alternative Choice list FishSET database.","code":""},{"path":"/reference/alt_choice_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Alternative Choice List — alt_choice_list","text":"","code":"alt_choice_list(project, name = NULL)"},{"path":"/reference/alt_choice_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Alternative Choice List — alt_choice_list","text":"project Name project. name Name Alternative Choice list FishSET database.  table name contain string \"AltMatrix\". NULL,  default table returned. Use tables_database see list  FishSET database tables project.","code":""},{"path":"/reference/angled_theme.html","id":null,"dir":"Reference","previous_headings":"","what":"Set x-axis labels to 45 degrees — angled_theme","title":"Set x-axis labels to 45 degrees — angled_theme","text":"Set x-axis labels 45 degrees","code":""},{"path":"/reference/angled_theme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set x-axis labels to 45 degrees — angled_theme","text":"","code":"angled_theme()"},{"path":"/reference/assignment_column.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign each observation in the primary dataset to a fishery management or regulatory zone Assign each observation in the primary dataset to a fishery management or regulatory zone. Function is primarily called by other functions that require zone assignment but can also be used on its own. — assignment_column","title":"Assign each observation in the primary dataset to a fishery management or regulatory zone Assign each observation in the primary dataset to a fishery management or regulatory zone. Function is primarily called by other functions that require zone assignment but can also be used on its own. — assignment_column","text":"Assign observation primary dataset fishery management   regulatory zone Assign observation primary dataset fishery management   regulatory zone. Function primarily called functions   require zone assignment can also used .","code":""},{"path":"/reference/assignment_column.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign each observation in the primary dataset to a fishery management or regulatory zone Assign each observation in the primary dataset to a fishery management or regulatory zone. Function is primarily called by other functions that require zone assignment but can also be used on its own. — assignment_column","text":"","code":"assignment_column(   dat,   project,   spat,   lon.dat,   lat.dat,   cat,   name = \"ZoneID\",   closest.pt = FALSE,   bufferval = NULL,   lon.spat = NULL,   lat.spat = NULL,   hull.polygon = FALSE,   epsg = NULL,   log.fun = TRUE )"},{"path":"/reference/assignment_column.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign each observation in the primary dataset to a fishery management or regulatory zone Assign each observation in the primary dataset to a fishery management or regulatory zone. Function is primarily called by other functions that require zone assignment but can also be used on its own. — assignment_column","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project name project. spat Spatial data containing information fishery management  regulatory zones. sf objects recommended, sp objects can used well. using spatial table read csv file, arguments lon.spat lat.spat required. upload spatial data FishSETFolder see load_spatial. lon.dat Longitude variable dat. lat.dat Latitude variable dat. cat Variable list spat identifies individual areas  zones. spat class sf, cat name list  containing information zones. name name new assignment column. Defaults \"ZoneID\". closest.pt Logical, TRUE, observations fall outside  zones classed closest zone polygon point. bufferval Maximum buffer distance, meters, assigning observations  closest zone polygon. observation within defined  bufferval, assigned zone polygon.  Required closest.pt = TRUE. lon.spat Variable list spat containing longitude data.  Required spatial tables read csv files. Leave NULL  spat sf sp object. lat.spat Variable list spat containing latitude data.  Required spatial tables read csv files. Leave NULL  spat sf sp object. hull.polygon Logical, TRUE, creates convex hull polygon. Use  spatial data creating polygon sparse irregular. epsg EPSG code. Manually set epsg code, applied  spat dat. epsg specified defined  spat, spat epsg applied dat. addition, epsg specified epsg defined spat, default epsg value applied spat dat (epsg = 4326). See http://spatialreference.org/ help identify optimal epsg number. log.fun Logical, whether log function call (internal use).","code":""},{"path":"/reference/assignment_column.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign each observation in the primary dataset to a fishery management or regulatory zone Assign each observation in the primary dataset to a fishery management or regulatory zone. Function is primarily called by other functions that require zone assignment but can also be used on its own. — assignment_column","text":"Returns primary dataset new assignment column.","code":""},{"path":"/reference/assignment_column.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Assign each observation in the primary dataset to a fishery management or regulatory zone Assign each observation in the primary dataset to a fishery management or regulatory zone. Function is primarily called by other functions that require zone assignment but can also be used on its own. — assignment_column","text":"Function uses specified latitude longitude primary    dataset assign row primary dataset zone. Zone polygons    defined spatial dataset. Set hull.polygon TRUE    spatial data sparse irregular. Function called functions    zone identifier exist primary dataset.","code":""},{"path":"/reference/assignment_column.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign each observation in the primary dataset to a fishery management or regulatory zone Assign each observation in the primary dataset to a fishery management or regulatory zone. Function is primarily called by other functions that require zone assignment but can also be used on its own. — assignment_column","text":"","code":"if (FALSE) { pollockMainDataTable <-       assignment_column(pollockMainDataTable, \"pollock\", spat = pollockNMFSSpatTable,                        lon.dat = \"LonLat_START_LON\", lat.dat = \"LonLat_START_LAT\") }"},{"path":"/reference/bbox.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute bounding box for a dataframe with lon/lat columns. — bbox","title":"Compute bounding box for a dataframe with lon/lat columns. — bbox","text":"Compute bounding box dataframe lon/lat columns.","code":""},{"path":"/reference/bbox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute bounding box for a dataframe with lon/lat columns. — bbox","text":"","code":"bbox(dat, lon, lat, f = 0.05)"},{"path":"/reference/bbox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute bounding box for a dataframe with lon/lat columns. — bbox","text":"dat Dataframe containing longitude/latitude columns. lon Name Longitude column. lat Name Latitude column. f Number specifying fraction extend range.","code":""},{"path":"/reference/bin_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates numeric variables divided into equal sized groups — bin_var","title":"Creates numeric variables divided into equal sized groups — bin_var","text":"Creates numeric variables divided equal sized groups","code":""},{"path":"/reference/bin_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates numeric variables divided into equal sized groups — bin_var","text":"","code":"bin_var(dat, project, var, br, name = \"bin\", labs = NULL, ...)"},{"path":"/reference/bin_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates numeric variables divided into equal sized groups — bin_var","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. var Numeric variable dat bin factor. br Numeric vector. single number, range var divided br even groups. two values given, var divided intervals. name Variable name return. Defaults `bin`. labs character string category labels. ... Additional arguments passed cut.","code":""},{"path":"/reference/bin_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates numeric variables divided into equal sized groups — bin_var","text":"Returns primary dataset binned variable added.","code":""},{"path":"/reference/bin_var.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates numeric variables divided into equal sized groups — bin_var","text":"Function adds new factor variable, labeled name, primary dataset. numeric variable  divided equal sized groups length br equal one intervals  length br greater one.","code":""},{"path":"/reference/bin_var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates numeric variables divided into equal sized groups — bin_var","text":"","code":"if (FALSE) {  pollockMainDataTable <- bin_var(pollockMainDataTable, 'pollock', 'HAUL', 10, 'HAULCAT')  pollockMainDataTable <- bin_var(pollockMainDataTable, 'pollock', 'HAUL', c(5,10), 'HAULCAT') }"},{"path":"/reference/bycatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare bycatch CPUE and total catch/percent of total catch for one or more species — bycatch","title":"Compare bycatch CPUE and total catch/percent of total catch for one or more species — bycatch","text":"Compare bycatch CPUE total catch/percent total catch one  species","code":""},{"path":"/reference/bycatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare bycatch CPUE and total catch/percent of total catch for one or more species — bycatch","text":"","code":"bycatch(   dat,   project,   cpue,   catch,   date,   period = \"year\",   names = NULL,   group = NULL,   sub_date = NULL,   filter_date = NULL,   date_value = NULL,   filter_by = NULL,   filter_value = NULL,   filter_expr = NULL,   facet_by = NULL,   conv = \"none\",   tran = \"identity\",   format_lab = \"decimal\",   value = \"stc\",   combine = FALSE,   scale = \"fixed\",   output = \"tab_plot\",   format_tab = \"wide\" )"},{"path":"/reference/bycatch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare bycatch CPUE and total catch/percent of total catch for one or more species — bycatch","text":"dat Main data frame apply function. Table FishSET  database contain string `MainDataTable`. project name project. cpue string CPUE variable names. function outputs  mean CPUE period. variable names must match order variable  names catch names. catch character string names catch variables aggregate.  function outputs total catch share total catch period depending  value argument. order catch variable string must match  cpue names arguments. date variable containing dates aggregate . period Period aggregate . Options include 'year', month', weeks'. names optional string species names used plot. NULL, species names catch used. group categorical variable dat group . sub_date Date variable used subsetting, grouping, splitting date. filter_date type filter apply `MainDataTable`. filter  range dates, use filter_date = \"date_range\". filter given  period, use \"year-day\", \"year-week\", \"year-month\", \"year\", \"month\", \"week\",  \"day\". argument date_value must provided. date_value argument paired filter_date. filter date range, set filter_date = \"date_range\" enter  start-  end-date date_value string:  date_value = c(\"2011-01-01\", \"2011-03-15\"). filter period (e.g. \"year\", \"year-month\"), use integers (4 digits year, 1-2  digits referencing day, month, week). Use vector filtering  single period: date_filter = \"month\" date_value = c(1, 3, 5).  filter data January, March, May. Use list using year-period type filter, e.g. \"year-week\",  format: list(year, period). example, filter_date = \"year-month\" date_value = list(2011:2013, 5:7) filter data table  May July years 2011-2013. filter_by String, variable name filter `MainDataTable` . argument  filter_value must provided. filter_value vector values filter `MainDataTable` using  variable filter_by. example, filter_by = \"GEAR_TYPE\",  filter_value = 1 include observations gear type 1. filter_expr String, valid R expression filter `MainDataTable`  using variable filter_by. facet_by Variable name facet . Accepts two variables. Facetting  \"year\", \"month\", \"week\" available date variable  added sub_date. conv Convert catch variable \"tons\", \"metric_tons\",  using function entered string. Defaults \"none\" conversion. tran function transform y-axis. Options include log, log2, log10, sqrt. format_lab Formatting option y-axis labels. Options include  \"decimal\" \"scientific\". value Whether return raw catch (\"raw\") share total catch ('stc'). combine Logical, whether combine variables listed group. scale Scale argument passed facet_grid. Defaults  \"fixed\". options include \"free_y\", \"free_x\",  \"free_xy\". output Output type. Options include 'table' 'plot'. format_tab table output formatted. Options include 'wide' (default) 'long'.","code":""},{"path":"/reference/bycatch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare bycatch CPUE and total catch/percent of total catch for one or more species — bycatch","text":"bycatch() compares average CPUE catch total/share total   catch one species. data can filtered date /   variable. filter_date specifies type date filter apply--   date-range period. date_value contain values filter    data . filter variable, enter name string filter_by include values filter filter_value. one grouping    variable displayed; however, number variables can combined    using combine = TRUE, three recommended. faceting,    variable dataset can used, \"year\" \"month\" also available    provided date variable added sub_date. Generally,    four species compared, even fewer faceting due limited    plot space. list containing table plot printed console    viewer default. optimal plot size R Notebook/Markdown document,    use chunk option fig.asp = 1.","code":""},{"path":"/reference/bycatch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare bycatch CPUE and total catch/percent of total catch for one or more species — bycatch","text":"Returns plot /table mean CPUE share total catch   raw count species entered. optimal plot size R Notebook/Markdown   document, recommend including four species. order variables   cpue catch arguments must order   names argument. names argument used join catch   cpue variables together.","code":""},{"path":"/reference/bycatch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare bycatch CPUE and total catch/percent of total catch for one or more species — bycatch","text":"","code":"if (FALSE) { cpue(pollockMainDataTable, \"myproject\", xWeight = \"f1Weight\",   xTime = \"Hour\", \"f1_cpue\" )  bycatch(pollockMainDataTable, \"myproject\",          cpue = c(\"f1_cpue\", \"f2_cpue\", \"f3_cpue\", \"f4_cpue\"),         catch = c(\"f1\", \"f2\", \"f3\", \"f4\"), date = \"FISHING_START_DATE\",         names = c(\"fish_1\", \"fish_2\", \"fish_3\", \"fish_4\"), period = \"month\",         date_filter = \"year\", date_value = 2011, value = \"stc\",          output = \"table\") }"},{"path":"/reference/bycatch_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Bycatch plot helper — bycatch_plot","title":"Bycatch plot helper — bycatch_plot","text":"Creates formats plots bycatch.","code":""},{"path":"/reference/bycatch_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bycatch plot helper — bycatch_plot","text":"","code":"bycatch_plot(   dat,   cpue,   catch,   period,   group,   facet_by,   names,   value,   scale,   conv,   tran,   format_lab )"},{"path":"/reference/bycatch_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bycatch plot helper — bycatch_plot","text":"dat Data used create plot. cpue String, cpue variable(s) passed bycatch. catch String, catch variable(s) passed bycatch. period String, period passed bycatch. group String, grouping variable(s) passed bycatch. facet_by String, facet variable(s) passed bycatch. names String, species names plot labels passed bycatch. value String, whether return percent sum catch. scale String, facet scale passed bycatch. conv Convert catch variable \"tons\", \"metric_tons\",  using function entered string. Defaults \"none\"  conversion. tran String, scale transformation passed bycatch. format_lab Formatting option y-axis labels. Options include  \"decimal\" \"scientific\".","code":""},{"path":"/reference/cache_check_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Add check table to confidentiality cache list — cache_check_table","title":"Add check table to confidentiality cache list — cache_check_table","text":"Add check table confidentiality cache list","code":""},{"path":"/reference/cache_check_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add check table to confidentiality cache list — cache_check_table","text":"","code":"cache_check_table(check, project)"},{"path":"/reference/cache_check_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add check table to confidentiality cache list — cache_check_table","text":"check Dataframe, check table added confidentiality cache. project Name project.","code":""},{"path":"/reference/calc_exp.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate expected catch/revenue — calc_exp","title":"Calculate expected catch/revenue — calc_exp","text":"Calculate expected catch/revenue","code":""},{"path":"/reference/calc_exp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate expected catch/revenue — calc_exp","text":"","code":"calc_exp(   dataset,   catch,   price = NULL,   defineGroup = NULL,   temp.var = NULL,   temporal = \"daily\",   calc.method = \"standardAverage\",   lag.method = \"simple\",   empty.catch = NULL,   empty.expectation = NULL,   temp.window = 7,   temp.lag = 0,   year.lag = 0,   dummy.exp = FALSE,   weight_avg = FALSE,   Alt )"},{"path":"/reference/calc_exp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate expected catch/revenue — calc_exp","text":"dataset Data catch catch price price defineGroup define group temp.var temporal variable temporal temporal calc.method calculation method lag.method lag method empty.catch empty catch empty.expectation empty expectation temp.window temporal window temp.lag temporal lag year.lag year lag dummy.exp dummy matrix weight_avg weighted average Alt Alternative choice list","code":""},{"path":"/reference/calc_exp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate expected catch/revenue — calc_exp","text":"Returns list containing expected catch/revenue matrix,    dummy matrix (dummy.exp = TRUE), list input args.","code":""},{"path":"/reference/catch_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Model for Catch — catch_lm","title":"Linear Model for Catch — catch_lm","text":"First stage regression model catch.","code":""},{"path":"/reference/catch_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Model for Catch — catch_lm","text":"","code":"catch_lm(   dat,   project,   catch.formula,   zoneID = NULL,   exp.name = NULL,   new.name = NULL,   date,   output = \"matrix\" )"},{"path":"/reference/catch_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Model for Catch — catch_lm","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. catch.formula formula object specifying linear model.See stats::lm(). zoneID zone ID Variable dat identifies individual zones areas. Required merging expected catch dat using exp.name, creating new expected catch matrix  exp.name NULL (see output ). exp.name Name(s) expected catch matrix merge dat. new.name Optional, string. output = 'matrix', new.name become name new expected catch matrix saved FishSET DB expected catch list. output = 'dataset', new.name become name new expected catch variable added primary dataset. date Date variable dat used create expected catch matrix. output Whether output dat expected catch variable added ('dataset') save expected catch matrix expected catch FishSET DB table ('matrix'). Defaults output = 'matrix'.","code":""},{"path":"/reference/catch_lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear Model for Catch — catch_lm","text":"catch_lm() two output options: dataset matrix. output == 'dataset', primary dataset returned fitted values model added new column. new column named using new.name. output == 'matrix' expected catch matrix created saved FishSET DB expected catch list (outputted console). two ways create expected catch matrix: using existing expected catch matrix catch.formula, using zone-identifier column (.e. zoneID) catch.formula. example, created expected catch matrix named 'user1' using create_expectations(), catch.formula equal catch ~ vessel_length * user1. case exp.name equal 'user1'. Alternatively, create expected catch matrix specifying catch.formula catch ~ vessel_length * zone. case, exp.name = NULL zoneID = 'zone'.","code":""},{"path":"/reference/catch_lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear Model for Catch — catch_lm","text":"catch_lm() can merge expected catch matrix primary dataset running linear model. done using passing exp.name zoneID merge_expected_catch() convenience; users can separately using merge_expected_catch() desired, just make sure leave exp.name empty running catch_lm(). Merging expected catch separate step useful creating tables plots running first stage linear regression.","code":""},{"path":[]},{"path":"/reference/category_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Find categorical columns in data frame — category_cols","title":"Find categorical columns in data frame — category_cols","text":"Find categorical columns data frame","code":""},{"path":"/reference/category_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find categorical columns in data frame — category_cols","text":"","code":"category_cols(dat, out = \"names\")"},{"path":"/reference/category_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find categorical columns in data frame — category_cols","text":"dat MainDataTable, dataframe, list check. Whether return column \"names\" (default) logical vector  (\"logical\").","code":""},{"path":"/reference/category_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find categorical columns in data frame — category_cols","text":"","code":"if (FALSE) { category_cols(pollockMainDataTable) }"},{"path":"/reference/centroid_to_fsdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Save Primary Table's Centroid Columns to FishSET Database — centroid_to_fsdb","title":"Save Primary Table's Centroid Columns to FishSET Database — centroid_to_fsdb","text":"Save unique centroid values primary table FishSET Database. Use function zone ID centroid longitude/latitude included primary table.","code":""},{"path":"/reference/centroid_to_fsdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save Primary Table's Centroid Columns to FishSET Database — centroid_to_fsdb","text":"","code":"centroid_to_fsdb(   dat,   spat.name = NULL,   project,   zoneID,   cent.lon,   cent.lat,   type = \"zone\" )"},{"path":"/reference/centroid_to_fsdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save Primary Table's Centroid Columns to FishSET Database — centroid_to_fsdb","text":"dat Required, main data frame containing data hauls trips. Table FishSET database contain string MainDataTable. spat.name Optional, name associate centroid table. project Name project. zoneID Variable dat identifies individual zones areas. cent.lon Required, variable dat identifies centroid longitude zones areas. cent.lat Required, variable dat identifies centroid latitude  zones areas. type type centroid. Options include \"zone\" zonal centroids \"fish\" fishing centroids.","code":""},{"path":"/reference/centroid_to_fsdb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Save Primary Table's Centroid Columns to FishSET Database — centroid_to_fsdb","text":"certain cases, user may necessary spatial variables run discrete choice model included primary table uploaded FishSET, need spatial table assign observations zones find centroids (e.g. using create_centroid()). However, centroid table table must saved FishSET Database centroid option used define alternative choice (see create_alternative_choice()). cent_to_fsdb() allows users save zonal fishing centroid table provided required variables: zone ID (zoneID), centroid longitude (cent.lon), centroid latitude (cent.lat) column.","code":""},{"path":"/reference/change_class.html","id":null,"dir":"Reference","previous_headings":"","what":"Change variable data class — change_class","title":"Change variable data class — change_class","text":"View data class variable call appropriate functions change  data class needed.","code":""},{"path":"/reference/change_class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Change variable data class — change_class","text":"","code":"change_class(dat, project, x = NULL, new_class = NULL, save = FALSE)"},{"path":"/reference/change_class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Change variable data class — change_class","text":"dat Main data frame apply function. Table FishSET  database contain string `MainDataTable`. project Name project. x character string variable(s) dat changed  new_class. One ore variables may included. Default set NULL. new_class character string data classes x  changed . Length new_class match length x  unless variables x new_class. Defaults NULL. Options \"numeric\", \"factor\", \"date\", \"character\". Must quotes. save Logical. data table saved FishSET database,  replacing working data table database? Defaults FALSE.","code":""},{"path":"/reference/change_class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Change variable data class — change_class","text":"Table data class variable working data modified    data class specified.","code":""},{"path":"/reference/change_class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Change variable data class — change_class","text":"Returns table data class variable dat    changes variable classes. view variable classes run function default    settings, specifying dat project. variable class    changed, run function , specifying variable(s) (x)    changed new_class(es) (new_class). Set save    TRUE save modified data table.","code":""},{"path":"/reference/change_class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Change variable data class — change_class","text":"","code":"if (FALSE) { #View table without changing class or saving change_class(pollockMainDataTable, \"myproject\")  #Change class for a single variable and save data table to FishSET database change_class(pollockMainDataTable, \"myproject\", x = \"HAUL\", new_class = 'numeric', save=TRUE)  #Change class for multiple variables and save data table to FishSET database change_class(pollockMainDataTable, \"myproject\", x = c(\"HAUL\",\"DISEMBARKED_PORT\"),  new_class = c('numeric', 'factor'), save=TRUE) }"},{"path":"/reference/checklist.html","id":null,"dir":"Reference","previous_headings":"","what":"Model checklist — checklist","title":"Model checklist — checklist","text":"Determines whether final data passes quality checks, occurrence points checked, alternative choice matrix created, expected catch/revenue matrix required.","code":""},{"path":"/reference/checklist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model checklist — checklist","text":"","code":"checklist(project, modDesignTab = NULL)"},{"path":"/reference/checklist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model checklist — checklist","text":"project String, name project. modDesignTab model design table. used FishSET app.","code":""},{"path":"/reference/check_and_suppress.html","id":null,"dir":"Reference","previous_headings":"","what":"Check and suppress data — check_and_suppress","title":"Check and suppress data — check_and_suppress","text":"Check suppress data","code":""},{"path":"/reference/check_and_suppress.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check and suppress data — check_and_suppress","text":"","code":"check_and_suppress(   dat,   output,   project,   v_id,   value_var,   group = NULL,   rule,   value,   type = \"code\",   names_to = \"name\",   values_to = \"value\" )"},{"path":"/reference/check_and_suppress.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check and suppress data — check_and_suppress","text":"dat dataset used create summary table. must include  vessel identifier column. output output table suppressed. output = NULL,  dat used.  @param project Name project. v_id String, name vessel identifier column. value_var String, name(s) value variable(s). group String, name(s) grouping variable(s).  include `period` name summarizing time. rule String, confidentiality rule apply. rule = \"n\"  suppresses values containing fewer n vessels. rule = \"k\" ( \"majority allocation rule\") suppresses values single vessel contains  k percent total catch. value threshold confidentiality. rule = \"n\" must  integer least 3. rule = \"k\" double value 0 100. type String, value used replace confidential data. \"code\"  replaces values -999, \"NA\" (quotes) replaces  NA, \"zero\" replaces 0. names_to String, name column containing names value  variables `value_var` two columns. values_to String, name column containing values variables listed `names_to`.","code":""},{"path":"/reference/check_confidentiality.html","id":null,"dir":"Reference","previous_headings":"","what":"Create confidentiality check table — check_confidentiality","title":"Create confidentiality check table — check_confidentiality","text":"function checks confidential values summary table creates  table suppression conditions, \"check table\".","code":""},{"path":"/reference/check_confidentiality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create confidentiality check table — check_confidentiality","text":"","code":"check_confidentiality(   dataset,   project,   v_id,   value_var,   group = NULL,   rule = c(\"n\", \"k\"),   value,   names_to = \"name\",   values_to = \"value\" )"},{"path":"/reference/check_confidentiality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create confidentiality check table — check_confidentiality","text":"dataset dataset used create summary table. must include  vessel identifier column. project Name project. v_id String, name vessel identifier column. value_var String, name(s) value variable(s). group String, name(s) grouping variable(s).  include `period` name summarizing time. rule String, confidentiality rule apply. rule = \"n\"  suppresses values containing fewer n vessels. rule = \"k\" ( \"majority allocation rule\") suppresses values single vessel contains  k percent total catch. value threshold confidentiality. rule = \"n\" must  integer least 3. rule = \"k\" double value 0 100. names_to String, name column containing names value  variables value_var two columns. values_to String, name column containing values variables listed names_to.","code":""},{"path":"/reference/check_confid_par.html","id":null,"dir":"Reference","previous_headings":"","what":"Check confidentiality parameters — check_confid_par","title":"Check confidentiality parameters — check_confid_par","text":"Check confidentiality parameters","code":""},{"path":"/reference/check_confid_par.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check confidentiality parameters — check_confid_par","text":"","code":"check_confid_par(rule, value)"},{"path":"/reference/check_confid_par.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check confidentiality parameters — check_confid_par","text":"rule String, \"n\" rule n, \"k\" n/k. value Numeric, rule = \"n\" must integer least  2. rule = \"k\" numeric value 0 100.","code":""},{"path":"/reference/check_confid_par.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check confidentiality parameters — check_confid_par","text":"TRUE confidentiality parameters valid, FALSE .","code":""},{"path":"/reference/check_conf_rc.html","id":null,"dir":"Reference","previous_headings":"","what":"Check and suppress roll_catch output — check_conf_rc","title":"Check and suppress roll_catch output — check_conf_rc","text":"Check suppress roll_catch output","code":""},{"path":"/reference/check_conf_rc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check and suppress roll_catch output — check_conf_rc","text":"","code":"check_conf_rc(dat, roll_tab, project, catch, date, group, k, full_dates, align)"},{"path":"/reference/check_conf_rc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check and suppress roll_catch output — check_conf_rc","text":"dat Dataset used create roll_tab dataframe. roll_tab Unsuppressed table roll_catch. project Name project. catch String, name catch variable(s). date String, name date variable. group String, name group variable(s). k Integer, width window. full_dates Vector full dates. align String, align argument rollapply().","code":""},{"path":"/reference/check_exp.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare expected catch matrix — check_exp","title":"Prepare expected catch matrix — check_exp","text":"Checks specified expected catch matrices exists formatted correctly make_model_design called.","code":""},{"path":"/reference/check_exp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare expected catch matrix — check_exp","text":"","code":"check_exp(ec, ec_names)"},{"path":"/reference/check_exp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare expected catch matrix — check_exp","text":"ec Expected catch list created create_expectations. ec_names names expected catch matrices include model used (.e. used together separately). See expectcatchmodels argument make_model_design.","code":""},{"path":"/reference/check_exp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare expected catch matrix — check_exp","text":"Returns list containing filtered expected catch list specified   matrices include model.","code":""},{"path":"/reference/check_exp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prepare expected catch matrix — check_exp","text":"Checks ec_names specified properly identifying    invalid options combining 'individual' '' option    including matrices exist ec.","code":""},{"path":"/reference/check_model_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for common data quality issues affecting modeling functions — check_model_data","title":"Check for common data quality issues affecting modeling functions — check_model_data","text":"Check primary dataset NAs, NaNs, Inf, row    unique choice occurrence","code":""},{"path":"/reference/check_model_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for common data quality issues affecting modeling functions — check_model_data","text":"","code":"check_model_data(dat, project, uniqueID, latlon, save.file = TRUE)"},{"path":"/reference/check_model_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for common data quality issues affecting modeling functions — check_model_data","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project Project name. uniqueID Variable dat containing unique occurrence identifier. latlon Vector names variables lat, lon coordinates check. save.file Logical, TRUE data issues identified, dataset  saved FishSET database. Defaults TRUE.","code":""},{"path":"/reference/check_model_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for common data quality issues affecting modeling functions — check_model_data","text":"Returns statements data quality issues data. Saves table    FishSET database.","code":""},{"path":"/reference/check_model_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check for common data quality issues affecting modeling functions — check_model_data","text":"best check data NAs, NaNs Inf, row    unique choice occurrence data creation functions run    making model design file (make_model_design). steps    taken even data passed earlier data verification checks,    data quality issues can arise creation modification data. Model    functions may fail return inaccurate results data quality issues exist.    integrated data save issues dataset.    data passes tests, data saved FishSET database    prefix ‘final’. data index table also updated saved.","code":""},{"path":"/reference/check_model_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for common data quality issues affecting modeling functions — check_model_data","text":"","code":"if (FALSE) { check_model_data(MainDataTable, uniqueID = \"uniqueID_Code\", save.file = TRUE) }"},{"path":"/reference/check_proj.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for project folder. Create folders if required — check_proj","title":"Check for project folder. Create folders if required — check_proj","text":"Check project folder. Create folders required","code":""},{"path":"/reference/check_proj.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for project folder. Create folders if required — check_proj","text":"","code":"check_proj(project = NULL)"},{"path":"/reference/check_proj.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for project folder. Create folders if required — check_proj","text":"project Project name","code":""},{"path":"/reference/check_spatdat.html","id":null,"dir":"Reference","previous_headings":"","what":"Check and correct spatial data format — check_spatdat","title":"Check and correct spatial data format — check_spatdat","text":"Converts spatial data sf object","code":""},{"path":"/reference/check_spatdat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check and correct spatial data format — check_spatdat","text":"","code":"check_spatdat(spatdat, lon = NULL, lat = NULL, id = NULL)"},{"path":"/reference/check_spatdat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check and correct spatial data format — check_spatdat","text":"spatdat Spatial data containing information fishery management  regulatory zones. lon Longitude variable spatdat. required csv files  spatdat dataframe (.e. sf sp object). lat Latitude variable spatdat. required csv files  spatdat dataframe (.e. sf sp object). id Polygon ID column. required csv files spatdat  dataframe (.e. sf sp object).","code":""},{"path":"/reference/check_spatdat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check and correct spatial data format — check_spatdat","text":"function checks whether spatdat sf object   attempts convert . also applies clean_spat   fixes certain spatial issues invalid empty polygons,    whether projected CRS used (converts WGS84 detected),    longitude shifted Pacific view (0-360 format) avoid    splitting Alaska region plotting.","code":""},{"path":"/reference/choose_directory.html","id":null,"dir":"Reference","previous_headings":"","what":"Choose directory — choose_directory","title":"Choose directory — choose_directory","text":"Choose directory","code":""},{"path":"/reference/choose_directory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Choose directory — choose_directory","text":"","code":"choose_directory()"},{"path":"/reference/clean_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove unnecessary nested lists — clean_list","title":"Remove unnecessary nested lists — clean_list","text":"Recursively removes unnecessary lists (\"lame lists\") list. lame list unnamed list containing single list object (see lame_list).","code":""},{"path":"/reference/clean_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove unnecessary nested lists — clean_list","text":"","code":"clean_list(l)"},{"path":"/reference/clean_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove unnecessary nested lists — clean_list","text":"l list.","code":""},{"path":"/reference/clean_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove unnecessary nested lists — clean_list","text":"list.","code":""},{"path":[]},{"path":"/reference/clean_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove unnecessary nested lists — clean_list","text":"","code":"if (FALSE) { clean_list(list(list(1:10))) clean_list(list(A = list(1:10))) clean_list(list(list(1:10), list(11:20))) }"},{"path":"/reference/clean_spat.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean spatial data — clean_spat","title":"Clean spatial data — clean_spat","text":"Clean spatial data","code":""},{"path":"/reference/clean_spat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean spatial data — clean_spat","text":"","code":"clean_spat(spat)"},{"path":"/reference/clean_spat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean spatial data — clean_spat","text":"spat Spatial data check.","code":""},{"path":"/reference/clean_spat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Clean spatial data — clean_spat","text":"clean_spat extracts polygons \"GEOMETRYCOLLECTION\" spatial features, removes non-polygons data, attempts fix  invalid geometries, shifts longitude Pacific view points  less 0.","code":""},{"path":"/reference/close_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve closure scenario names — close_names","title":"Retrieve closure scenario names — close_names","text":"helper function used display names currently saved closure scenarios.","code":""},{"path":"/reference/close_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve closure scenario names — close_names","text":"","code":"close_names(project)"},{"path":"/reference/close_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve closure scenario names — close_names","text":"project Name project","code":""},{"path":"/reference/close_names.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve closure scenario names — close_names","text":"retrieve complete closure scenario file, use  get_closure_scenario.","code":""},{"path":"/reference/colDescUI.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a text box for each column in data — colDescUI","title":"Create a text box for each column in data — colDescUI","text":"Create text box column data","code":""},{"path":"/reference/colDescUI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a text box for each column in data — colDescUI","text":"","code":"colDescUI(id, nm, value = \"\")"},{"path":"/reference/colDescUI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a text box for each column in data — colDescUI","text":"id ID string matches corresponding server functions:  metaCreateLoadServ metaEditLoadServ  metaSaveServ. nm Column name passed textAreaInput id. value Value passed textAreaInput.","code":""},{"path":"/reference/colDescUI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a text box for each column in data — colDescUI","text":"module used metadata_gui function    FishSET app. creates text box column FishSET   table.","code":""},{"path":"/reference/collapse_leaf.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert vector to scalar — collapse_leaf","title":"Convert vector to scalar — collapse_leaf","text":"Collapses vector scalar. needed convert R list html list.","code":""},{"path":"/reference/collapse_leaf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert vector to scalar — collapse_leaf","text":"","code":"collapse_leaf(x)"},{"path":"/reference/collapse_leaf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert vector to scalar — collapse_leaf","text":"x vector object list.","code":""},{"path":"/reference/collapse_leaf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert vector to scalar — collapse_leaf","text":"character vector length 1.","code":""},{"path":"/reference/collapse_leaf_r.html","id":null,"dir":"Reference","previous_headings":"","what":"Recursively apply collapse_leaf() to a list object — collapse_leaf_r","title":"Recursively apply collapse_leaf() to a list object — collapse_leaf_r","text":"Recursively apply collapse_leaf() list object","code":""},{"path":"/reference/collapse_leaf_r.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recursively apply collapse_leaf() to a list object — collapse_leaf_r","text":"","code":"collapse_leaf_r(l)"},{"path":"/reference/collapse_leaf_r.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recursively apply collapse_leaf() to a list object — collapse_leaf_r","text":"l list","code":""},{"path":"/reference/collapse_leaf_r.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recursively apply collapse_leaf() to a list object — collapse_leaf_r","text":"list.","code":""},{"path":"/reference/column_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that column names exists — column_check","title":"Check that column names exists — column_check","text":"Check whether user supplied column names exist data.","code":""},{"path":"/reference/column_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that column names exists — column_check","text":"","code":"column_check(dat, cols)"},{"path":"/reference/column_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that column names exists — column_check","text":"dat data used function. cols String, column names used function.","code":""},{"path":"/reference/col_desc.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a list of column names Used to create a new metadata entry. — col_desc","title":"Create a list of column names Used to create a new metadata entry. — col_desc","text":"Create list column names Used create new metadata entry.","code":""},{"path":"/reference/col_desc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a list of column names Used to create a new metadata entry. — col_desc","text":"","code":"col_desc(dat)"},{"path":"/reference/col_desc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a list of column names Used to create a new metadata entry. — col_desc","text":"dat Dataframe","code":""},{"path":"/reference/combine_zone.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine zone and closure area — combine_zone","title":"Combine zone and closure area — combine_zone","text":"Creates new spatial dataset merges regulatory zones closure areas.","code":""},{"path":"/reference/combine_zone.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine zone and closure area — combine_zone","text":"","code":"combine_zone(spat, closure, grid.nm, closure.nm, recast = TRUE)"},{"path":"/reference/combine_zone.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine zone and closure area — combine_zone","text":"spat Spatial file containing regulatory zones. closure Closure file containing closure areas. grid.nm Character, column name containing grid ID. closure.nm Character, column name containing closure ID. recast Logical, TRUE combined passed  recast_multipoly.","code":""},{"path":"/reference/combine_zone.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Combine zone and closure area — combine_zone","text":"combine zones closure areas, function performs    following steps: Create union closure area Take difference closure union zone file Take intersection zone closure union Combine difference intersection objects one spatial        dataframe Assign new zone IDs intersecting polygons result single spatial dataset containing polygons spat   closure overlapping (intersecting) polygons receiving new   IDs (see new_zone_id). allows users partially close   regulatory zones model design stage.","code":""},{"path":[]},{"path":"/reference/confid_cache_exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidentialy cache exists — confid_cache_exists","title":"Confidentialy cache exists — confid_cache_exists","text":"Returns TRUE confidentiality cache file found project output folder.","code":""},{"path":"/reference/confid_cache_exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidentialy cache exists — confid_cache_exists","text":"","code":"confid_cache_exists(project)"},{"path":"/reference/confid_cache_exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidentialy cache exists — confid_cache_exists","text":"project Name project.","code":""},{"path":"/reference/confid_cache_exists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Confidentialy cache exists — confid_cache_exists","text":"","code":"if (FALSE) { confid_cache_exists(\"pollock\") }"},{"path":"/reference/contactUI.html","id":null,"dir":"Reference","previous_headings":"","what":"UIs for entering metadata contact info — contactUI","title":"UIs for entering metadata contact info — contactUI","text":"UIs entering metadata contact info","code":""},{"path":"/reference/contactUI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"UIs for entering metadata contact info — contactUI","text":"","code":"contactUI(id)"},{"path":"/reference/contactUI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"UIs for entering metadata contact info — contactUI","text":"id ID string matches corresponding server functions:  metaCreateLoadServ metaEditLoadServ  metaSaveServ.","code":""},{"path":"/reference/contactUI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"UIs for entering metadata contact info — contactUI","text":"module used metadata_gui function    FishSET app. creates text boxes contact info.   include person, organization, address, phone number, email, license,   citation, general purpose \"\" category.","code":""},{"path":"/reference/corr_out.html","id":null,"dir":"Reference","previous_headings":"","what":"View correlation coefficients between numeric variables — corr_out","title":"View correlation coefficients between numeric variables — corr_out","text":"Correlations coefficients can displayed numeric    variables selected numeric variables. Defaults pearson correlation    coefficient. change method, specify 'method'    'kendall', 'spearman'.    plot table output generated saved `output`     folder.","code":""},{"path":"/reference/corr_out.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View correlation coefficients between numeric variables — corr_out","text":"","code":"corr_out(   dat,   project,   variables = \"all\",   method = \"pearson\",   show_coef = FALSE )"},{"path":"/reference/corr_out.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View correlation coefficients between numeric variables — corr_out","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project String, project name. variables character string variables include. Defaults  \"\" numeric variables. method character string indicating correlation coefficient  computed. One \"pearson\" (default), \"kendall\", \"spearman\". show_coef Logical, whether include correlation coefficients  correlation plot. coefficients p-value less  equal 0.05 shown.","code":""},{"path":"/reference/corr_out.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"View correlation coefficients between numeric variables — corr_out","text":"Returns Pearson's correlation coefficient numeric variables    plot table format. Output saved output folder.","code":""},{"path":"/reference/corr_out.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View correlation coefficients between numeric variables — corr_out","text":"","code":"if (FALSE) { corr_out(pollockMainDataTable, 'pollock', 'all') }"},{"path":"/reference/corr_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Correlation plot — corr_plot","title":"Correlation plot — corr_plot","text":"Correlation plot","code":""},{"path":"/reference/corr_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correlation plot — corr_plot","text":"","code":"corr_plot(corr, p.val, show_coef, project)"},{"path":"/reference/corr_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correlation plot — corr_plot","text":"corr Correlation matrix p.val Correlation matrix p values. show_coef Whether show correlation coefficients. project Name project","code":""},{"path":"/reference/cpue.html","id":null,"dir":"Reference","previous_headings":"","what":"Create catch or revenue per unit effort variable — cpue","title":"Create catch or revenue per unit effort variable — cpue","text":"Add catch per unit effort (CPUE) revenue per unit effort    variable primary dataset. Catch weight variable can    count. Effort duration time, days, hours,    minutes.","code":""},{"path":"/reference/cpue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create catch or revenue per unit effort variable — cpue","text":"","code":"cpue(dat, project, xWeight = NULL, xTime, price = NULL, name = NULL)"},{"path":"/reference/cpue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create catch or revenue per unit effort variable — cpue","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project Project name. xWeight Catch variable dat. Variable measure  weight (pounds, metric tons, etc) can also count. calculating revenue per unit effort (RPUE) revenue column exists dat,  add revenue column price set xWeight = NULL. xTime Duration time variable dat representing effort,  weeks, days, hours, minutes. price Optional, variable dat containing price/value data.  Price multiplied catch variable, xWeight, generated  revenue. revenue exists dat wish use revenue  instead price, xWeight must NULL. Defaults  NULL. name String, name created variable. Defaults \"cpue\" \"rpue\"  price NULL.","code":""},{"path":"/reference/cpue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create catch or revenue per unit effort variable — cpue","text":"Returns primary dataset CPUE variable added.","code":""},{"path":"/reference/cpue.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create catch or revenue per unit effort variable — cpue","text":"Creates catch revenue per unit effort variable. Catch variable    weight (lbs, mts). Effort variable measurement    duration time. New variable added primary dataset    column name defined name argument. CPUE individual species   calculated separately.","code":""},{"path":"/reference/cpue.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create catch or revenue per unit effort variable — cpue","text":"","code":"if (FALSE) { pollockMainDataTable <- cpue(pollockMainDataTable, 'pollock',                               xWeight = 'OFFICIAL_TOTAL_CATCH_MT',                               xTime = 'DURATION_IN_MIN', name = 'cpue') }"},{"path":"/reference/create_alternative_choice.html","id":null,"dir":"Reference","previous_headings":"","what":"Define alternative fishing choice — create_alternative_choice","title":"Define alternative fishing choice — create_alternative_choice","text":"Required step. Creates list identifying alternative fishing choices defined. Output saved FishSET database. Run function running models. dat must zone assignment column (see assignment_column()). certain cases centroid table must saved FishSET Database, see occasion_var details.","code":""},{"path":"/reference/create_alternative_choice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define alternative fishing choice — create_alternative_choice","text":"","code":"create_alternative_choice(   dat,   project,   occasion = \"zonal centroid\",   occasion_var = NULL,   alt_var = \"zonal centroid\",   dist.unit = \"miles\",   min.haul = 0,   zoneID,   zone.cent.name = NULL,   fish.cent.name = NULL,   spat = NULL,   spatID = NULL,   outsample = FALSE )"},{"path":"/reference/create_alternative_choice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define alternative fishing choice — create_alternative_choice","text":"dat Required, main data frame containing data hauls trips. Table FishSET database contain string MainDataTable. project Required, name project. occasion String, determines starting point calculating distance matrix. Options \"zonal centroid\", \"fishing centroid\", \"port\", \"lon-lat\". See occasion_var requirements. occasion_var Identifies ID column set lon-lat variables needed create distance matrix. Possible options depend value occasion: Centroid occasion = zonal/fishing centroid possible options NULL, name zone ID variable, set coordinate variables (Lon-Lat order). NULL merge centroid lon-lat data primary table using column enter zoneID. centroid table must saved FishSET Database. Zone ID option specifies zone ID variable merge centroid table . example, column containing previous zonal area. centroid table must saved FishSET Database. Lon-Lat string vector length two containing longitude latitude existing set centroid variables dat. Port occasion = port possible options include name port ID variable set lon-lat variables describing location port. value NULL return error. Port ID name port ID variable dat used join port table primary table. port table required (see load_port()) contains port name longitude latitude port. Lon-Lat string vector length two containing port's longitude latitude dat. Lon-Lat occasion = lon-lat, occasion_var must contain string vector length two containing longitude latitude vessel's location dat. example, current previous haul location. alt_var Determines alternative choices used calculate distance matrix. alt_var may centroid zonal assignment (\"zonal centroid\"), \"fishing centroid\", closest point fishing zone (\"nearest point\"). centroid options require appropriate centroid table saved project's FishSET Database. See create_centroid() create save centroids. List existing centroid tables  running list_tables(\"project\", type = \"centroid\"). dist.unit String, distance measure returned. Choices \"meters\" \"m\", \"kilometers\" \"km\", \"miles\", \"nmiles\" (nautical miles). Defaults \"miles\". min.haul Required, numeric, minimum number hauls. Zones fewer hauls min.haul value included model data. zoneID Variable dat identifies individual zones areas. zone.cent.name name zonal centroid table use occasion alt_var set zonal centroid. Use list_tables(\"project\", type = \"centroid\") view existing centroid tables. See create_centroid() create centroid tables centroid_to_fsdb() create centroid table columns found dat. fish.cent.name name fishing centroid table use occasion alt_var set fishing centroid. Use list_tables(\"project\", type = \"centroid\") view existing centroid tables. See create_centroid() create centroid tables centroid_to_fsdb() create centroid table columns found dat. spat Required alt_var = 'nearest point'. spat spatial data file  containing information fishery management regulatory zones boundaries. sf objects recommended, sp objects can used well. See dat_to_sf() convert spatial table read csv file sf object. upload spatial data FishSETFolder see load_spatial().spat come FishSET database, name original file name, quotes. example, \"pollockNMFSZonesSpatTable\". Use tables_database() list_tables(\"project\", type = \"spat\") view names spatial tables FishSET database. spatID Required alt_var = 'nearest point'. Variable spat identifies individual zones areas. outsample Logical, indicating whether main data -sample data.","code":""},{"path":"/reference/create_alternative_choice.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define alternative fishing choice — create_alternative_choice","text":"Saves alternative choice list FishSET database list. Output includes:","code":""},{"path":"/reference/create_alternative_choice.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define alternative fishing choice — create_alternative_choice","text":"Defines alternative fishing choices. choices used develop matrix distances observed alternative fishing choices (fished ). distance matrix calculated make_model_design() function. occasion defines observed fishing location alt_var alternative fishing location. occasion_var identifies ID column set lon-lat variables needed create distance matrix. Parts alternative choice list pulled create_expectations(), make_model_design(), model run discretefish_subroutine()) functions. output include choices variable use catch zones include analyses based minimum number hauls per trip within zone. Note alternative choice list modified, create_expectations() make_model_design() functions also updated rerunning models.","code":""},{"path":"/reference/create_centroid.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Centroid Table — create_centroid","title":"Create Centroid Table — create_centroid","text":"Create zonal fishing centroid table. centroid can joined primary data output = \"dataset\". centroid table automatically saved FishSET Database.","code":""},{"path":"/reference/create_centroid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Centroid Table — create_centroid","text":"","code":"create_centroid(   spat = NULL,   dat = NULL,   project,   spatID = NULL,   zoneID = NULL,   lon.dat = NULL,   lat.dat = NULL,   weight.var = NULL,   type = \"zonal centroid\",   names = NULL,   cent.name = NULL,   output = \"dataset\" )"},{"path":"/reference/create_centroid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Centroid Table — create_centroid","text":"spat Spatial data containing information fishery management regulatory zones. Required type = \"zonal centroid\", required type = \"fishing centroid\". spat included centroid table name. dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. dat required type = \"zonal centroid\" output = \"centroid table\". project Name project. spatID Variable list spat identifies individual areas zones. spat class sf, spatID name list containing information zones. Ignored type = \"fishing centroid\". zoneID Variable dat identifies zonal assignments. zoneID required type = \"zonal centroid\" output = \"centroid table\". lon.dat Longitude variable dat. Required type = \"fishing centroid\". lat.dat Latitude variable dat. Required type = \"fishing centroid\". weight.var Variable dat weighted average (type = \"fishing centroid\". ). weight.var defined, centroid defined latitude longitude fishing locations zone weighted weight.var. type type centroid create. Options include \"zonal centroid\" \"fishing centroid\". See arguments type requirements. names Character vector length two containing names fishing centroid columns. order c(\"lon_name\", \"lat_name\"). default names c(\"weight_cent_lon\", \"weight_cent_lat\") weighted fishing centroid c(\"fish_cent_lon\", \"fish_cent_lat\") unweighted fishing centroid. cent.name string include centroid table name. Table names take form \"projectNameZoneCentroid\" zonal centroids \"projectNameFishCentroid\" fishing centroids. output Options \"centroid table\", \"dataset\", \"\". \"centroid table\" returns table containing zone name longitude latitude centroid. \"dataset\" returns primary table joined centroid table. \"\" returns list containing merged primary table centroid table.","code":""},{"path":"/reference/create_dist_between.html","id":null,"dir":"Reference","previous_headings":"","what":"Interactive application to create distance between points variable — create_dist_between","title":"Interactive application to create distance between points variable — create_dist_between","text":"Adds variable distance two points primary dataset. two versions   function. difference two versions additional arguments specific start end locations added.   version requires five arguments specified running. Additional arguments specific identifying   lat/lon start end points added prompts. function designed interactive session.   create_dist_between_for_gui function requires necessary arguments specified running   best used non-interactive session. versions distance function require start   end points different vectors. start ending points port PortTable must specified   obtain lat/lons. start ending points center fishing zone area spat, lon.dat,   lat.dat, cat, lon.spat, lat.spat must specified obtain latitude longitude.","code":""},{"path":"/reference/create_dist_between.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interactive application to create distance between points variable — create_dist_between","text":"","code":"create_dist_between(   dat,   project,   start,   end,   units = c(\"miles\", \"meters\", \"km\", \"midpoint\"),   zoneid = NULL,   name = \"distBetween\" )"},{"path":"/reference/create_dist_between.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interactive application to create distance between points variable — create_dist_between","text":"dat Primary data frame apply function. Table FishSET database contain string `MainDataTable`. project Project name. start, end Starting ending location. port, lat/lon location, fishery management zone/area centroid. area. port desired, start column name dat containing port Latitude longitude port extracted port table. lat/lon location desired start character string column names dat. order must lon, lat. fishery management centroid used set start=\"centroid\" end=\"centroid\". find_centroid assignment_column called identify latitude longitude  centroid table exist FishSET database. units Unit measurement calculated distance start ending points. Can \"miles\", \"meters\", \"kilometers\", \"midpoint\" location. zoneid Variable dat identifies individual zones areas. Define exists dat names `ZoneID`. name String, output variable name. Defaults `distBetween`.","code":""},{"path":"/reference/create_dist_between.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interactive application to create distance between points variable — create_dist_between","text":"Returns primary data set distance variable.","code":""},{"path":"/reference/create_dist_between.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interactive application to create distance between points variable — create_dist_between","text":"Additional arguments.  arguments required identify latitude longitude starting ending location start end defined zonal centroid column primary dataset containing port information, departing embarking port. Prompts appear asking required arguments.  Port arguments required: Centroids arguments required:","code":""},{"path":"/reference/create_dist_between.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interactive application to create distance between points variable — create_dist_between","text":"","code":"if (FALSE) { pollockMainDataTable <- create_dist_between(pollockMainDataTable, 'pollock', 'centroid',  'EMBARKED_PORT', units = 'miles', 'DistCentPort')  pollockMainDataTable <- create_dist_between(pollockMainDataTable, 'pollock', c('LonLat_START_LON',  'LonLat_START_LAT'), c('LonLat_END_LON','LonLat_END_LAT'), units='midpoint', 'DistLocLock')   pollockMainDataTable <- create_dist_between(pollockMainDataTable, 'pollock', 'DISEMBARKED_PORT',   'EMBARKED_PORT', units='meters', 'DistPortPort') }"},{"path":"/reference/create_dist_between_for_gui.html","id":null,"dir":"Reference","previous_headings":"","what":"Create distance between points variable - non-interactive version — create_dist_between_for_gui","title":"Create distance between points variable - non-interactive version — create_dist_between_for_gui","text":"Adds distance two points primary data set. two versions function. difference two versions   additional arguments specific start end locations added.   version requires necessary arguments specified running best used non-interactive session.   create_dist_between version requires five arguments specified running. Additional arguments   specific identifying lat/long start end points added prompts. function designed   interactive session. versions distance function require start end points different vectors.   start ending points port, PortTable must specified obtain lat/lons. start ending   points center fishing zone area spat, lon.dat, lat.dat, cat, lon.spat, lat.spat   must specified obtain latitude longitude.","code":""},{"path":"/reference/create_dist_between_for_gui.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create distance between points variable - non-interactive version — create_dist_between_for_gui","text":"","code":"create_dist_between_for_gui(   dat,   project,   start = c(\"lat\", \"lon\"),   end = c(\"lat\", \"lon\"),   units,   name = \"DistBetwen\",   portTable = NULL,   zoneid,   spat = NULL,   lon.dat = NULL,   lat.dat = NULL,   cat = NULL,   lon.spat = NULL,   lat.spat = NULL )"},{"path":"/reference/create_dist_between_for_gui.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create distance between points variable - non-interactive version — create_dist_between_for_gui","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name start, end Starting location. port, lat/lon location, centroid regulatory zone/area. units Unit distance. Choices \"miles\", \"kilometers\", \"midpoint\". name String, name new variable. Defaults `DistBetween`. portTable Data table containing port data. Required start end vector dat containing port names. zoneid Variable dat identifies individual zones areas. Required zone identifier variable exists  `ZoneID`. Defaults NULL. spat Spatial data containing information fishery management regulatory zones. Shape, json, geojson, csv formats supported.  Required start end \"centroid\" centroid table exist FishSET database. lon.dat Longitude variable dat. Required start end ‘centroid’. lat.dat Latitude variable dat. Required start end ‘centroid’. cat Variable list spat identifies individual areas zones. spat class sf, cat name list containing information zones. Required start end \"centroid\". lon.spat Variable list spat containing longitude data. Required csv files.  Leave NULL spat shape json file, Required start end \"centroid\". lat.spat Variable list spat containing latitude data. Required csv files. Leave NULL spat shape json file, Required start end \"centroid\".","code":""},{"path":"/reference/create_dist_between_for_gui.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create distance between points variable - non-interactive version — create_dist_between_for_gui","text":"Primary data set distance points variable added.","code":""},{"path":"/reference/create_dist_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the distance matrix — create_dist_matrix","title":"Create the distance matrix — create_dist_matrix","text":"Create distance matrix","code":""},{"path":"/reference/create_dist_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the distance matrix — create_dist_matrix","text":"","code":"create_dist_matrix(   dataset,   spat = NULL,   spatID = NULL,   alt_var,   occasion,   occasion_var = NULL,   dataZoneTrue,   zone_cent = NULL,   fish_cent = NULL,   choice,   units,   port = NULL,   zoneRow,   zoneID,   crs = NULL )"},{"path":"/reference/create_dist_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the distance matrix — create_dist_matrix","text":"dataset Primary data set spat Spatial table. spatID Column name Zone/area ID. alt_var Alternative choice location occasion Define choice location occasion_var Identify variable(s) needed define choice location. dataZoneTrue Include zone zone_cent Zonal centroid table. fish_cent Fishing centroid table. choice Choice zone units Distance units port Port table zoneRow Zone row zoneID Zone identifier crs Coordinate reference system.","code":""},{"path":"/reference/create_dist_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the distance matrix — create_dist_matrix","text":"Distance matrix based choices made create_alternative_choice","code":""},{"path":"/reference/create_dist_matrix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the distance matrix — create_dist_matrix","text":"Function called make_model_design generate    distance matrix. Alternative fishing options come Alternative Choice    list, generated create_alternative_choice function.","code":""},{"path":"/reference/create_duration.html","id":null,"dir":"Reference","previous_headings":"","what":"Create duration of time variable — create_duration","title":"Create duration of time variable — create_duration","text":"Create duration time variable based start ending dates desired temporal units.","code":""},{"path":"/reference/create_duration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create duration of time variable — create_duration","text":"","code":"create_duration(   dat,   project,   start,   end,   units = c(\"week\", \"day\", \"hour\", \"minute\"),   name = \"create_duration\" )"},{"path":"/reference/create_duration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create duration of time variable — create_duration","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. start Date variable dat indicating start time period. end Date variable dat indicating end time period. units String, unit time calculating duration. Must \"week\", \"day\", \"hour\", \"minute\". name String, name created vector. Defaults name function defined.","code":""},{"path":"/reference/create_duration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create duration of time variable — create_duration","text":"Returns primary dataset duration time variable added.","code":""},{"path":"/reference/create_duration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create duration of time variable — create_duration","text":"Calculates duration time two temporal variables based defined time unit. new variable added dataset. duration time variable required functions, cpue.","code":""},{"path":"/reference/create_duration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create duration of time variable — create_duration","text":"","code":"if (FALSE) { pollockMainDataTable <- create_duration(pollockMainDataTable, 'pollock', 'TRIP_START', 'TRIP_END',   units = 'minute', name = 'TripDur') }"},{"path":"/reference/create_expectations.html","id":null,"dir":"Reference","previous_headings":"","what":"Create expected catch/expected revenue matrix — create_expectations","title":"Create expected catch/expected revenue matrix — create_expectations","text":"Create expected catch expected revenue matrix. matrix required  logit_c model. Multiple user-defined matrices can saved setting replace.output = FALSE re-running function.","code":""},{"path":"/reference/create_expectations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create expected catch/expected revenue matrix — create_expectations","text":"","code":"create_expectations(   dat,   project,   catch,   price = NULL,   defineGroup = NULL,   temp.var = NULL,   temporal = \"daily\",   calc.method = \"standardAverage\",   lag.method = \"simple\",   empty.catch = NULL,   empty.expectation = 1e-04,   temp.window = 7,   temp.lag = 0,   year.lag = 0,   dummy.exp = FALSE,   default.exp = FALSE,   replace.output = TRUE,   weight_avg = FALSE,   outsample = FALSE )"},{"path":"/reference/create_expectations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create expected catch/expected revenue matrix — create_expectations","text":"dat Primary data containing information hauls trips. Table FishSET  database contains string 'MainDataTable'. project String, name project. catch Variable dat containing catch data. price Optional, variable dat containing price/value data. Price multiplied catch generated revenue. revenue exists  dat wish use revenue instead price, catch  must vector 1 length equal dat. Defaults NULL. defineGroup Optional, variable dat defines split  fleet. Defaults treating entire dataframe dat fleet. temp.var Optional, temporal variable dat. Set NULL  temporal patterns catch considered. temporal String, choices \"daily\" \"sequential\".  time, temp.var defined, included daily timeline sequential  order recorded dates. daily, catch dates record filled  NA. choice affects rolling average calculated.  temporal daily window size average temporal lag  days. sequential, averaging occur specified number  observations, regardless many days represent. calc.method String, catch values average window size. Select  standard average (\"standardAverage\"), simple lag regression means  (\"simpleLag\"), weights regressed groups (\"weights\") lag.method String, use regression entire group (\"simple\")  grouped time periods (\"grouped\"). empty.catch String, replace empty catch NA, 0, mean  catch (\"allCatch\"), mean grouped catch (\"groupCatch\"). empty.expectation Numeric, treat empty expectation values. Choices  replace (NULL) replace 0.0001 0. temp.window Numeric, temporal window size. temp.var NULL,  set window size average catch . Defaults 14 (14 days temporal  \"daily\"). temp.lag Numeric, temporal lag time. temp.var NULL,  far back lag temp.window. year.lag expected catch based catch previous year(s),  set year.lag number years go back. dummy.exp Logical, dummy variable created? TRUE,  output dummy variable originally missing value. FALSE, dummy  variable outputted. Defaults FALSE. default.exp Whether run default expectations. Defaults FALSE. Alternatively, character string containing names default expectations  run can entered. Options include \"recent\", \"older\", \"oldest\",  \"logbook\". logbook expectation run defineGroup used.  \"recent\" include defineGroup. Setting default.exp = TRUE include four options. See Details default expectations  defined. replace.output Logical, replace existing saved expected catch data frame  new expected catch data frame? FALSE, new expected catch data  frames appended previously saved expected catch data frames. Default  TRUE. TRUE weight_avg Logical, TRUE observations given zone  given date included calculating mean, thus giving  weight days observations given zone. FALSE,  daily mean zone calculated prior calculating mean across time window. outsample Logical, TRUE generate expected catch matrix  --sample data. FALSE generate main data table. Defaults outsample = FALSE","code":""},{"path":"/reference/create_expectations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create expected catch/expected revenue matrix — create_expectations","text":"Function saves list expected catch matrices FishSET database   projectExpectedCatch. list includes    expected catch matrix user-defined choices, recent fine grained   information, older fine grained information, oldest fine grained information,   logbook level information. Additional expected catch cases can added    list specifying replace.output = FALSE. list    automatically saved FishSET database called    make_model_design. expected catch output need    loaded defining running model. newGridVar,  newDumV","code":""},{"path":"/reference/create_expectations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create expected catch/expected revenue matrix — create_expectations","text":"Function creates expectation catch revenue alternative    fishing zones (zones fished ). output    saved FishSET database called make_model_design    function. create_alternative_choice must called first observed    catch zone inclusion requirements defined . primary choices    whether treat data fleet group data (defineGroup)    time frame catch data calculating expected catch. Catch averaged    along daily sequential timeline (temporal) using rolling average.    temp.window temp.lag determine window size temporal    lag window averaging. Use temp_obs_table using    function assess availability data desired temporal moving    window size. Sparse data suited shorter moving window sizes.    sparse data, consider setting temp.var NULL excluding    temporal patterns catch.    Empty catch values considered times fishing activity. Values    0 catch variable considered times fishing activity occurred    catch. points included averaging dummy creation    points time fishing occurred.    Four default expected catch cases run: recent: Moving window size two days. case,    grouping, catch entire fleet used. older: Moving window size seven days lag two days.    case, vessels grouped () based defineGroup argument. oldest: Moving window seven days lag eight days.    case, vessels grouped () based defineGroup argument. logbook: Moving window size 14 days lag one year, seven days.    used fleet defined defineGroup.","code":""},{"path":"/reference/create_expectations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create expected catch/expected revenue matrix — create_expectations","text":"","code":"if (FALSE) { create_expectations(pollockMainDataTable, \"pollock\", \"OFFICIAL_TOTAL_CATCH_MT\",   price = NULL, defineGroup = \"fleet\", temp.var = \"DATE_FISHING_BEGAN\",   temporal = \"daily\", calc.method = \"standardAverage\", lag.method = \"simple\",   empty.catch = \"allCatch\", empty.expectation = 0.0001, temp.window = 4,   temp.lag = 2, year.lag = 0, dummy.exp = FALSE, replace.output = FALSE,   weight_avg = FALSE, outsample = FALSE ) }"},{"path":"/reference/create_logit_input.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a data matrix consistent with built-in model forms — create_logit_input","title":"Creates a data matrix consistent with built-in model forms — create_logit_input","text":"Creates data matrix consistent built-model forms","code":""},{"path":"/reference/create_logit_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a data matrix consistent with built-in model forms — create_logit_input","text":"","code":"create_logit_input(choice)"},{"path":"/reference/create_logit_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a data matrix consistent with built-in model forms — create_logit_input","text":"choice dataframe single vector chosen locations length = number observations","code":""},{"path":"/reference/create_logit_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a data matrix consistent with built-in model forms — create_logit_input","text":"dataCompile: large data matrix.Number rows = number observations, number cols = square number alternatives.     row contains flattened identity matrix size = number alternatives x number alternatives.","code":""},{"path":"/reference/create_logit_input.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates a data matrix consistent with built-in model forms — create_logit_input","text":"Called discrete_fish_subroutine function","code":""},{"path":"/reference/create_mid_haul.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates haul midpoint latitude and longitude variables — create_mid_haul","title":"Creates haul midpoint latitude and longitude variables — create_mid_haul","text":"Calculates latitude longitude haul midpoint adds two variables primary data set: midpoint latitude midpoint longitude.","code":""},{"path":"/reference/create_mid_haul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates haul midpoint latitude and longitude variables — create_mid_haul","text":"","code":"create_mid_haul(   dat,   project,   start = c(\"lon\", \"lat\"),   end = c(\"lon\", \"lat\"),   name = \"mid_haul\" )"},{"path":"/reference/create_mid_haul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates haul midpoint latitude and longitude variables — create_mid_haul","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. start Character string, variables dat defining longitude latitude starting location haul. Must decimal degrees. end Character string, variables dat defining longitude latitude ending location haul.  Must decimal degrees. name String, name new variable. Defaults `mid_haul`.","code":""},{"path":"/reference/create_mid_haul.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates haul midpoint latitude and longitude variables — create_mid_haul","text":"Returns primary dataset two new variables added: latitude longitude haul midpoint.","code":""},{"path":"/reference/create_mid_haul.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates haul midpoint latitude and longitude variables — create_mid_haul","text":"row data must unique haul. Requires start end point observation.","code":""},{"path":"/reference/create_mid_haul.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates haul midpoint latitude and longitude variables — create_mid_haul","text":"","code":"if (FALSE) { pollockMainDataTable <- create_mid_haul(pollockMainDataTable, 'pollock',      start = c('LonLat_START_LON', 'LonLat_START_LAT'),     end = c('LonLat_END_LON', 'LonLat_END_LAT'), name = 'mid_haul') }"},{"path":"/reference/create_model_input.html","id":null,"dir":"Reference","previous_headings":"","what":"Create model input data — create_model_input","title":"Create model input data — create_model_input","text":"Takes structure data compile, price (EPM), distance, gridvarying,  interaction terms","code":""},{"path":"/reference/create_model_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create model input data — create_model_input","text":"","code":"create_model_input(   project,   x = NULL,   mod.name = NULL,   use.scalers = FALSE,   scaler.func = NULL,   expected.catch = NULL,   exp.names = NULL )"},{"path":"/reference/create_model_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create model input data — create_model_input","text":"project Project name x Optional, Model input data mod.name Optional, name model. Include building model data  specific defined model. use.scalers Logical, data normalized? Defaults FALSE.  Rescaling factors mean numeric vector unless specified  scaler.func. scaler.func Function calculate rescaling factors. expected.catch conditional logit. Expected catch matrices include exp.names names expected catch matrices use model. Specified make_model_design.","code":""},{"path":"/reference/create_model_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create model input data — create_model_input","text":"Returns list datacompile/choice matrix, dataCompile, distance,    otherdat, expname, choice, choice.table, mod.name","code":""},{"path":"/reference/create_proj_settings.html","id":null,"dir":"Reference","previous_headings":"","what":"Create FishSET project settings — create_proj_settings","title":"Create FishSET project settings — create_proj_settings","text":"function creates project settings file located project/doc folder.","code":""},{"path":"/reference/create_proj_settings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create FishSET project settings — create_proj_settings","text":"","code":"create_proj_settings(project)"},{"path":"/reference/create_proj_settings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create FishSET project settings — create_proj_settings","text":"project settings file contains confidentiality settings, file path  user output folder, plot size (width height  inches), table names used shiny app (logging purposes).","code":""},{"path":[]},{"path":"/reference/create_seasonal_ID.html","id":null,"dir":"Reference","previous_headings":"","what":"Create fishery season identifier variable — create_seasonal_ID","title":"Create fishery season identifier variable — create_seasonal_ID","text":"Create fishery season identifier variable","code":""},{"path":"/reference/create_seasonal_ID.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create fishery season identifier variable — create_seasonal_ID","text":"","code":"create_seasonal_ID(   dat,   project,   seasonal.dat,   use.location = c(TRUE, FALSE),   use.geartype = c(TRUE, FALSE),   sp.col,   target = NULL )"},{"path":"/reference/create_seasonal_ID.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create fishery season identifier variable — create_seasonal_ID","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. seasonal.dat Table containing date fishery season(s). Can pulled FishSET database. use.location Logical, fishery season dates depend fishery location? Column names containing location dat seasonal.dat must match. use.geartype Logical, fishery season dates depend gear type. Column names containing gear type dat seasonal.dat must match. sp.col Variable seasonal.dat containing species names. target Name target species. target NULL, runs fisheries order listed seasonal.dat","code":""},{"path":"/reference/create_seasonal_ID.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create fishery season identifier variable — create_seasonal_ID","text":"Returns primary dataset variable SeasonID, series variables identifying individual   fisheries included (seasonID*fishery).","code":""},{"path":"/reference/create_seasonal_ID.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create fishery season identifier variable — create_seasonal_ID","text":"Uses table fishery season dates create fishery season identifier variables. Output SeasonID variable /multiple SeasonID*fishery variables. fishery season dates vary location gear type, use.location use.geartype TRUE.  function matches fishery season dates provided seasonal.dat earliest date variable dat. `seasonID` variable vector fishery seasons whereas `SeasonID*fishery` variables 1/0 depending whether fishery open observed date.  target defined, row seasonID defined earliest fishery listed seasonal.dat fishery season date encompasses date variable primary dataset. target fishery defined, `SeasonID` defined whether target fishery open date primary dataset different fishery. vector filled 'target' ''. `SeasonID*fishery` variables 1/0 seasonID vector fishery (labeled seasonID fishery) 1 indicates dates given row main data table fall within fishery dates fishery.","code":""},{"path":"/reference/create_seasonal_ID.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create fishery season identifier variable — create_seasonal_ID","text":"","code":"if (FALSE) { pcodMainDataTable <- create_seasonal_ID(\"pcodMainDataTable\", seasonal_dat,   use.location = TRUE, use.geartype = TRUE, sp.col = \"SPECIES\", target = \"POLLOCK\" ) }"},{"path":"/reference/create_startingloc.html","id":null,"dir":"Reference","previous_headings":"","what":"Create starting location variable — create_startingloc","title":"Create starting location variable — create_startingloc","text":"Creates variable containing zone/area location vessel choice  fish next made. variable required full information  model Dahl's correction (logit_correction).","code":""},{"path":"/reference/create_startingloc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create starting location variable — create_startingloc","text":"","code":"create_startingloc(   dat,   project = NULL,   spat,   port,   port_name,   port_lon,   port_lat,   trip_id,   haul_order,   starting_port,   zoneID,   spatID,   name = \"startingloc\" )"},{"path":"/reference/create_startingloc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create starting location variable — create_startingloc","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Name project spat Spatial data. Required ZoneID exists dat. Shape, json, geojson, csv formats supported. port Port data. Contains columns: Port_Name, Port_Long, Port_Lat.  Table generated using load_port saved FishSET  database project port table, example 'pollockPortTable'. port_name Character string indicating column port table contains port name port_lon Character string indication column port table contains port longitude port_lat Character string indication column port table contains port latitude trip_id Variable dat identifies unique trips. haul_order Variable dat containing information order  hauls occur within trip. Can time, coded variable, etc. starting_port Variable dat identify port start trip. zoneID Variable dat identifies individual zones  areas. spatID Variable spat identifies individual zones  areas. name String, name created variable. Defaults name function  defined.","code":""},{"path":"/reference/create_startingloc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create starting location variable — create_startingloc","text":"Primary data set starting location variable added.","code":""},{"path":"/reference/create_startingloc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create starting location variable — create_startingloc","text":"Function creates startloc vector required    full information model Dahl's correction logit_correction.    vector zone location vessel decision fish    next made. Generally, first zone trip departure port.    assignment_column function called assign starting port    locations haul locations zones. ZoneID exists dat,    assignment_column called following arguments    required: spat, lon.dat, lat.dat, cat, lon.grid, lat.grid.","code":""},{"path":"/reference/create_startingloc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create starting location variable — create_startingloc","text":"","code":"if (FALSE) { pcodMainDataTable <- create_startingloc(pcodMainDataTable, 'pcod',     map2, \"pcodPortTable\", \"TRIP_SEQ\", \"HAUL_SEQ\", \"DISEMBARKED_PORT\",   \"START_LON\", \"START_LAT\", \"NMFS_AREA\", \"STARTING_LOC\" ) }"},{"path":"/reference/create_trip_centroid.html","id":null,"dir":"Reference","previous_headings":"","what":"Create trip centroid variable — create_trip_centroid","title":"Create trip centroid variable — create_trip_centroid","text":"Create latitude longitude variables containing centroid trip","code":""},{"path":"/reference/create_trip_centroid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create trip centroid variable — create_trip_centroid","text":"","code":"create_trip_centroid(dat, project, lon, lat, tripID, weight.var = NULL)"},{"path":"/reference/create_trip_centroid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create trip centroid variable — create_trip_centroid","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. lon Variable dat containing longitudinal data. lat Variable dat containing latitudinal data. tripID Variable dat containing trip identifier. trip identifier defined one variable list c('var1', 'var2'). weight.var Variable dat computing weighted average.","code":""},{"path":"/reference/create_trip_centroid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create trip centroid variable — create_trip_centroid","text":"Returns primary dataset centroid latitude centroid longitude variables added.","code":""},{"path":"/reference/create_trip_centroid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create trip centroid variable — create_trip_centroid","text":"Computes average longitude latitude trip. Specify weight.var calculate weighted centroid.   Additional arguments can added define unique trips. additional arguments added, row treated unique trip.","code":""},{"path":"/reference/create_trip_centroid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create trip centroid variable — create_trip_centroid","text":"","code":"if (FALSE) { pollockMainDataTable <- create_trip_centroid(pollockMainDataTable, 'pollock', 'LonLat_START_LON',    'LonLat_START_LAT', weight.var = NULL, 'DISEMBARKED_PORT', 'EMBARKED_PORT') }"},{"path":"/reference/create_trip_distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Create haul level trip distance variable — create_trip_distance","title":"Create haul level trip distance variable — create_trip_distance","text":"Create haul level trip distance variable","code":""},{"path":"/reference/create_trip_distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create haul level trip distance variable — create_trip_distance","text":"","code":"create_trip_distance(   dat,   project,   port,   trip_id,   starting_port,   starting_haul = c(\"Lon\", \"Lat\"),   ending_haul = c(\"Lon\", \"Lat\"),   ending_port,   haul_order,   name = \"TripDistance\",   a = 6378137,   f = 1/298.257223563 )"},{"path":"/reference/create_trip_distance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create haul level trip distance variable — create_trip_distance","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. port Port data frame. Contains columns: Port_Name, Port_Long, Port_Lat. Table generated using load_port function saved FishSET database project port, example 'pollockPortTable'. trip_id Unique trip identifier dat. starting_port Variable dat containing ports start trip. starting_haul Character string, variables containing latitude longitude start haul dat. ending_haul Character string, variables containing latitude longitude end haul dat. ending_port Variable dat containing ports end trip. haul_order Variable dat identifies haul order within trip. Can time, coded variable, etc. name String, name created variable. Defaults `TripDistance`. Numeric, major (equatorial) radius ellipsoid. default value WGS84 ellipsoid. f Numeric, ellipsoid flattening. default value WGS84 ellipsoid.","code":""},{"path":"/reference/create_trip_distance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create haul level trip distance variable — create_trip_distance","text":"Returns primary dataset trip distance variable added.","code":""},{"path":"/reference/create_trip_distance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create haul level trip distance variable — create_trip_distance","text":"Summation distance across trip based starting ending ports hauls . function uses distGeo geosphere package calculate distances  hauls. Inputs trips, ports, hauls primary dataset, latitude  longitude ports port. ellipsoid arguments, f, numeric  can changed ellipsoid WGS84 appropriate. See geosphere R package details  (https://cran.r-project.org/web/packages/geosphere/geosphere.pdf).","code":""},{"path":"/reference/create_trip_distance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create haul level trip distance variable — create_trip_distance","text":"","code":"if (FALSE) { pcodMainDataTable <- create_trip_distance(pcodMainDataTable, \"pcod\", \"pcodPortTable\",    \"TRIP_SEQ\", \"DISEMBARKED_PORT\", c(\"LonLat_START_LON\", \"LonLat_START_LAT\"),   c(\"LonLat_END_LON\", \"LonLat_END_LAT\"), \"EMBARKED_PORT\", \"HAUL_SEQ\", \"TripDistance\" ) }  #"},{"path":"/reference/create_var_num.html","id":null,"dir":"Reference","previous_headings":"","what":"Create numeric variable using arithmetic expression — create_var_num","title":"Create numeric variable using arithmetic expression — create_var_num","text":"Creates new variable based arithmetic operation two variables.     Function useful creating rate variables summation two related variables.","code":""},{"path":"/reference/create_var_num.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create numeric variable using arithmetic expression — create_var_num","text":"","code":"create_var_num(dat, project, x, y, method, name = \"create_var_num\")"},{"path":"/reference/create_var_num.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create numeric variable using arithmetic expression — create_var_num","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. x Variable dat. Variable numerator method division. y Variable  dat numeric value. Variable denominator method division. method String, arithmetic expression. Options include: \"sum\", addition (\"add\"), subtraction (\"sub\"), multiplication (\"mult\"), division (\"div\"). name String, name created vector. Defaults name function defined.","code":""},{"path":"/reference/create_var_num.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create numeric variable using arithmetic expression — create_var_num","text":"Returns primary dataset new variable added.","code":""},{"path":"/reference/create_var_num.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create numeric variable using arithmetic expression — create_var_num","text":"Creates new numeric variable based defined arithmetic expression method.    New variable added primary dataset.","code":""},{"path":"/reference/create_var_num.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create numeric variable using arithmetic expression — create_var_num","text":"","code":"if (FALSE) { pollockMainDataTable <- create_var_num(pollockMainDataTable, 'pollock', x = 'HAUL_CHINOOK',     y = 'HAUL_CHUM', method = 'sum', name = 'tot_salmon') }"},{"path":"/reference/cross_validation.html","id":null,"dir":"Reference","previous_headings":"","what":"K-fold cross validation — cross_validation","title":"K-fold cross validation — cross_validation","text":"K-fold cross validation estimating model performance","code":""},{"path":"/reference/cross_validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"K-fold cross validation — cross_validation","text":"","code":"cross_validation(   project,   mod.name,   zone.dat,   groups,   k = NULL,   time_var = NULL,   use.scalers = FALSE,   scaler.func = NULL )"},{"path":"/reference/cross_validation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K-fold cross validation — cross_validation","text":"project Name project mod.name Name saved model use. Argument can name model can pull name  saved \"best\" model. Leave mod.name empty use saved \"best\" model. one model saved, mod.name numeric indicator model use. Use table_view(\"modelChosen\", project) view table saved models. zone.dat Variable main data table identifies individual zones areas. groups Determine subset dataset groups training testing k Integer, value required groups = 'Observations' determine number groups splitting data  training testing datasets. value k chosen balance bias variance values k = 5 10 found efficient standard values literature. Note higher k values  increase runtime computational cost cross_validation. Leave--cross validation type  k-fold cross validation k = n number observations, can useful small datasets. time_var Name column time variable. Required groups = 'Years'. use.scalers Input create_model_input(). Logical, data normalized? Defaults FALSE.  Rescaling factors mean numeric vector unless specified scaler.func. scaler.func Input create_model_input(). Function calculate rescaling factors.","code":""},{"path":"/reference/cross_validation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"K-fold cross validation — cross_validation","text":"K-fold cross validation resampling procedure evaluating predictive performance model. First data split k groups, can split randomly across observations (e.g., 5-fold cross validation group randomly assigned across observations)  split based particular variable (e.g., split groups based gear type). group takes turn 'hold-' 'test' data set, remaining groups training dataset (parameters estimated training dataset). Finally predictive performance iteration calculated percent absolute prediction error.  s","code":""},{"path":"/reference/cross_validation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"K-fold cross validation — cross_validation","text":"","code":"if (FALSE) {  model_design_outsample(\"scallop\", \"scallopModName\")  }"},{"path":"/reference/current_db_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve name of the most recent table from a project — current_db_table","title":"Retrieve name of the most recent table from a project — current_db_table","text":"Retrieve name recent table project","code":""},{"path":"/reference/current_db_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve name of the most recent table from a project — current_db_table","text":"","code":"current_db_table(project, table)"},{"path":"/reference/current_db_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve name of the most recent table from a project — current_db_table","text":"project Name project. table Name table, e.g. \"MainDataTable\".","code":""},{"path":"/reference/current_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Lists most recent log file — current_log","title":"Lists most recent log file — current_log","text":"Lists recent log file","code":""},{"path":"/reference/current_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lists most recent log file — current_log","text":"","code":"current_log(project)"},{"path":"/reference/current_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lists most recent log file — current_log","text":"project Project name.","code":""},{"path":"/reference/current_log.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Lists most recent log file — current_log","text":"Prints name recent log file, filepath.","code":""},{"path":"/reference/current_out.html","id":null,"dir":"Reference","previous_headings":"","what":"Lists most recent output files — current_out","title":"Lists most recent output files — current_out","text":"Lists recent output files","code":""},{"path":"/reference/current_out.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lists most recent output files — current_out","text":"","code":"current_out(project)"},{"path":"/reference/current_out.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lists most recent output files — current_out","text":"project Project name","code":""},{"path":"/reference/current_out.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Lists most recent output files — current_out","text":"Prints name recent output files.","code":""},{"path":"/reference/current_out.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lists most recent output files — current_out","text":"","code":"if (FALSE) { current_out(\"pollock\") }"},{"path":"/reference/data_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for common data quality issues — data_check","title":"Check for common data quality issues — data_check","text":"Check primary data common data quality issues, NaNs, NAs, outliers,  unique rows, empty variables.","code":""},{"path":"/reference/data_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for common data quality issues — data_check","text":"","code":"data_check(dat, project, x)"},{"path":"/reference/data_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for common data quality issues — data_check","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project String, name project. x Variable dat check outliers. Must quotes called FishSET database.","code":""},{"path":"/reference/data_check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check for common data quality issues — data_check","text":"Prints summary stats variables dat. Prints column    names contain NaNs NAs. Checks outliers specified variable    x. Checks column names unique, whether columns    dat empty, whether row unique choice occurrence    haul trip level, data either lat/lon fishing area included.    function also called functions.","code":""},{"path":"/reference/data_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for common data quality issues — data_check","text":"","code":"if (FALSE) { data_check(pcodMainDataTable, \"OFFICIAL_TOTAL_CATCH_MT\") }"},{"path":"/reference/data_pull.html","id":null,"dir":"Reference","previous_headings":"","what":"Pull data from sqlite database — data_pull","title":"Pull data from sqlite database — data_pull","text":"Pull data sqlite database","code":""},{"path":"/reference/data_pull.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pull data from sqlite database — data_pull","text":"","code":"data_pull(dat, project)"},{"path":"/reference/data_pull.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pull data from sqlite database — data_pull","text":"dat Data table project Project name","code":""},{"path":"/reference/data_upload_helper.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload data from file, FishSET DB, or working environment — data_upload_helper","title":"Upload data from file, FishSET DB, or working environment — data_upload_helper","text":"Helper function can read data file, FishSET DB, dataframe working environment. Used data upload functions:  load_maindata, load_port, load_aux, load_grid, load_spatial.","code":""},{"path":"/reference/data_upload_helper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload data from file, FishSET DB, or working environment — data_upload_helper","text":"","code":"data_upload_helper(dat, type, ...)"},{"path":"/reference/data_upload_helper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload data from file, FishSET DB, or working environment — data_upload_helper","text":"dat Reference dataframe. can filepath, name existing FishSET table, dataframe object working environment. type type data upload. Options include \"main\",  \"port\", \"grid\", \"aux\", \"spat\". ... Additional arguments passed read_dat.","code":""},{"path":"/reference/data_upload_helper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upload data from file, FishSET DB, or working environment — data_upload_helper","text":"","code":"if (FALSE) { dataset <- data_upload_helper(dat, type = \"main\") }"},{"path":"/reference/data_verification.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for common data quality issues that may be present in the data set. — data_verification","title":"Check for common data quality issues that may be present in the data set. — data_verification","text":"Function tests common data quality issues.","code":""},{"path":"/reference/data_verification.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for common data quality issues that may be present in the data set. — data_verification","text":"","code":"data_verification(dat, project, log_fun = TRUE)"},{"path":"/reference/data_verification.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for common data quality issues that may be present in the data set. — data_verification","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. log_fun Logical, whether log function call (internal use).","code":""},{"path":"/reference/data_verification.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for common data quality issues that may be present in the data set. — data_verification","text":"Statements whether data quality issues may exist.","code":""},{"path":"/reference/data_verification.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check for common data quality issues that may be present in the data set. — data_verification","text":"Checks columnn names data frame unique, whether    columns data frame empty, whether row unique choice    occurrence haul trip level, either latitude longitude   fishing area included.","code":""},{"path":"/reference/data_verification.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for common data quality issues that may be present in the data set. — data_verification","text":"","code":"if (FALSE) { data_verification(pollockMainDataTable, 'pollock') }"},{"path":"/reference/date_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse date/date-time variable — date_check","title":"Parse date/date-time variable — date_check","text":"Parse date/date-time variable","code":""},{"path":"/reference/date_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse date/date-time variable — date_check","text":"","code":"date_check(dat, date)"},{"path":"/reference/date_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse date/date-time variable — date_check","text":"dat Dataframe containing variable convert date/date-time. date Date variable name convert.","code":""},{"path":"/reference/date_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse date/date-time variable — date_check","text":"Checks whether variable can converted date date-time. Returns  dataframe converted variable.","code":""},{"path":"/reference/date_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Find columns that can be converted to Date or Date-time class — date_cols","title":"Find columns that can be converted to Date or Date-time class — date_cols","text":"Find columns can converted Date Date-time class","code":""},{"path":"/reference/date_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find columns that can be converted to Date or Date-time class — date_cols","text":"","code":"date_cols(dat, out = \"names\", type = \"both\")"},{"path":"/reference/date_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find columns that can be converted to Date or Date-time class — date_cols","text":"dat MainDataTable dataframe check. Whether return column \"names\" (default) logical vector  (\"logical\"). type String, type date column test . Options  \"date\", \"date_time\", \"\".","code":""},{"path":"/reference/date_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find columns that can be converted to Date or Date-time class — date_cols","text":"","code":"if (FALSE) { date_cols(pollockMainDataTable) # returns column names date_cols(pollockMainDataTable, \"logical\") }"},{"path":"/reference/date_factorize.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert date variable of type character to ordered factor — date_factorize","title":"Convert date variable of type character to ordered factor — date_factorize","text":"Convert date variable type character ordered factor","code":""},{"path":"/reference/date_factorize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert date variable of type character to ordered factor — date_factorize","text":"","code":"date_factorize(dataset, date_col, date_code)"},{"path":"/reference/date_factorize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert date variable of type character to ordered factor — date_factorize","text":"dataset data frame containing date variable. date_col date variable type character convert ordered factor. date_code date code used format date variable.","code":""},{"path":"/reference/date_parser.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse date variable — date_parser","title":"Parse date variable — date_parser","text":"Parse date variable","code":""},{"path":"/reference/date_parser.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse date variable — date_parser","text":"","code":"date_parser(dates, args = NULL)"},{"path":"/reference/date_parser.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse date variable — date_parser","text":"dates Variable containing dates","code":""},{"path":"/reference/date_time_parser.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse date-time variable — date_time_parser","title":"Parse date-time variable — date_time_parser","text":"Parse date-time variable","code":""},{"path":"/reference/date_time_parser.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse date-time variable — date_time_parser","text":"","code":"date_time_parser(dates)"},{"path":"/reference/date_time_parser.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse date-time variable — date_time_parser","text":"dates Variable containing date-times","code":""},{"path":"/reference/date_title.html","id":null,"dir":"Reference","previous_headings":"","what":"Add date to ggplot title — date_title","title":"Add date to ggplot title — date_title","text":"Add date ggplot title","code":""},{"path":"/reference/date_title.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add date to ggplot title — date_title","text":"","code":"date_title(plot, filter_date, date_value)"},{"path":"/reference/date_title.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add date to ggplot title — date_title","text":"plot ggplot2 plot object add new title . filter_date filter_date parameter function. date_value values used filter data table used plot.","code":""},{"path":"/reference/date_title.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add date to ggplot title — date_title","text":"plot year, month, year-month included tittle.","code":""},{"path":"/reference/dat_to_sf.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert dataframe to sf — dat_to_sf","title":"Convert dataframe to sf — dat_to_sf","text":"Used convert spatial data spatial class sf object.  useful spatial data read non-spatial file type,  e.g. CSV file.","code":""},{"path":"/reference/dat_to_sf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert dataframe to sf — dat_to_sf","text":"","code":"dat_to_sf(dat, lon, lat, id, cast = \"POLYGON\", multi = FALSE, crs = 4326)"},{"path":"/reference/dat_to_sf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert dataframe to sf — dat_to_sf","text":"dat Spatial data containing information fishery management  regulatory zones. lon Longitude variable spatdat. lat Latitude variable spatdat. id Spatial feature ID column. cast Spatial feature type create. Commonly used options \"POINT\", \"LINESTRING\", \"POLYGON\". See st_cast  details. multi Logical, use needing convert multi-featured (grouped) sf object, e.g. MULTIPOLYGON MULTILINESTRING. crs Coordinate reference system assign dat. Defaults WGS 84 (EPSG: 4326).","code":""},{"path":"/reference/dd2dms.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert DD to DMS — dd2dms","title":"Convert DD to DMS — dd2dms","text":"Convert decimal degree format degree minutes seconds format.","code":""},{"path":"/reference/dd2dms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert DD to DMS — dd2dms","text":"","code":"dd2dms(dd, NS = FALSE)"},{"path":"/reference/dd2dms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert DD to DMS — dd2dms","text":"dd numeric vector decimal degrees. NS logical, TRUE north/south decimal degrees, FALSE  east/west decimal degrees.","code":""},{"path":"/reference/degree.html","id":null,"dir":"Reference","previous_headings":"","what":"Check and convert lat/lon to decimal degrees — degree","title":"Check and convert lat/lon to decimal degrees — degree","text":"Check latitude longitude decimal degrees variable  sign correct. Correct lat/lon required.","code":""},{"path":"/reference/degree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check and convert lat/lon to decimal degrees — degree","text":"","code":"degree(   dat,   project,   lat = NULL,   lon = NULL,   latsign = FALSE,   lonsign = FALSE,   replace = TRUE )"},{"path":"/reference/degree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check and convert lat/lon to decimal degrees — degree","text":"dat Dataset containing latitude longitude data. project Project name. lat Variable(s) containing latitude data. NULL function attempt search latitude variables name (e.g. matching \"lat\" \"LAT\"). lon Variable(s) containing longitude data. NULL function attempt search longitude variables name (e.g. matching \"lon\" \"LON\"). latsign sign value lat changed? Choices  NULL change, \"neg\" convert positive values  negative, \"pos\" convert negative values positive, \"\" change values. lonsign sign value lon changed? Choices  NULL change, \"neg\" convert positive values  negative, \"pos\" convert negative values positive, \"\" change values. replace Logical, lat lon dat  converted decimal degrees? Defaults TRUE. Set FALSE  checking compliance.","code":""},{"path":"/reference/degree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check and convert lat/lon to decimal degrees — degree","text":"Returns primary dataset latitudes longitudes converted    decimal degrees replace = TRUE Changing sign.    Otherwise, message indicating whether selected longitude latitude   variables correct format.","code":""},{"path":"/reference/degree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check and convert lat/lon to decimal degrees — degree","text":"First checks whether variables containing 'lat' 'lon'    names numeric. Returns message results. convert variable    decimal degrees, identify lat lon variable(s) set    replace = TRUE. change sign, set latsign (lat)    lonsign (lon = TRUE. FishSET requires latitude    longitude decimal degrees.","code":""},{"path":"/reference/degree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check and convert lat/lon to decimal degrees — degree","text":"","code":"if (FALSE) { # check format degree(pollockMainDataTable, 'pollock', lat = 'LatLon_START_LAT',        lon = 'LatLon_START_LON')  # change signs and convert to decimal degrees pollockMainDataTable <- degree(pollockMainDataTable, 'pollock',                                 lat = 'LatLon_START_LAT',                                 lon = 'LatLon_START_LON', latsign = FALSE,                                 lonsign = FALSE, replace = TRUE) }"},{"path":"/reference/deleteButtonColumn.html","id":null,"dir":"Reference","previous_headings":"","what":"A column of delete buttons for each row in the data frame for the first column — deleteButtonColumn","title":"A column of delete buttons for each row in the data frame for the first column — deleteButtonColumn","text":"column delete buttons row data frame first column","code":""},{"path":"/reference/deleteButtonColumn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A column of delete buttons for each row in the data frame for the first column — deleteButtonColumn","text":"","code":"deleteButtonColumn(df, id, ...)"},{"path":"/reference/deleteButtonColumn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A column of delete buttons for each row in the data frame for the first column — deleteButtonColumn","text":"df data frame id id prefix add actionButton. buttons id'd id_INDEX.","code":""},{"path":"/reference/deleteButtonColumn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A column of delete buttons for each row in the data frame for the first column — deleteButtonColumn","text":"DT::datatable escaping turned delete buttons first column    df function create one action button string","code":""},{"path":"/reference/delete_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete table meta data or project meta file — delete_meta","title":"Delete table meta data or project meta file — delete_meta","text":"Delete table meta data project meta file","code":""},{"path":"/reference/delete_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete table meta data or project meta file — delete_meta","text":"","code":"delete_meta(project, tab.name = NULL, delete_file = FALSE)"},{"path":"/reference/delete_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete table meta data or project meta file — delete_meta","text":"project Project name. tab.name String, table name. delete_file Logical, whether delete project meta file.","code":""},{"path":"/reference/delete_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete models from FishSET Database — delete_models","title":"Delete models from FishSET Database — delete_models","text":"Delete models model design file (MDF) model output table (MOT).","code":""},{"path":"/reference/delete_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete models from FishSET Database — delete_models","text":"","code":"delete_models(project, model.names, delete.nested = FALSE)"},{"path":"/reference/delete_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete models from FishSET Database — delete_models","text":"project String, name project. model.names String, name models delete. Use model_names() see model names model design file. delete.nested Logical, whether delete model containing nested models. Defaults FALSE.","code":""},{"path":"/reference/delete_models.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Delete models from FishSET Database — delete_models","text":"Nested models conditional logit models include one expected catch/revenue model. example, conditional logit model named 'logit_c_mod1' saved MDF argument expectcatchmodels = list('exp1', 'recent', 'older'), 'logit_c_mod1 include three separate models, using different expected catch matrix. delete three models, enter model.names = 'logit_c_mod1' set delete.nested = TRUE. delete one specific nested models, use model.names = 'logit_c_mod1.exp1', .e. original model name, period, name expected catch matrix used model.","code":""},{"path":[]},{"path":"/reference/density_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create KDE, CDF, or empirical CDF plots — density_plot","title":"Create KDE, CDF, or empirical CDF plots — density_plot","text":"Creates kernel density estimate, empirical cumulative distribution function, cumulative distribution function plot selected variable. Grouping, filtering, several plot options available.","code":""},{"path":"/reference/density_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create KDE, CDF, or empirical CDF plots — density_plot","text":"","code":"density_plot(   dat,   project,   var,   type = \"kde\",   group = NULL,   combine = TRUE,   date = NULL,   filter_date = NULL,   date_value = NULL,   filter_by = NULL,   filter_value = NULL,   filter_expr = NULL,   facet_by = NULL,   conv = \"none\",   tran = \"identity\",   format_lab = \"decimal\",   scale = \"fixed\",   bw = 1,   position = \"identity\",   pages = \"single\" )"},{"path":"/reference/density_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create KDE, CDF, or empirical CDF plots — density_plot","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project String, name project. var String, name variable plot. type String, type density plot. Options include \"kde\" (kernel  density estimate), \"ecdf\" (empirical cdf), \"cdf\" (cumulative  distribution function), \"\" (plot types). Two plot types can  chosen. group Optional, string names variables group . two grouping variables included, default \"cdf\" \"ecdf\" plots  combine groups. can changed using combine = TRUE.  \"kde\" plots always combine two groups. \"cdf\"  \"ecdf\" plots can use two grouping variables combine = FALSE:  first variable represented color second line type. combine Logical, whether combine variables listed group  plot. date Date variable dat used subset /facet plot . filter_date type filter apply `MainDataTable`. filter  range dates, use filter_date = \"date_range\". filter given  period, use \"year-day\", \"year-week\", \"year-month\", \"year\", \"month\", \"week\",  \"day\". argument date_value must provided. date_value argument paired filter_date. filter date range, set filter_date = \"date_range\" enter  start-  end-date date_value string:  date_value = c(\"2011-01-01\", \"2011-03-15\"). filter period (e.g. \"year\", \"year-month\"), use integers (4 digits year, 1-2  digits referencing day, month, week). Use vector filtering  single period: date_filter = \"month\" date_value = c(1, 3, 5).  filter data January, March, May. Use list using year-period type filter, e.g. \"year-week\",  format: list(year, period). example, filter_date = \"year-month\" date_value = list(2011:2013, 5:7) filter data table  May July years 2011-2013. filter_by String, variable name filter `MainDataTable` . argument  filter_value must provided. filter_value vector values filter `MainDataTable` using  variable filter_by. example, filter_by = \"GEAR_TYPE\",  filter_value = 1 include observations gear type 1. filter_expr String, valid R expression filter `MainDataTable` . facet_by Variable name facet . can variable exists dat variable created density_plot() \"year\",  \"month\", \"week\". date required facetting period. conv Convert catch variable \"tons\", \"metric_tons\",  using function entered string. Defaults \"none\"  conversion. tran String; name function transform variable, example  \"log\" \"sqrt\". format_lab Formatting option x-axis labels. Options include  \"decimal\" \"scientific\". scale Scale argument passed facet_grid. Defaults  \"fixed\". options include \"free_y\", \"free_x\",  \"free\". bw Adjusts KDE bandwidth. Defaults 1. position position grouped variable KDE plot. Options include \"identity\", \"stack\", \"fill\". pages Whether output plots single page (\"single\",  default) multiple pages (\"multi\").","code":""},{"path":"/reference/density_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create KDE, CDF, or empirical CDF plots — density_plot","text":"denstiy_plot() can return three plots single call.    pages = \"single\" plots combined stacked vertically.  pages = \"multi\" return separate plots.","code":""},{"path":"/reference/density_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create KDE, CDF, or empirical CDF plots — density_plot","text":"data can filtered date variable (see filter_date    filter_by). type contains \"kde\" \"\"    grouping variables automatically combined. variable dat    can used faceting, \"year\", \"month\", \"week\"    also available date provided.","code":""},{"path":"/reference/density_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create KDE, CDF, or empirical CDF plots — density_plot","text":"","code":"if (FALSE) {  density_plot(pollockMainDataTable, \"pollock\", var = \"OFFICIAL_TOTAL_CATCH_MT\",              type = c(\"kde\", \"ecdf\"))  # facet  density_plot(pollockMainDataTable, \"pollock\", var = \"OFFICIAL_TOTAL_CATCH_MT\",              type = c(\"kde\", \"ecdf\"), facet_by = \"GEAR_TYPE\")  # filter by period density_plot(pollockMainDataTable, \"pollock\", var = \"OFFICIAL_TOTAL_CATCH_MT\",               type = \"kde\", date = \"FISHING_START_DATE\", filter_date = \"year-month\",               filter_value = list(2011, 9:11)) }"},{"path":"/reference/dens_plot_helper.html","id":null,"dir":"Reference","previous_headings":"","what":"density_plot helper function — dens_plot_helper","title":"density_plot helper function — dens_plot_helper","text":"Creates formats plots","code":""},{"path":"/reference/dens_plot_helper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"density_plot helper function — dens_plot_helper","text":"","code":"dens_plot_helper(   dataset,   var,   group,   date,   facet_by,   filter_date,   date_value,   type,   bw,   conv,   tran,   format_lab,   scale,   position,   pages )"},{"path":"/reference/dens_plot_helper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"density_plot helper function — dens_plot_helper","text":"dataset Data used create plot. var String, variable passed density_plot. group String, grouping variable(s) passed density_plot. date String, date variable passed density_plot. facet_by String, facet variable(s) passed density_plot. filter_date String, date filter type passed density_plot. date_value Numeric, date filter value passed density_plot. type String, plot type(s) passed density_plot. bw Numeric, bandwidth passed density_plot. conv String, convert pounds \"tons\" \"metric_tons\". tran String, scale transformation passed density_plot. format_lab String, label formatting option passed density_plot. scale Scale argument passed facet_grid. Defaults \"fixed\".  options include \"free_y\", \"free_x\", \"free\". position String, plot position passed density_plot. pages String, single multiple plots passed density_plot.","code":""},{"path":"/reference/deparse_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Deparse a data table for log — deparse_name","title":"Deparse a data table for log — deparse_name","text":"Deparse data table log","code":""},{"path":"/reference/deparse_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deparse a data table for log — deparse_name","text":"","code":"deparse_name(dat)"},{"path":"/reference/deparse_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deparse a data table for log — deparse_name","text":"dat dataframe object string deparse log_call function.","code":""},{"path":"/reference/discretefish_subroutine.html","id":null,"dir":"Reference","previous_headings":"","what":"Run discrete choice model — discretefish_subroutine","title":"Run discrete choice model — discretefish_subroutine","text":"Subroutine run chosen discrete choice model. Function pulls necessary data  generated make_model_design loops model design  choices expected catch cases. Output saved FishSET database.","code":""},{"path":"/reference/discretefish_subroutine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run discrete choice model — discretefish_subroutine","text":"","code":"discretefish_subroutine(   project,   run = \"new\",   select.model = FALSE,   explorestarts = TRUE,   breakearly = TRUE,   space = NULL,   dev = NULL,   use.scalers = FALSE,   scaler.func = NULL,   CV = FALSE )"},{"path":"/reference/discretefish_subroutine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run discrete choice model — discretefish_subroutine","text":"project String, name project. run String, models run. 'new' run models exist model design file model output table. '' run models model design file, replacing existing model output.  third option enter vector model names run (use  model_names() see current model names).  specified model already output replaced. select.model Return interactive data table allows users  select save table best models based measures fit. explorestarts Logical, starting parameters value space explored?  Set TRUE unsure number starting parameter values  include reasonable starting parameters values. Better starting parameter  values can help model convergence. breakearly Logical, explorestarts = TRUE, first set  starting parameter values returns valid (numeric) loglikelihood  value returned (TRUE) entire parameter space considered  set starting parameter values return lowest loglikelihood  value returned (FALSE). space Specify explorestarts = TRUE. List length 1 length  equal number models evaluated. space number  starting value permutations test (size space explore).  greater dev argument, larger space argument . dev Specify explorestarts = TRUE. List length 1 length  equal number models evaluated. dev refers far  deviate average parameter values exploring (random normal  deviates). less certain average parameters , greater  dev argument . use.scalers Logical, data normalized? Defaults FALSE.  Rescaling factors mean numeric vector unless specified  scaler.func. scaler.func Function calculate rescaling factors. Can generic  function, mean, user-defined function. User-defined functions  must specified scaler.fun = function(x, FUN = sd) 2*FUN(x).  example returns two times standard deviation x. CV Logical, CV = TRUE running discretefish_subroutine k-fold cross validation, default value CV = FALSE.","code":""},{"path":[]},{"path":"/reference/discretefish_subroutine.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run discrete choice model — discretefish_subroutine","text":"Runs model design choices generated make_model_design    stored `ModelInputData` FishSET database.  Data matrix created    create_model_input. Required data, optional data, details    likelihood functions outlined make_model_design. Likelihood-specific initial parameter estimates: Conditional logit likelihood (logit_c)    Starting parameter values takes order : c([alternative-specific parameters],  [travel-distance parameters]).    alternative-specific parameters travel-distance parameters length (# alternative-specific variables) (#    travel-distance variables) respectively. Zonal logit area specific constants (logit_zonal)     Starting parameters takes order : c([average-catch parameters], [travel-distance parameters]).    average-catch travel-distance parameters length (# average-catch variables)*(k-1) (# travel-distance variables)    respectively, (k) equals number alternative fishing choices. Full information model Dahl's correction function (logit_correction)     Starting parameter values takes order : c([marginal utility catch], [catch-function parameters],    [polynomial starting parameters], [travel-distance parameters], [catch sigma]).    number polynomial interaction terms currently set 2, given chosen degree 'polyn'    \"(((polyn+1)*2)+2)*(k)\" polynomial starting parameters, (k) equals number alternative fishing choices.    marginal utility catch catch sigma length equal unity respectively. catch-function    travel-distance parameters length (# catch variables)*(k) (# cost variables) respectively. Expected profit model normal catch function (epm_normal)     Starting parameters values take order : c([catch-function parameters], [travel-distance parameters], [catch sigma(s)], [scale parameter]).    catch-function travel-distance parameters length (# catch-function variables)*(k) (# travel-distance    variables) respectively, (k) equals number alternative fishing choices. catch sigma(s) either length equal    unity length (k) analyst estimating location-specific catch sigma parameters. scale parameter length    equal unity. Expected profit model Weibull catch function (epm_weibull)     Starting parameter values takes order : c([catch-function parameters], [travel-distance parameters], [catch sigma(s)], [scale parameter]).    catch-function travel-distance parameters length (# catch-function variables)*(k) (# travel-distance variables)    respectively, (k) equals number alternative fishing choices. catch sigma(s) either length equal unity    length (k) analyst estimating location-specific catch sigma parameters. scale parameter length equal unity. Expected profit model log-normal catch function (epm_lognormal)     Starting parameter values takes order : c([catch-function parameters], [travel-distanceparameters],    [catch sigma(s)], [scale parameter]).    catch-function travel-distance parameters length (#    catch-function variables)*(k) (# travel-distance variables) respectively, (k) equals number alternative fishing choices.    catch sigma(s) either length equal unity length (k) analyst estimating location-specific catch sigma parameters.    scale parameter length equal unity.  Model output saved FishSET database can loaded console : obtaining catch, choice, distance, otherdat data generated make_model_design function.    ModelInputData table pulled FishSET database.","code":""},{"path":"/reference/discretefish_subroutine.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run discrete choice model — discretefish_subroutine","text":"","code":"if (FALSE) { results <- discretefish_subroutine(\"pcod\", run = 'all', select.model = TRUE) }"},{"path":"/reference/dms_to_dd.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert decimal minutes/seconds to degrees — dms_to_dd","title":"Convert decimal minutes/seconds to degrees — dms_to_dd","text":"Convert decimal minutes/seconds degrees","code":""},{"path":"/reference/dms_to_dd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert decimal minutes/seconds to degrees — dms_to_dd","text":"","code":"dms_to_dd(x)"},{"path":"/reference/dms_to_dd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert decimal minutes/seconds to degrees — dms_to_dd","text":"x Latitude longitude vector.","code":""},{"path":"/reference/dms_to_dd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert decimal minutes/seconds to degrees — dms_to_dd","text":"","code":"if (FALSE) { pollockMainDataTable$LonLat_START_LAT <- dms_to_dd(pollockMainDataTable$LonLat_START_LAT) }"},{"path":"/reference/dms_to_pdms.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert DMS to Packed DMS — dms_to_pdms","title":"Convert DMS to Packed DMS — dms_to_pdms","text":"Convert DMS Packed DMS","code":""},{"path":"/reference/dms_to_pdms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert DMS to Packed DMS — dms_to_pdms","text":"","code":"dms_to_pdms(x, type, dec = FALSE, as_num = FALSE)"},{"path":"/reference/dms_to_pdms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert DMS to Packed DMS — dms_to_pdms","text":"x Latitude longitude vector. type \"lat\" \"lon\". dec Logical, whether keep decimal present. as_num Logical, whether convert numeric. FALSE,  character string outputted.","code":""},{"path":"/reference/dms_to_pdms.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert DMS to Packed DMS — dms_to_pdms","text":"Primarily used testing whether degree() can convert   Packed DMS decimal degrees.","code":""},{"path":"/reference/dummy_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Create dummy matrix from a coded ID variable — dummy_matrix","title":"Create dummy matrix from a coded ID variable — dummy_matrix","text":"Create dummy matrix coded ID variable","code":""},{"path":"/reference/dummy_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create dummy matrix from a coded ID variable — dummy_matrix","text":"","code":"dummy_matrix(dat, project, x)"},{"path":"/reference/dummy_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create dummy matrix from a coded ID variable — dummy_matrix","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. x Variable dat used generate dummy matrix.","code":""},{"path":"/reference/dummy_matrix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create dummy matrix from a coded ID variable — dummy_matrix","text":"Creates dummy matrix 1/0 dimensions [(number observations dataset) x (number factors x)] column unique factor level. Values 1 value column matches column factor level 0 otherwise.","code":""},{"path":"/reference/dummy_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create dummy matrix from a coded ID variable — dummy_matrix","text":"","code":"if (FALSE) { PortMatrix <- dummy_matrix(pollockMainDataTable, 'pollock', 'PORT_CODE') }"},{"path":"/reference/dummy_num.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a binary vector from numeric, date, and character or factor vectors. — dummy_num","title":"Create a binary vector from numeric, date, and character or factor vectors. — dummy_num","text":"Create binary vector numeric, date, character factor vectors.","code":""},{"path":"/reference/dummy_num.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a binary vector from numeric, date, and character or factor vectors. — dummy_num","text":"","code":"dummy_num(dat, project, var, value, opts = \"more_less\", name = \"dummy_num\")"},{"path":"/reference/dummy_num.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a binary vector from numeric, date, and character or factor vectors. — dummy_num","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. var Variable dat create dummy variable . value String, value set dummy variable . var date, value year, var factor, value factor level. var numeric, value single number range numbers [use c(1,5)]. opts String, dummy variable defined. Choices \"x_y\" \"more_less’\". \"x_y\", element var set 1 element matches value, otherwise 0. \"more_less\", element var less value set 0 elements greater value set 1. var factor, elements match value set 1 elements set 0. Default set \"more_less\". name String, name created dummy variable. Defaults name function defined.","code":""},{"path":"/reference/dummy_num.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a binary vector from numeric, date, and character or factor vectors. — dummy_num","text":"Returns primary dataset dummy variable added.","code":""},{"path":"/reference/dummy_num.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a binary vector from numeric, date, and character or factor vectors. — dummy_num","text":"date variables, dummy variable defined date (year) may either year x versus   years (\"x_y\") vs year x (\"more_less\"). Use function create variable defining whether   policy action implemented.    Example: vs. 2008 amendment: dummy_num('pollockMainDataTable', 'Haul_date', 2008, 'more_less', 'amend08') factor variables, choices opts compare selected factor level(s) factor levels.  Example: Fishers targeting pollock vs. another species:  dummy_num('pollockMainDataTable', 'GF_TARGET_FT', c('Pollock - bottom', 'Pollock - midwater'), 'x_y', 'pollock_target') numeric variables, value can single number range numbers. dummy variable  selected value(s) others (x_y) less selected value versus selected value  (more_less). more_less, mean used critical value range values provided.","code":""},{"path":"/reference/dummy_num.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a binary vector from numeric, date, and character or factor vectors. — dummy_num","text":"","code":"if (FALSE) { pollockMainDataTable <- dummy_num(pollockMainDataTable, 'pollock', 'Haul_date', 2008,    'more_less', 'amend80') }"},{"path":"/reference/dummy_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Create dummy variable — dummy_var","title":"Create dummy variable — dummy_var","text":"Create dummy variable","code":""},{"path":"/reference/dummy_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create dummy variable — dummy_var","text":"","code":"dummy_var(dat, project, DumFill = 1, name = \"dummy_var\")"},{"path":"/reference/dummy_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create dummy variable — dummy_var","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. DumFill Fill dummy variable 1 0 name String, name created dummy variable. Defaults name function defined.","code":""},{"path":"/reference/dummy_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create dummy variable — dummy_var","text":"Primary dataset dummy variable added.","code":""},{"path":"/reference/dummy_var.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create dummy variable — dummy_var","text":"Creates dummy variable either 0 1 length number rows data set.","code":""},{"path":"/reference/dummy_var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create dummy variable — dummy_var","text":"","code":"if (FALSE) { pollockMainDataTable <- dummy_var(pollockMainDataTable, 'pollock', DumFill=1, 'dummyvar') }"},{"path":"/reference/edit_proj_settings.html","id":null,"dir":"Reference","previous_headings":"","what":"Edit project settings — edit_proj_settings","title":"Edit project settings — edit_proj_settings","text":"Edit confidentiality settings, user output folder location, default plot  size, tables currently used shiny app.","code":""},{"path":"/reference/edit_proj_settings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Edit project settings — edit_proj_settings","text":"","code":"edit_proj_settings(   project,   confid = NULL,   user_out = NULL,   tab_name = NULL,   tab_type = NULL,   plot_size = NULL,   save_plot_rds = NULL )"},{"path":"/reference/edit_proj_settings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Edit project settings — edit_proj_settings","text":"project Name project. confid List containing new confidentiality settings. See  set_confid_check. user_out Folder directory containing FishSET output. see  set_user_locoutput. tab_name Name table loaded shiny app. tab_type Table type. Options include \"main\", \"port\", \"spat\", \"grid\", \"aux\". plot_size Plot size (width, height) inches. Must numeric. save_plot_rds Logical, whether save plot RDS file  FishSETFolder ouput folder addition save PNG. allows users  edit plots later time.","code":""},{"path":[]},{"path":"/reference/edit_proj_settings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Edit project settings — edit_proj_settings","text":"","code":"if (FALSE) { edit_project_settings(\"pollock\", plot_size = c(5, 4)) }"},{"path":"/reference/empty_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function Determines if metadata fields are empty in metadata_gui. — empty_meta","title":"Helper function Determines if metadata fields are empty in metadata_gui. — empty_meta","text":"Helper function Determines metadata fields empty metadata_gui.","code":""},{"path":"/reference/empty_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function Determines if metadata fields are empty in metadata_gui. — empty_meta","text":"","code":"empty_meta(input, col_nms)"},{"path":"/reference/empty_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function Determines if metadata fields are empty in metadata_gui. — empty_meta","text":"input Shiny input. col_nms Column names.","code":""},{"path":"/reference/empty_meta_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an empty meta list Used to create a new metadata entry. — empty_meta_list","title":"Create an empty meta list Used to create a new metadata entry. — empty_meta_list","text":"Create empty meta list Used create new metadata entry.","code":""},{"path":"/reference/empty_meta_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an empty meta list Used to create a new metadata entry. — empty_meta_list","text":"","code":"empty_meta_list()"},{"path":"/reference/empty_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for empty variables — empty_vars","title":"Check for empty variables — empty_vars","text":"Detects variables contain NAs removes  remove = TRUE.","code":""},{"path":"/reference/empty_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for empty variables — empty_vars","text":"","code":"empty_vars(dat, remove = TRUE)"},{"path":"/reference/empty_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for empty variables — empty_vars","text":"dat data.frame check. remove Logical, whether remove empty variables.","code":""},{"path":"/reference/empty_vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for empty variables — empty_vars","text":"","code":"if (FALSE) { dat <- empty_vars(dat) }"},{"path":"/reference/empty_vars_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Check variables are not empty — empty_vars_filter","title":"Check variables are not empty — empty_vars_filter","text":"Check remove empty variables dataset. Empty variables  columns data contain NAs /empty strings.","code":""},{"path":"/reference/empty_vars_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check variables are not empty — empty_vars_filter","text":"","code":"empty_vars_filter(dat, project, remove = FALSE)"},{"path":"/reference/empty_vars_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check variables are not empty — empty_vars_filter","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. remove Logical, whether remove empty variables. Defaults FALSE.","code":""},{"path":"/reference/empty_vars_filter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check variables are not empty — empty_vars_filter","text":"Returns dataset empty variables removed remove = TRUE.","code":""},{"path":"/reference/empty_vars_filter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check variables are not empty — empty_vars_filter","text":"Function checks empty variables prints outcome message    console. empty variables present remove = TRUE,    empty variables removed dataset. Empty variables    columns dataset contain NAs empty strings.","code":""},{"path":"/reference/empty_vars_filter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check variables are not empty — empty_vars_filter","text":"","code":"if (FALSE) { # check for empty vars empty_vars_filter(pollockMainDataTable)  # remove empty vars from data mod.dat <- empty_vars_filter(pollockMainDataTable, 'pollock', remove = TRUE) }"},{"path":"/reference/epm_lognormal.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected profit model with log-normal catch function — epm_lognormal","title":"Expected profit model with log-normal catch function — epm_lognormal","text":"Calculate negative log-likelihood expected profit model (EPM) log-normal catch  function. information EPM lognormal model see section 8.4.5 FishSET  user manual. https://docs.google.com/document/d/1dzXsVt5iWcAQooDDXRJ3XyMoqnSmpZOqirU_f_PnQUM/edit#heading=h.ps7td88zo4ge","code":""},{"path":"/reference/epm_lognormal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected profit model with log-normal catch function — epm_lognormal","text":"","code":"epm_lognormal(starts3, dat, otherdat, alts, project, expname, mod.name)"},{"path":"/reference/epm_lognormal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expected profit model with log-normal catch function — epm_lognormal","text":"starts3 Starting parameter values numeric vector. order parameters  vector :   c([catch-function params], [travel-dist params],  [stdev], [common scale param]),  length catch-function parameters # alternatives * #  catch-function variables, length travel-distance parameters #  travel-distance variables, length standard deviation defaults 1 alternative- specific standard deviation values can specified (length = # alternatives), common scale parameter single value. dat Data matrix, see output shift_sort_x, alternatives distance. otherdat List contains data used model, see section 8.4.5  FishSET user manual details (link description ): (1) 'griddat': catch-function variables interact alternative-specific catch-function parameters vary across alternatives (e.g., vessel gross  tonnage). (2) 'intdat': travel-distance variables interact  travel-distance parameters distance matrix vary across alternatives. (3) 'prices': price terms $/landings units. typically vector prices observation, can single value representing price entire dataset. alts Number alternative choices model project Name project expname Expected catch table (optional) mod.name Name model run model result output table","code":""},{"path":"/reference/epm_lognormal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expected profit model with log-normal catch function — epm_lognormal","text":"ld: negative log likelihood","code":""},{"path":"/reference/epm_lognormal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Expected profit model with log-normal catch function — epm_lognormal","text":"function called discretefish_subroutine running EPM model     log-normal catch function.","code":""},{"path":"/reference/epm_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected profit model with normal catch function — epm_normal","title":"Expected profit model with normal catch function — epm_normal","text":"Calculate negative log-likelihood expected profit model (EPM) normal catch  function. information EPM normal model see section 8.4.3 FishSET  user manual. https://docs.google.com/document/d/1p8mK65uG8yp-HbzCeBgtO0q6DSpKV1Zyk_ucNskt5ug/edit#heading=h.mrt9b1ee2yb8","code":""},{"path":"/reference/epm_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected profit model with normal catch function — epm_normal","text":"","code":"epm_normal(starts3, dat, otherdat, alts, project, expname, mod.name)"},{"path":"/reference/epm_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expected profit model with normal catch function — epm_normal","text":"starts3 Starting values numeric vector. order parameters vector :  c([catch-function params], [travel-dist params],  [stdev], [common scale param]),  length catch-function parameters # alternatives * # catch-function variables, length travel-distance parameters # travel-distance variables, length standard deviation defaults 1 alternative- specific standard deviation values can specified (length = # alternatives), common scale parameter single value. dat Data matrix, see output shift_sort_x, alternatives distance. otherdat List contains data used model, see section 8.4.3  FishSET user manual details (link description ): (1) 'griddat': catch-function variables interact alternative-specific catch-function parameters vary across alternatives (e.g., vessel gross tonnage). (2) 'intdat': travel-distance variables interact travel-distance parameters distance matrix vary across alternatives. (3) 'prices': price terms $/landings units. typically vector prices observation, can single value representing price entire dataset. alts Number alternative choices model project Name project expname Expected catch table (optional) mod.name Name model run model result output table","code":""},{"path":"/reference/epm_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expected profit model with normal catch function — epm_normal","text":"ld: negative log likelihood","code":""},{"path":"/reference/epm_normal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Expected profit model with normal catch function — epm_normal","text":"function called discretefish_subroutine running EPM model     normal catch function.","code":""},{"path":"/reference/epm_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"EPM predict — epm_predict","title":"EPM predict — epm_predict","text":"Prediction component expected profit models (EPMs). function called  model_prediction, called within run_policy.","code":""},{"path":"/reference/epm_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EPM predict — epm_predict","text":"","code":"epm_predict(   project,   mod.name,   mod.type,   use.scalers = FALSE,   scaler.func = NULL,   outsample = FALSE,   outsample.mod.name = NULL )"},{"path":"/reference/epm_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EPM predict — epm_predict","text":"project Name project mod.name Name saved model use mod.type String. Options weibull, lognormal, normal use.scalers Input create_model_input. Logical, data normalized? Defaults FALSE. Rescaling factors mean  numeric vector unless specified scaler.func. scaler.func Input create_model_input. Function calculate rescaling factors. outsample Logical, FALSE predicting probabilities main data, TRUE predicting --sample data. outsample = FALSE  default setting.","code":""},{"path":"/reference/epm_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EPM predict — epm_predict","text":"Returns probability epm model choice","code":""},{"path":"/reference/epm_weibull.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected profit model with Weibull catch function — epm_weibull","title":"Expected profit model with Weibull catch function — epm_weibull","text":"Calculate negative log-likelihood expected profit model (EPM) Weibull catch  function. information EPM Weibull model see section 8.4.4 FishSET  user manual. https://docs.google.com/document/d/1dzXsVt5iWcAQooDDXRJ3XyMoqnSmpZOqirU_f_PnQUM/edit#heading=h.gh3zw8f9nsdi","code":""},{"path":"/reference/epm_weibull.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected profit model with Weibull catch function — epm_weibull","text":"","code":"epm_weibull(starts3, dat, otherdat, alts, project, expname, mod.name)"},{"path":"/reference/epm_weibull.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expected profit model with Weibull catch function — epm_weibull","text":"starts3 Starting parameter values numeric vector. order parameters  vector :   c([catch-function params], [travel-dist params],  [shape params], [common scale param]),  length catch-function parameters # alternatives * #  catch-function variables, length travel-distance parameters #  travel-distance variables, length shape parameters defaults 1 alternative- specific shape parameters can specified (length = # alternatives), common scale parameter single value. dat Data matrix, see output shift_sort_x, alternatives distance. otherdat List contains data used model, see section 8.4.4  FishSET user manual details (link description ): (1) 'griddat': catch-function variables interact alternative-specific catch-function parameters vary across alternatives (e.g., vessel gross  tonnage). (2) 'intdat': travel-distance variables interact  travel-distance parameters distance matrix vary across alternatives. (3) 'prices': price terms $/landings units. typically vector prices observation, can single value representing price entire dataset. alts Number alternative choices model project Name project expname Expected catch table (optional) mod.name Name model run model result output table","code":""},{"path":"/reference/epm_weibull.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expected profit model with Weibull catch function — epm_weibull","text":"ld: negative log likelihood","code":""},{"path":"/reference/epm_weibull.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Expected profit model with Weibull catch function — epm_weibull","text":"function called discretefish_subroutine running EPM model     Weibull catch function.","code":""},{"path":"/reference/erase_project.html","id":null,"dir":"Reference","previous_headings":"","what":"Erase project folder — erase_project","title":"Erase project folder — erase_project","text":"Erase project folder","code":""},{"path":"/reference/erase_project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Erase project folder — erase_project","text":"","code":"erase_project(project)"},{"path":"/reference/erase_project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Erase project folder — erase_project","text":"project Project name.","code":""},{"path":"/reference/expand_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Add missing dates and variable combos to `MainDataTable`. — expand_data","title":"Add missing dates and variable combos to `MainDataTable`. — expand_data","text":"Add missing dates variable combos `MainDataTable`.","code":""},{"path":"/reference/expand_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add missing dates and variable combos to `MainDataTable`. — expand_data","text":"","code":"expand_data(   dataset,   project,   date = NULL,   value,   sub_date = NULL,   period = NULL,   group = NULL,   facet_by = NULL,   fun = \"sum\" )"},{"path":"/reference/expand_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add missing dates and variable combos to `MainDataTable`. — expand_data","text":"dataset Object containing `MainDataTable`. project Name project. date String, name date variable find missing days. value String, name value variable aggregated agg_helper. sub_date String, name date variable subset . period String, name period variable(s). group String, name grouping variable(s). facet_by String, name variable(s) facetted (split).","code":""},{"path":"/reference/expand_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add missing dates and variable combos to `MainDataTable`. — expand_data","text":"function expands data include missing periods/dates   combinations grouping variables used aggregate   data. variables needed aggregate data kept minimize memory usage.   confidentiality checks turned , vessel ID column included   well.","code":""},{"path":"/reference/expected_catch_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Expected Catch List — expected_catch_list","title":"Get Expected Catch List — expected_catch_list","text":"Returns Expected Catch list FishSET database.","code":""},{"path":"/reference/expected_catch_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Expected Catch List — expected_catch_list","text":"","code":"expected_catch_list(project, name = NULL)"},{"path":"/reference/expected_catch_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Expected Catch List — expected_catch_list","text":"project Name project. name Name expected catch table FishSET database. table  name contain string \"ExpectedCatch\". NULL, default  table returned. Use tables_database see list  FishSET database tables project.","code":""},{"path":"/reference/explore_startparams.html","id":null,"dir":"Reference","previous_headings":"","what":"Explore starting value parameter space — explore_startparams","title":"Explore starting value parameter space — explore_startparams","text":"Shotgun method find better parameter starting values exploring starting value      parameter space.","code":""},{"path":"/reference/explore_startparams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explore starting value parameter space — explore_startparams","text":"","code":"explore_startparams(project, space, dev, startsr = NULL)"},{"path":"/reference/explore_startparams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explore starting value parameter space — explore_startparams","text":"project String, name project. space List length 1 length equal number models evaluated. space number starting value permutations test (size space explore). greater dev argument, larger space argument . dev List length 1 length equal number models evaluated. dev refers far deviate average parameter values exploring (random normal deviates). less certain average parameters , greater dev argument . startsr Optional. List, average starting value parameters revenue/location-specific covariates cost/distance. best guess starting value parameters (e.g. ones). Specify starting value parameters model values differetn ones. number starting value parameters correspond likelihood data want test.","code":""},{"path":"/reference/explore_startparams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explore starting value parameter space — explore_startparams","text":"Returns three data frames.","code":""},{"path":"/reference/explore_startparams.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Explore starting value parameter space — explore_startparams","text":"Function used identify better starting parameters   convergence issue. details likelihood functions data, see make_model_design.   Function calls model design file used make_model_design   function called.    one model defined model design file, starting parameters   must defined model.","code":""},{"path":[]},{"path":"/reference/explore_startparams_discrete.html","id":null,"dir":"Reference","previous_headings":"","what":"Explore starting value parameter space — explore_startparams_discrete","title":"Explore starting value parameter space — explore_startparams_discrete","text":"Shotgun method find better parameter starting values exploring starting value      parameter space.","code":""},{"path":"/reference/explore_startparams_discrete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explore starting value parameter space — explore_startparams_discrete","text":"","code":"explore_startparams_discrete(   space,   dev,   breakearly = TRUE,   startsr = NULL,   fr,   d,   otherdat,   choice,   project )"},{"path":"/reference/explore_startparams_discrete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explore starting value parameter space — explore_startparams_discrete","text":"space List length 1 length equal number models evaluated. space number starting value permutations test (size space explore). greater dev argument, larger space argument . dev List length 1 length equal number models evaluated. dev refers far deviate average parameter values exploring (random normal deviates). less certain average parameters , greater dev argument . breakearly Logical, function return first set inits return INF search entire space  return inits lowest LLoglikelihood. startsr Optional. List, average starting value parameters revenue/location-specific covariates cost/distance. best guess starting value parameters (e.g. ones). Specify starting value parameters model values different ones. number starting value parameters correspond likelihood data want test. fr Name likelihood function test. d Data shift_sort_x otherdat data (list, corresponding likelihood function want test). choice Data corresponding actual zonal choice. project Project name","code":""},{"path":"/reference/explore_startparams_discrete.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explore starting value parameter space — explore_startparams_discrete","text":"Returns three data frames.","code":""},{"path":"/reference/explore_startparams_discrete.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Explore starting value parameter space — explore_startparams_discrete","text":"Function used identify better starting parameters   convergence issue. details likelihood functions data, see make_model_design.   Function calls model design file used make_model_design   function called.    one model defined model design file, starting parameters   must defined model.","code":""},{"path":"/reference/exp_catch_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Return names of expected catch matrices — exp_catch_names","title":"Return names of expected catch matrices — exp_catch_names","text":"Return names expected catch matrices saved FishSET database.","code":""},{"path":"/reference/exp_catch_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return names of expected catch matrices — exp_catch_names","text":"","code":"exp_catch_names(project)"},{"path":"/reference/exp_catch_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return names of expected catch matrices — exp_catch_names","text":"project Name project.","code":""},{"path":"/reference/facet_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Create date variables for facetting — facet_period","title":"Create date variables for facetting — facet_period","text":"Create date variables facetting","code":""},{"path":"/reference/facet_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create date variables for facetting — facet_period","text":"","code":"facet_period(dataset, facet_date, date, period = NULL)"},{"path":"/reference/facet_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create date variables for facetting — facet_period","text":"dataset Dataset used create tables/plots function. facet_date String, period facet (\"year\", \"month\", \"week\"). date String, Data variable used convert periods. period String, period name. needed summarizing time.","code":""},{"path":"/reference/file_nm_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check name or file name — file_nm_check","title":"Check name or file name — file_nm_check","text":"Check name file name illegal characters.","code":""},{"path":"/reference/file_nm_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check name or file name — file_nm_check","text":"","code":"file_nm_check(file_nm)"},{"path":"/reference/file_nm_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check name or file name — file_nm_check","text":"file_nm String, file name name check.","code":""},{"path":"/reference/filter_dat.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove rows based on filter expressions defined in 'filterTable' — filter_dat","title":"Remove rows based on filter expressions defined in 'filterTable' — filter_dat","text":"Remove rows based filter expressions defined 'filterTable'","code":""},{"path":"/reference/filter_dat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove rows based on filter expressions defined in 'filterTable' — filter_dat","text":"","code":"filter_dat(dat, project, exp, filterTable = NULL)"},{"path":"/reference/filter_dat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove rows based on filter expressions defined in 'filterTable' — filter_dat","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project Project name. exp filter. May row filter table generated  filter_table contains filter expression filter  expression apply data. filter expression supplied,  take form \"x < 100\" \".na(x) == FALSE\". filterTable Name filter table FishSET database. Name  contain phrase 'filterTable'.","code":""},{"path":"/reference/filter_dat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove rows based on filter expressions defined in 'filterTable' — filter_dat","text":"Filtered data frame","code":""},{"path":"/reference/filter_dat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove rows based on filter expressions defined in 'filterTable' — filter_dat","text":"Filter data frame based predefined filter expression    filter_table filter expression. recommend creating    filter table using filter_table filter expressions    stored easily accessed future.","code":""},{"path":"/reference/filter_dat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove rows based on filter expressions defined in 'filterTable' — filter_dat","text":"","code":"if (FALSE) { newdat <- filter_dat(pcodMainDataTable, 'pcod', exp = 3,                       filterTable = 'pcodfilterTable01012011')                       newdat <- filter_dat(pcodMainDataTable, 'pcod',                       exp = 'PERFORMANCE_Code == 1', filteTable = NULL)                       newdat <- filter_dat(pcodMainDataTable, \"pcod\", exp = \"SEASON == 'A'\",                      filterTable = NULL) }"},{"path":"/reference/filter_outsample.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter out-of-sample data for model predictions — filter_outsample","title":"Filter out-of-sample data for model predictions — filter_outsample","text":"Filter --sample dataset prepare predictions fishing probability.","code":""},{"path":"/reference/filter_outsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter out-of-sample data for model predictions — filter_outsample","text":"","code":"filter_outsample(   dat,   project,   mod.name,   spatial_outsample = FALSE,   zone.dat = NULL,   spat = NULL,   zone.spat = NULL,   outsample_zones = NULL,   lon.spat = NULL,   lat.spat = NULL,   use.scalers = FALSE,   scaler.func = NULL )"},{"path":"/reference/filter_outsample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter out-of-sample data for model predictions — filter_outsample","text":"dat --sample data project Name project mod.name Name saved model use. Argument can name model can pull name  saved \"best\" model. Leave mod.name empty use saved \"best\" model. one model saved, mod.name numeric indicator model use. Use table_view(\"modelChosen\", project) view table saved models. spatial_outsample Logical, indicate whether data --sample spatially .  Note models zone-specific coefficients (e.g., zonal logit) used predict data  --sample spatially. spatial_outsample = FALSE can represent data --sample temporally --sample  based another variable (e.g., vessel tonnage, gear type, etc.) zone.dat Variable datthat identifies individual areas zones. spat Required, data file character.  spat spatial data file containing information fishery  management regulatory zones boundaries. Shape, json, geojson, csv  formats supported. geojson preferred format. json files must  converted geoson. done automatically file loaded  read_dat .map set true. spat  , time, loaded FishSET database. zone.spat Variable spat identifies individual areas zones. outsample_zones Vector --sample zones filter dat. provided input running function main app. lon.spat Required csv files. Variable list spat  containing longitude data. Leave NULL spat shape json file. lat.spat Required csv files. Variable list spat  containing latitude data.  Leave NULL spat shape json file. use.scalers Input create_model_input(). Logical, data normalized? Defaults FALSE. Rescaling factors mean  numeric vector unless specified scaler.func. scaler.func Input create_model_input(). Function calculate rescaling factors.","code":""},{"path":"/reference/filter_outsample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter out-of-sample data for model predictions — filter_outsample","text":"Returns probability logit model choice","code":""},{"path":"/reference/filter_outsample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Filter out-of-sample data for model predictions — filter_outsample","text":"function filters --sample data. data --sample spatially, set spatial_outsample = TRUE  provide spatial file (spat) zone id spatial file zone.spat. interactive map used selecting sample zones. data spatially --sample, just filter data zones included selected model. Note  models zone-specific coefficients (e.g., zonal logit) predict spatial --sample data. Upon successful execution  filter_outsample() filtered dataset saved RDS file outputs folder. function overwrite existing RDS file time run.","code":""},{"path":"/reference/filter_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Select function calls to display — filter_summary","title":"Select function calls to display — filter_summary","text":"Select function calls display","code":""},{"path":"/reference/filter_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select function calls to display — filter_summary","text":"","code":"filter_summary(sum_tab, filter_list)"},{"path":"/reference/filter_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select function calls to display — filter_summary","text":"sum_tab Summary table filter. filter_list named list integers. list entry contain name function row number(s) filter . example, list(temporal_mod = 2) display second row  temporal_mod dataframe summary list.","code":""},{"path":[]},{"path":"/reference/filter_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select function calls to display — filter_summary","text":"","code":"if (FALSE) { filter_summary(function_summary(),               filter_list = list(set_quants = 2, temporal_mod = 2)) }"},{"path":"/reference/filter_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Define and store filter expressions — filter_table","title":"Define and store filter expressions — filter_table","text":"Define store filter expressions","code":""},{"path":"/reference/filter_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define and store filter expressions — filter_table","text":"","code":"filter_table(dat, project, x, exp)"},{"path":"/reference/filter_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define and store filter expressions — filter_table","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. x Variable dat filter applied. exp Filter expression. take form \"x < 100\"  \".na(x) == FALSE\".","code":""},{"path":"/reference/filter_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define and store filter expressions — filter_table","text":"Filter expressions saved table FishSET database.","code":""},{"path":"/reference/filter_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define and store filter expressions — filter_table","text":"function allows users define store data filter expressions    can applied data. filter table saved    FishSET database project name `filterTable`.    new filter functions added time function run table    automatically updated FishSET database. function call    logged log file.","code":""},{"path":"/reference/filter_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define and store filter expressions — filter_table","text":"","code":"if (FALSE) { filter_table(pcodMainDataTable, 'pcod', x = 'PERFORMANCE_Code',              exp = 'PERFORMANCE_Code == 1') }"},{"path":"/reference/find_catch.html","id":null,"dir":"Reference","previous_headings":"","what":"Find columns that may contain catch — find_catch","title":"Find columns that may contain catch — find_catch","text":"Find columns may contain catch","code":""},{"path":"/reference/find_catch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find columns that may contain catch — find_catch","text":"","code":"find_catch(dat)"},{"path":"/reference/find_catch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find columns that may contain catch — find_catch","text":"dat Dataset search ","code":""},{"path":"/reference/find_centroid.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify geographic centroid of fishery management or regulatory zone — find_centroid","title":"Identify geographic centroid of fishery management or regulatory zone — find_centroid","text":"Identify geographic centroid fishery management regulatory zone","code":""},{"path":"/reference/find_centroid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify geographic centroid of fishery management or regulatory zone — find_centroid","text":"","code":"find_centroid(   spat,   project,   spatID,   lon.spat = NULL,   lat.spat = NULL,   cent.name = NULL,   log.fun = TRUE )"},{"path":"/reference/find_centroid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify geographic centroid of fishery management or regulatory zone — find_centroid","text":"spat Spatial data containing information fishery management  regulatory zones. Can shape file, json, geojson, data frame, list. project Name project spatID Variable list spat identifies individual areas  zones. spat class sf, spatID name list  containing information zones. lon.spat Variable list spat containing longitude data.  Required csv files. Leave NULL spat shape json file. lat.spat Variable list spat containing latitude data.  Required csv files. Leave NULL spat shape json file. cent.name String, name include centroid table. Centroid name take  form `\"projectNameZoneCentroid\"`. Defaults `NULL`  (e.g. `\"projectZoneCentroid\"`). log.fun Logical, whether log function call (internal use).","code":""},{"path":"/reference/find_centroid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify geographic centroid of fishery management or regulatory zone — find_centroid","text":"Returns data frame row unique zone columns    zone ID latitude longitude defining centroid zone.","code":""},{"path":"/reference/find_centroid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify geographic centroid of fishery management or regulatory zone — find_centroid","text":"Returns geographic centroid area/zone spat.    centroid table saved FishSET database. Function called    create_alternative_choice create_dist_between functions.","code":""},{"path":"/reference/find_datetime.html","id":null,"dir":"Reference","previous_headings":"","what":"Find columns that may be date/datetime — find_datetime","title":"Find columns that may be date/datetime — find_datetime","text":"Find columns may date/datetime","code":""},{"path":"/reference/find_datetime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find columns that may be date/datetime — find_datetime","text":"","code":"find_datetime(dat)"},{"path":"/reference/find_datetime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find columns that may be date/datetime — find_datetime","text":"dat Dataset search ","code":""},{"path":"/reference/find_dev.html","id":null,"dir":"Reference","previous_headings":"","what":"Find how many standard deviations point x is from mean of y. — find_dev","title":"Find how many standard deviations point x is from mean of y. — find_dev","text":"Find many standard deviations point x mean y.","code":""},{"path":"/reference/find_dev.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find how many standard deviations point x is from mean of y. — find_dev","text":"","code":"find_dev(x, y)"},{"path":"/reference/find_dev.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find how many standard deviations point x is from mean of y. — find_dev","text":"x value check y data vector. Must numeric","code":""},{"path":"/reference/find_duration.html","id":null,"dir":"Reference","previous_headings":"","what":"Find columns that may contain durations — find_duration","title":"Find columns that may contain durations — find_duration","text":"Find columns may contain durations","code":""},{"path":"/reference/find_duration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find columns that may contain durations — find_duration","text":"","code":"find_duration(dat)"},{"path":"/reference/find_duration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find columns that may contain durations — find_duration","text":"dat Dataset search ","code":""},{"path":"/reference/find_first.html","id":null,"dir":"Reference","previous_headings":"","what":"Find earliest date — find_first","title":"Find earliest date — find_first","text":"Find earliest date","code":""},{"path":"/reference/find_first.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find earliest date — find_first","text":"","code":"find_first(y)"},{"path":"/reference/find_first.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find earliest date — find_first","text":"y variable interest","code":""},{"path":"/reference/find_fishing_centroid.html","id":null,"dir":"Reference","previous_headings":"","what":"Create fishing or weighted fishing centroid — find_fishing_centroid","title":"Create fishing or weighted fishing centroid — find_fishing_centroid","text":"Create fishing weighted fishing centroid","code":""},{"path":"/reference/find_fishing_centroid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create fishing or weighted fishing centroid — find_fishing_centroid","text":"","code":"find_fishing_centroid(   dat,   project,   zoneID,   weight.var = NULL,   lon.dat,   lat.dat,   names = NULL,   cent.name = NULL,   log.fun = TRUE )"},{"path":"/reference/find_fishing_centroid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create fishing or weighted fishing centroid — find_fishing_centroid","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project Name project zoneID Variable dat identifies zonal assignments  spat class sf, zoneID name list containing  information zones. weight.var Variable dat weighted average.  weight.var defined, centroid defined latitude  longitude fishing locations zone weighted weight.var. lon.dat Required. Longitude variable dat. lat.dat Required. Latitude variable dat. names names fishing centroid columns added. vector length two order c(\"lon\", \"lat\"). default  c(\"fish_cent_lon\", \"fish_cent_lat\")  c(\"weight_cent_lon\", \"weight_cent_lat\") weight.var used. cent.name string include centroid table name. Table names  take form `\"projectNameFishCentroid\"` fishing centroids. log.fun Logical, whether log function call (internal use).","code":""},{"path":"/reference/find_fishing_centroid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create fishing or weighted fishing centroid — find_fishing_centroid","text":"Returns primary dataset fishing centroid , weight.var specified, weighted fishing centroid.","code":""},{"path":"/reference/find_fishing_centroid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create fishing or weighted fishing centroid — find_fishing_centroid","text":"Fishing centroid defines centroid mean latitude longitude    fishing locations zone. Weighted centroid defines centroid    mean latitude longitude fishing locations zone weighted    weight.var. fishing weighted centroid variables can    used anywhere latitude/longitude variables appear. observation    dat must assigned fishery regulatory area/zone. zone    identifier exists dat called 'ZoneID',     zoneID variable name containing zone identifier.    zone identifier variable exist dat, spat must    specified zoneID must zone identifier spat.    assignment_column function run zone identifier variable    added dat.","code":""},{"path":"/reference/find_last.html","id":null,"dir":"Reference","previous_headings":"","what":"Find latest date — find_last","title":"Find latest date — find_last","text":"Find latest date","code":""},{"path":"/reference/find_last.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find latest date — find_last","text":"","code":"find_last(y)"},{"path":"/reference/find_last.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find latest date — find_last","text":"y variable interest","code":""},{"path":"/reference/find_lat.html","id":null,"dir":"Reference","previous_headings":"","what":"Find columns that may be latitude data — find_lat","title":"Find columns that may be latitude data — find_lat","text":"Find columns may latitude data","code":""},{"path":"/reference/find_lat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find columns that may be latitude data — find_lat","text":"","code":"find_lat(dat)"},{"path":"/reference/find_lat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find columns that may be latitude data — find_lat","text":"dat Data set search ","code":""},{"path":"/reference/find_lon.html","id":null,"dir":"Reference","previous_headings":"","what":"Find columns that may be longitude data — find_lon","title":"Find columns that may be longitude data — find_lon","text":"Find columns may longitude data","code":""},{"path":"/reference/find_lon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find columns that may be longitude data — find_lon","text":"","code":"find_lon(dat)"},{"path":"/reference/find_lon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find columns that may be longitude data — find_lon","text":"dat Data set search ","code":""},{"path":"/reference/find_lonlat.html","id":null,"dir":"Reference","previous_headings":"","what":"Find columns that may be longitude or latitude data — find_lonlat","title":"Find columns that may be longitude or latitude data — find_lonlat","text":"Find columns may longitude latitude data","code":""},{"path":"/reference/find_lonlat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find columns that may be longitude or latitude data — find_lonlat","text":"","code":"find_lonlat(dat)"},{"path":"/reference/find_lonlat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find columns that may be longitude or latitude data — find_lonlat","text":"dat Dataset search ","code":""},{"path":"/reference/find_original_name.html","id":null,"dir":"Reference","previous_headings":"","what":"find original name — find_original_name","title":"find original name — find_original_name","text":"find original name","code":""},{"path":"/reference/find_original_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"find original name — find_original_name","text":"","code":"find_original_name(fun)"},{"path":"/reference/find_original_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"find original name — find_original_name","text":"fun function","code":""},{"path":"/reference/find_port.html","id":null,"dir":"Reference","previous_headings":"","what":"Find columns that may contain ports — find_port","title":"Find columns that may contain ports — find_port","text":"Find columns may contain ports","code":""},{"path":"/reference/find_port.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find columns that may contain ports — find_port","text":"","code":"find_port(dat)"},{"path":"/reference/find_port.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find columns that may contain ports — find_port","text":"dat Dataset search ","code":""},{"path":"/reference/find_project.html","id":null,"dir":"Reference","previous_headings":"","what":"Find project — find_project","title":"Find project — find_project","text":"Find project","code":""},{"path":"/reference/find_project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find project — find_project","text":"","code":"find_project(dat, project = NULL)"},{"path":"/reference/find_project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find project — find_project","text":"dat Data table name project Project Name","code":""},{"path":"/reference/find_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Find columns that may contain value — find_value","title":"Find columns that may contain value — find_value","text":"Find columns may contain value","code":""},{"path":"/reference/find_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find columns that may contain value — find_value","text":"","code":"find_value(dat)"},{"path":"/reference/find_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find columns that may contain value — find_value","text":"dat Dataset search ","code":""},{"path":"/reference/fishset_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare imported data table to the previously saved version of the data table — fishset_compare","title":"Compare imported data table to the previously saved version of the data table — fishset_compare","text":"Compare imported data table previously saved version data table","code":""},{"path":"/reference/fishset_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare imported data table to the previously saved version of the data table — fishset_compare","text":"","code":"fishset_compare(x, y, compare = c(TRUE, FALSE), project)"},{"path":"/reference/fishset_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare imported data table to the previously saved version of the data table — fishset_compare","text":"x Updated data table saved. y Previously saved version data table. compare Logical, TRUE, compares x y saving x FishSET database. project Name project","code":""},{"path":"/reference/fishset_compare.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare imported data table to the previously saved version of the data table — fishset_compare","text":"Function optional. designed check consistency versions data frame logged functions can used rerun previous analysis updated data. column names, including spelling capitalization, must match previous version use logged functions rerun code data updated (.e., new year data). function called data import functions (load_maindata, load_port, load_aux, load_grid).  Set compare argument TRUE compare column names new previously saved data tables. new data tables saved FishSET database column names match. Set compare argument FALSE previous versions data table exist FishSET database. comparison made new file saved database.","code":""},{"path":"/reference/fishset_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Show all SQL Tables in FishSET Folder — fishset_tables","title":"Show all SQL Tables in FishSET Folder — fishset_tables","text":"Returns data frame containing tables project project name table type.","code":""},{"path":"/reference/fishset_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show all SQL Tables in FishSET Folder — fishset_tables","text":"","code":"fishset_tables(project = NULL)"},{"path":"/reference/fishset_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show all SQL Tables in FishSET Folder — fishset_tables","text":"project Project name. NULL, tables available projects  displayed.","code":""},{"path":"/reference/fishset_tables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show all SQL Tables in FishSET Folder — fishset_tables","text":"","code":"if (FALSE) { # return all tables for all projects fishset_tables()  # return all tables for a specific project fishset_tables(\"pollock\") }"},{"path":"/reference/fishset_theme.html","id":null,"dir":"Reference","previous_headings":"","what":"Default FishSET plot theme — fishset_theme","title":"Default FishSET plot theme — fishset_theme","text":"Default FishSET plot theme","code":""},{"path":"/reference/fishset_theme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default FishSET plot theme — fishset_theme","text":"","code":"fishset_theme()"},{"path":"/reference/fishset_viridis.html","id":null,"dir":"Reference","previous_headings":"","what":"viridis color function — fishset_viridis","title":"viridis color function — fishset_viridis","text":"viridis color function","code":""},{"path":"/reference/fishset_viridis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"viridis color function — fishset_viridis","text":"","code":"fishset_viridis(n)"},{"path":"/reference/fishset_viridis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"viridis color function — fishset_viridis","text":"n data","code":""},{"path":"/reference/fleet_assign.html","id":null,"dir":"Reference","previous_headings":"","what":"Create fleet variable using fleet definition table — fleet_assign","title":"Create fleet variable using fleet definition table — fleet_assign","text":"Add fleet ID column main data using fleet table (see fleet_table  details).","code":""},{"path":"/reference/fleet_assign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create fleet variable using fleet definition table — fleet_assign","text":"","code":"fleet_assign(   dat,   project,   fleet_tab,   assign = NULL,   overlap = FALSE,   format_var = \"string\" )"},{"path":"/reference/fleet_assign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create fleet variable using fleet definition table — fleet_assign","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project String, name project. fleet_tab String, name fleet table stored FishSET database.  contain string `FleetTable`. assign Integer, vector row numbers fleet_tab.  fleet definitions rows used added `MainDataTable`.  assign = NULL (default), fleet definitions table  used. overlap Logical; whether overlapping fleet assignments allowed.  Defaults FALSE. format_var String. format_var = \"string\", single column named  \"fleet\" added `MainDataTable`. overlap = TRUE,   observations multiple fleet assignments duplicated. format_var =\"dummy\"    outputs binary column fleet fleet table. Defaults \"string\".","code":""},{"path":"/reference/fleet_assign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create fleet variable using fleet definition table — fleet_assign","text":"Returns primary dataset added fleet variable(s).","code":""},{"path":[]},{"path":"/reference/fleet_assign.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create fleet variable using fleet definition table — fleet_assign","text":"","code":"if (FALSE) { fleet_assign(pollockMainDataTable, 'pollock', fleet_tab = 'pollockFleetTable',               overlap = TRUE) }"},{"path":"/reference/fleet_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Define and store fleet expressions — fleet_table","title":"Define and store fleet expressions — fleet_table","text":"fleet_table saves table fleet expression FishSET   database can applied dataset fleet_assign.    table must contain 'condition' 'fleet' column row corresponding    set expressions used assign observations fleets.    table can created cond fleet_val arguments    uploading existing table matches format requirements. See    'Details' examples tables can formatted.","code":""},{"path":"/reference/fleet_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define and store fleet expressions — fleet_table","text":"","code":"fleet_table(   dat,   project,   cond = NULL,   fleet_val = NULL,   table = NULL,   save = TRUE )"},{"path":"/reference/fleet_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define and store fleet expressions — fleet_table","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project String, name project. cond String; vector containing valid R expressions saved strings.  Must used fleet_val argument. expression  quotes (double single) nested quotes indicated escaped quotes  (\\') opposite quote used contain expression. example,  \"species == 'cod'\" \"species == \\'cod\\'\" valid. fleet_val String; vector fleet names assigned. Must used  cond argument. table data frame one condition column one fleet column. See 'Details' table formatting. save Logical; whether save current fleet_table FishSET  database. Defaults TRUE. Tables saved format  'projectFleetTable'. project can one fleet table. New fleet  definitions appended exiting fleet table. See table_remove  delete table.","code":""},{"path":"/reference/fleet_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define and store fleet expressions — fleet_table","text":"Returns table fleet conditions saved FishSET database    name 'projectFleetTable'.","code":""},{"path":"/reference/fleet_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define and store fleet expressions — fleet_table","text":"simple example fleet table. fleet table created,    must contain one \"condition\" column one \"fleet\" column. fleet    definition can long necessary. example, first expression    condition column example also \"GEAR == 8 & species == 'pollock'\".    Use '&' operator combining expressions.","code":""},{"path":"/reference/fleet_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define and store fleet expressions — fleet_table","text":"","code":"if (FALSE) {  fleet_table(\"MainDataTable\", \"myProject\",              cond = c(\"GEAR == 8\", \"species == 'cod'\", \"area %in% c(640, 620)\"),             fleet_val = c(\"A\", \"B\", \"C\"), save = TRUE             )  }"},{"path":"/reference/format_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Format Gridded Data — format_grid","title":"Format Gridded Data — format_grid","text":"Change format gridded dataset wide long (vice versa) remove unmatched area/zones grid. necessary step including gridded variables conditional logit (logit_c()) model.","code":""},{"path":"/reference/format_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format Gridded Data — format_grid","text":"","code":"format_grid(   grid,   dat,   project,   dat.key,   area.dat,   area.grid = NULL,   id.cols,   from.format = \"wide\",   to.format = \"wide\",   val.name = NULL,   save = FALSE )"},{"path":"/reference/format_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format Gridded Data — format_grid","text":"grid Gridded dataset format. dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Name project. dat.key String, name column(s) MainDataTable join . number columns must match id.cols. area.dat String, name area zone column dat. area.grid String, name area zone column dat .format = \"long\". Ignored .format = \"wide\". id.cols String, names columns grid neither area (area.grid) value (val.name) columns, example date period column(s). .format original format grid. Options include \"long\" \"wide\". Use \"long\" single area column exists grid. Use \"wide\" grid contains column area. .format desired format grid. Options include \"long\" \"wide\". Use \"long\" want single area column corresponding value column. Use \"wide\" like area column. val.name Required converting wide long long wide format. .format = \"wide\" .format = \"long\", val.name name new value variable associated area column.  .format = \"long\" .format = \"wide\", val.name name existing value variable associated area column. save Logical, whether save formatted grid. TRUE, table saved string \"Wide\" \"Long\" appended depending value .format.","code":""},{"path":[]},{"path":"/reference/format_outsample_coefs.html","id":null,"dir":"Reference","previous_headings":"","what":"Reformat out-of-sample model coefficients — format_outsample_coefs","title":"Reformat out-of-sample model coefficients — format_outsample_coefs","text":"Reformat --sample model coefficients removing zones included --sample dataset","code":""},{"path":"/reference/format_outsample_coefs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reformat out-of-sample model coefficients — format_outsample_coefs","text":"","code":"format_outsample_coefs(in_zones, out_zones, Eq, likelihood)"},{"path":"/reference/format_outsample_coefs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reformat out-of-sample model coefficients — format_outsample_coefs","text":"in_zones Vector zoneIDs -sample dataset out_zones Vector zoneIDs --sample dataset Eq Tibble containing estimated model coefficients (including standard errors t-values) likelihood Character, name likelihood","code":""},{"path":"/reference/format_outsample_coefs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reformat out-of-sample model coefficients — format_outsample_coefs","text":"Return list (1) vector coefficients (zones --sample dataset removed)  (2) flag indicating first alt (-sample dataset) included --sample dataset.","code":""},{"path":"/reference/freq_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a binned frequency table — freq_table","title":"Create a binned frequency table — freq_table","text":"Create binned frequency, relative frequency, density table.","code":""},{"path":"/reference/freq_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a binned frequency table — freq_table","text":"","code":"freq_table(   dataset,   var,   group = NULL,   bins = 30,   type = \"dens\",   v_id = NULL,   format_lab = \"decimal\",   format_tab = \"wide\" )"},{"path":"/reference/freq_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a binned frequency table — freq_table","text":"dataset Primary data containing information hauls trips. Table FishSET database contain string `MainDataTable`. var String, name numeric variable bin. group String, name variable(s) group var . bins Integer, number bins create. type String, type binned frequency table create. \"freq\" creates frequency table, \"perc\" creates relative frequency table, \"dens\" creates density table. v_id String, name vessel ID column (used detect confidential information). format_lab Formatting option bin labels. Options include  \"decimal\" \"scientific\". format_tab Format table \"wide\" \"long\"","code":""},{"path":"/reference/function_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Display summary of function calls — function_summary","title":"Display summary of function calls — function_summary","text":"Display summary function calls","code":""},{"path":"/reference/function_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display summary of function calls — function_summary","text":"","code":"function_summary(project, date = NULL, type = \"dat_load\", show = \"all\")"},{"path":"/reference/function_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display summary of function calls — function_summary","text":"project Project name. date Character string; date log file (\" retrieve. NULL recent log pulled. type type function display. \"dat_load\", \"dat_quality\", \"dat_create\", \"dat_exploration\", \"fleet\", \"model\". show Whether display \"\" calls, \"last\" (recent) call, \"first\" (oldest) function call log file.","code":""},{"path":"/reference/function_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Display summary of function calls — function_summary","text":"Displays list functions type arguments log file.   date entered recent log file pulled.","code":""},{"path":[]},{"path":"/reference/function_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display summary of function calls — function_summary","text":"","code":"if (FALSE) { function_summary(\"pollock\") }"},{"path":"/reference/getis_ord_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate and view Getis-Ord statistic — getis_ord_stats","title":"Calculate and view Getis-Ord statistic — getis_ord_stats","text":"Wrapper function calculate global local Getis-Ord discrete area","code":""},{"path":"/reference/getis_ord_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate and view Getis-Ord statistic — getis_ord_stats","text":"","code":"getis_ord_stats(   dat,   project,   varofint,   zoneid,   spat,   cat,   lon.dat = NULL,   lat.dat = NULL,   lon.spat = NULL,   lat.spat = NULL )"},{"path":"/reference/getis_ord_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate and view Getis-Ord statistic — getis_ord_stats","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. varofint Numeric variable dat test spatial high/low clustering. zoneid Variable dat identifies individual zones  areas. Define exists dat named `ZoneID`. Defaults NULL. spat Spatial data containing information fishery management  regulatory zones. See load_spatial. cat Variable spat defining individual areas zones. lon.dat Longitude variable dat.Require zoneid defined. lat.dat Latitude variable dat. Require zoneid defined. lon.spat Variable list spat containing longitude data. Required csv files. Leave NULL spat shape json file. lat.spat Variable list spat containing latitude data. Required csv files. Leave NULL spat shape json file.","code":""},{"path":"/reference/getis_ord_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate and view Getis-Ord statistic — getis_ord_stats","text":"Returns plot table. saved output folder.","code":""},{"path":"/reference/getis_ord_stats.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate and view Getis-Ord statistic — getis_ord_stats","text":"Calculates degree, within zone, high low values   varofint cluster space. Function utilizes localG    knearneigh functions spdep package.    spatial input row-standardized spatial weights matrix computed nearest    neighbor matrix, null setting nb2listw   function. Requires data frame area factor, lon/lat centroid    area, lat/lon outlining area, variable interest    (varofint) map file lat/lon defining boundaries area/zones    variable interest weighting. Also required lat/lon defining    center zone/area. centroid included map file,    find_centroid can called calculate centroid    zone. variable interest associated area/zone    assignment_column function can used assign    observation zone. Arguments identify centroid assign variable    interest area/zone optional default NULL.","code":""},{"path":"/reference/getis_ord_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate and view Getis-Ord statistic — getis_ord_stats","text":"","code":"if (FALSE) { getis_ord_stats(pcodMainDataTable, project = 'pcod', varofint = 'OFFICIAL_MT_TONS',   spat = spatdat, lon.dat = 'LonLat_START_LON', lat.dat = 'LonLat_START_LAT', cat = 'NMFS_AREA') }"},{"path":"/reference/get_closure_scenario.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve closure scenario by project — get_closure_scenario","title":"Retrieve closure scenario by project — get_closure_scenario","text":"Retrieve closure scenario project","code":""},{"path":"/reference/get_closure_scenario.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve closure scenario by project — get_closure_scenario","text":"","code":"get_closure_scenario(project)"},{"path":"/reference/get_closure_scenario.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve closure scenario by project — get_closure_scenario","text":"project Name project.","code":""},{"path":"/reference/get_closure_scenario.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve closure scenario by project — get_closure_scenario","text":"","code":"if (FALSE) { get_closure_scenario(\"pollock\") }"},{"path":"/reference/get_confid_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Return cached confidentiality tables — get_confid_cache","title":"Return cached confidentiality tables — get_confid_cache","text":"function lists confidentiality \"check\" tables used suppress values.","code":""},{"path":"/reference/get_confid_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return cached confidentiality tables — get_confid_cache","text":"","code":"get_confid_cache(project, show = \"all\")"},{"path":"/reference/get_confid_cache.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return cached confidentiality tables — get_confid_cache","text":"project Name project show Output \"\" tables, \"last\" table, \"first\" table.","code":""},{"path":"/reference/get_confid_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return cached confidentiality tables — get_confid_cache","text":"list tables containing suppression conditions.","code":""},{"path":[]},{"path":"/reference/get_confid_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the confidentiality settings — get_confid_check","title":"Return the confidentiality settings — get_confid_check","text":"function returns confidentiality settings project settings file.","code":""},{"path":"/reference/get_confid_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the confidentiality settings — get_confid_check","text":"","code":"get_confid_check(project)"},{"path":"/reference/get_confid_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the confidentiality settings — get_confid_check","text":"project Name project","code":""},{"path":"/reference/get_confid_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the confidentiality settings — get_confid_check","text":"list containing confidentiality parameters: check,  v_id, rule, value.","code":""},{"path":[]},{"path":"/reference/get_grid_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve grid log file — get_grid_log","title":"Retrieve grid log file — get_grid_log","text":"Retrieves grid log file project. grid log shows grid  files currently saved project data folder.","code":""},{"path":"/reference/get_grid_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve grid log file — get_grid_log","text":"","code":"get_grid_log(project)"},{"path":"/reference/get_grid_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve grid log file — get_grid_log","text":"project Name project.","code":""},{"path":"/reference/get_grid_log.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve grid log file — get_grid_log","text":"grid log list containing information grid files    currently saved project data folder. grid entry contains three    fields: grid_name, closure_name, combined_areas.    grid_name name original grid object. two   fields empty, means grid file altered    original. closure_name name second    grid file containing closure areas combined grid_name.    combined_areas names/IDs closures areas     closure grid file combined grid_name.","code":""},{"path":"/reference/get_grid_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve grid log file — get_grid_log","text":"","code":"if (FALSE) { get_grid_log(\"pollock\") }"},{"path":"/reference/get_latest_projectfile.html","id":null,"dir":"Reference","previous_headings":"","what":"Pull data from latest project file — get_latest_projectfile","title":"Pull data from latest project file — get_latest_projectfile","text":"Pull data latest project file","code":""},{"path":"/reference/get_latest_projectfile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pull data from latest project file — get_latest_projectfile","text":"","code":"get_latest_projectfile(project, mod.name)"},{"path":"/reference/get_latest_projectfile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pull data from latest project file — get_latest_projectfile","text":"project Project name mod.name Model name","code":""},{"path":"/reference/get_latest_projectfile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pull data from latest project file — get_latest_projectfile","text":"","code":"if (FALSE) { get_latest_projectfile(\"pollock\", \"logit_mod1\") }"},{"path":"/reference/get_proj_settings.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve project settings — get_proj_settings","title":"Retrieve project settings — get_proj_settings","text":"Retrieve project settings","code":""},{"path":"/reference/get_proj_settings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve project settings — get_proj_settings","text":"","code":"get_proj_settings(project, format = FALSE)"},{"path":"/reference/get_proj_settings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve project settings — get_proj_settings","text":"project Name project. format Logical, output project settings using pander. Useful markdown documents.","code":""},{"path":"/reference/get_proj_settings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve project settings — get_proj_settings","text":"project settings file includes confidentiality settings,  user output folder directory, default plot saving size.","code":""},{"path":"/reference/get_user_locoutput.html","id":null,"dir":"Reference","previous_headings":"","what":"Print user folder directory — get_user_locoutput","title":"Print user folder directory — get_user_locoutput","text":"Print user folder directory","code":""},{"path":"/reference/get_user_locoutput.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print user folder directory — get_user_locoutput","text":"","code":"get_user_locoutput(project)"},{"path":"/reference/get_user_locoutput.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print user folder directory — get_user_locoutput","text":"project Name project.","code":""},{"path":"/reference/get_user_locoutput.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print user folder directory — get_user_locoutput","text":"function prints local user directory saved project  settings file. directory path used inserting plots tables   folder outside FishSET package FishSET RMarkdown Template.","code":""},{"path":"/reference/globalcheck_view.html","id":null,"dir":"Reference","previous_headings":"","what":"View error output from discrete choice model for the defined project — globalcheck_view","title":"View error output from discrete choice model for the defined project — globalcheck_view","text":"Returns error output running discretefish_subroutine  function. table argument must full name table name  FishSET database. Use tables_databaseto view table names  FishSET database.","code":""},{"path":"/reference/globalcheck_view.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View error output from discrete choice model for the defined project — globalcheck_view","text":"","code":"globalcheck_view(table, project)"},{"path":"/reference/globalcheck_view.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View error output from discrete choice model for the defined project — globalcheck_view","text":"table Table name FishSET database. contain project,    phrase 'LDGlobalCheck', date YMD format (20200101).  Table name must quotes. project Name project","code":""},{"path":"/reference/globalcheck_view.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View error output from discrete choice model for the defined project — globalcheck_view","text":"","code":"if (FALSE) { globalcheck_view('pcodLDGlobalCheck20190604', 'pcod') }"},{"path":"/reference/gridcheck.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that spatial data is a sf object. Convert if not. — gridcheck","title":"Check that spatial data is a sf object. Convert if not. — gridcheck","text":"Check spatial data sf object. Convert .","code":""},{"path":"/reference/gridcheck.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that spatial data is a sf object. Convert if not. — gridcheck","text":"","code":"gridcheck(   spatialdat,   catdat,   londat = NULL,   latdat = NULL,   lon.grid = NULL,   lat.grid = NULL )"},{"path":"/reference/gridcheck.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that spatial data is a sf object. Convert if not. — gridcheck","text":"spatialdat spatial dataframe catdat Variable names polygons londat Longitude data primary dataset latdat Latitude data primary dataset lon.grid Variable spatialdat containing longitude data lat.grid Variable spatialdat containing latitude data","code":""},{"path":"/reference/grid_lab_helper.html","id":null,"dir":"Reference","previous_headings":"","what":"Labeling function for saving grid files — grid_lab_helper","title":"Labeling function for saving grid files — grid_lab_helper","text":"Labeling function saving grid files","code":""},{"path":"/reference/grid_lab_helper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Labeling function for saving grid files — grid_lab_helper","text":"","code":"grid_lab_helper(project, grid_info, grid_log = NULL, mod_type = \"combine\")"},{"path":"/reference/grid_lab_helper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Labeling function for saving grid files — grid_lab_helper","text":"project Name project. grid_info List containing grid information. grid_log Optional, grid log. NULL, uses names  grid_info. mod_type String, \"combine\" combined map files \"edit\"  edited map files.","code":""},{"path":"/reference/group_cumsum.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a within-group running sum variable — group_cumsum","title":"Create a within-group running sum variable — group_cumsum","text":"Create within-group running sum variable","code":""},{"path":"/reference/group_cumsum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a within-group running sum variable — group_cumsum","text":"","code":"group_cumsum(   dat,   project,   group,   sort_by,   value,   name = \"group_cumsum\",   create_group_ID = FALSE,   drop_total_col = FALSE )"},{"path":"/reference/group_cumsum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a within-group running sum variable — group_cumsum","text":"dat Primaryy data frame apply function. Table FishSET  database contain string `MainDataTable`. project String, project name. group String, grouping variable(s) sum value . Used create  \"group_total\" variable. sort_by String, date variable order `MainDataTable` . value String, value variable used calculate cumulative sum. Must numeric. name String, name new variable. Defaults \"group_cumsum\". create_group_ID Logical, whether create group ID variable using ID_var. Defaults FALSE. drop_total_col Logical, whether remove \"group_total\" variable created calculate percentage. Defaults FALSE.","code":""},{"path":"/reference/group_cumsum.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a within-group running sum variable — group_cumsum","text":"group_cumsum sums value group, cumulatively   sums within groups. example, running sum trip variable can made    entering   variables identify unique vessels trips group numeric   variable (catch # hauls) value. vessel's   trip total calculated cumulatively summed. \"group_total\" variable    gives total value group can dropped setting drop_total_col = TRUE.   group ID column can created using variables group setting   create_group_ID = TRUE.","code":""},{"path":"/reference/group_cumsum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a within-group running sum variable — group_cumsum","text":"","code":"if (FALSE) { group_cumsum(pollockMainDataTable, \"pollock\", group = c(\"PERMIT\", \"TRIP_ID\"),              sort_by = \"HAUL_DATE\", value = \"OFFICIAL_TOTAL_CATCH\") }"},{"path":"/reference/group_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a within-group lagged difference variable — group_diff","title":"Create a within-group lagged difference variable — group_diff","text":"Create within-group lagged difference variable","code":""},{"path":"/reference/group_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a within-group lagged difference variable — group_diff","text":"","code":"group_diff(   dat,   project,   group,   sort_by,   value,   name = \"group_diff\",   lag = 1,   create_group_ID = FALSE,   drop_total_col = FALSE )"},{"path":"/reference/group_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a within-group lagged difference variable — group_diff","text":"dat Primary data frame apply function. Table FishSET  database contain string `MainDataTable`. project String, project name. group String, grouping variable(s) sum value . Used create  \"group_total\" variable. sort_by String, date variable order `MainDataTable` . value String, value variable used calculate lagged difference. Must numeric. name String, name new variable. Defaults \"group_diff\". lag Integer, adjusts lag length. Defaults 1. create_group_ID Logical, whether create group ID variable using ID_var. Defaults FALSE. drop_total_col Logical, whether remove \"group_total\" variable created calculate percentage. Defaults FALSE.","code":""},{"path":"/reference/group_diff.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a within-group lagged difference variable — group_diff","text":"group_diff creates grouped lagged difference variable. value   first summed variable(s) group, difference within-group    calculated. \"group_total\" variable gives total value group can   dropped setting drop_total_col = TRUE. group ID column can    created using variables group setting create_group_ID = TRUE.","code":""},{"path":"/reference/group_diff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a within-group lagged difference variable — group_diff","text":"","code":"if (FALSE) { group_diff(pollockMainDataTable, \"pollock\", group = c(\"PERMIT\", \"TRIP_ID\"),            sort_by = \"HAUL_DATE\", value = \"HAUL\") }"},{"path":"/reference/group_perc.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a within-group percentage variable — group_perc","title":"Create a within-group percentage variable — group_perc","text":"Create within-group percentage variable","code":""},{"path":"/reference/group_perc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a within-group percentage variable — group_perc","text":"","code":"group_perc(   dat,   project,   id_group,   group = NULL,   value,   name = \"group_perc\",   create_group_ID = FALSE,   drop_total_col = FALSE )"},{"path":"/reference/group_perc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a within-group percentage variable — group_perc","text":"dat Main data frame apply function. Table FishSET  database contain string `MainDataTable`. project String, project name. id_group String, primary grouping variable(s). Used create \"total_value\"  variable sums value id_group. group = NULL,  value divided \"total_value\". group String, secondary grouping variable(s). Used create \"group_total\"  variable sums value id_group group. Percentage  calculated dividing \"group_total\" \"total_value\". Defaults NULL. value String, value variable used calculate percentage. Must numeric. name String, name new variable. Defaults \"group_perc\". create_group_ID Logical, whether create group ID variable using ID_var. Defaults FALSE. drop_total_col Logical, whether remove \"total_value\" \"group_total\" variables created calculate percentage. Defaults FALSE.","code":""},{"path":"/reference/group_perc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a within-group percentage variable — group_perc","text":"group_perc creates within-group percentage variable using primary   group ID (id_group) secondary group (group). total value    id_group stored \"total_value\" variable, within-group total   stored \"group_total\". group percentage calculated using two function-created   variables. \"total_value\" \"group_total\" can dropped setting drop_total_col = TRUE.   group ID column can created using variables inid_group group setting    create_group_ID = TRUE.","code":""},{"path":"/reference/group_perc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a within-group percentage variable — group_perc","text":"","code":"if (FALSE) { group_perc(pollockMainDataTable, \"pollock\", id_group = \"PERMIT\", group = NULL,             value = \"OFFICIAL_TOTAL_CATCH_MT\")             group_perc(pollockMainDataTable, \"pollock\", id_group = \"PERMIT\",            group = \"DISEMBARKED_PORT\", value = \"HAUL\") }"},{"path":"/reference/haul_to_trip.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse data frame from haul to trip — haul_to_trip","title":"Collapse data frame from haul to trip — haul_to_trip","text":"Collapse data frame haul trip","code":""},{"path":"/reference/haul_to_trip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse data frame from haul to trip — haul_to_trip","text":"","code":"haul_to_trip(   dat,   project,   fun.numeric = mean,   fun.time = mean,   tripID,   haul_count = TRUE,   log_fun = TRUE )"},{"path":"/reference/haul_to_trip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse data frame from haul to trip — haul_to_trip","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. fun.numeric collapse numeric temporal data. example, min, mean,  max, sum. Defaults mean. fun.time collapse temporal data. example, min, mean, max.  sum temporal variables. tripID Column(s) identify individual trip. haul_count Logical, whether return column number hauls per trip. log_fun Logical, whether log function call (internal use).","code":""},{"path":"/reference/haul_to_trip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collapse data frame from haul to trip — haul_to_trip","text":"Returns primary dataset row trip.","code":""},{"path":"/reference/haul_to_trip.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Collapse data frame from haul to trip — haul_to_trip","text":"Collapses primary dataset haul trip level. Unique trips defined based selected column(s),    example, landing permit number disembarked port. id column used collapse   data trip level.  fun.numeric fun.time define multiple observations trip   collapsed. variables numeric dates, first observation used.","code":""},{"path":"/reference/haul_to_trip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collapse data frame from haul to trip — haul_to_trip","text":"","code":"if (FALSE) { pollockMainDataTable <- haul_to_trip(\"pollockMainDataTable\",\"pollock\",     min, mean, \"PERMIT\", \"DISEMBARKED_PORT\"     ) }"},{"path":"/reference/ID_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Create ID variable — ID_var","title":"Create ID variable — ID_var","text":"Create ID variable one variables","code":""},{"path":"/reference/ID_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create ID variable — ID_var","text":"","code":"ID_var(   dat,   project,   vars,   name = NULL,   type = \"string\",   drop = FALSE,   sep = \"_\",   log_fun = TRUE )"},{"path":"/reference/ID_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create ID variable — ID_var","text":"dat Primary data containing information hauls trips. Table FishSET database contains string `MainDataTable`. project Project name. vars Character string, additional column(s) dat define unique observations. name String, name new ID column. type String, class type new ID column. Choices `string`` `integar`. `string` returns character vector column vars  combined separated sep.  `integer` returns integer vector value corresponds unique group vars. drop Logical, whether drop columns vars. sep Symbol used combined variables. log_fun Logical, whether log function call (internal use).","code":""},{"path":"/reference/ID_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create ID variable — ID_var","text":"Returns `MainDataTable` ID variable included.","code":""},{"path":"/reference/ID_var.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create ID variable — ID_var","text":"ID variable can based single multiple variables.  Use sep = TRUE dropping variables create ID variable.","code":""},{"path":"/reference/ID_var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create ID variable — ID_var","text":"","code":"if (FALSE) { pcodMainDataTable <- ID_var(pcodMainDataTable, \"pcod\", name = \"PermitID\",          vars = c(\"GEAR_TYPE\", \"TRIP_SEQ\"), type = 'integar') pcodMainDataTable <- ID_var(pcodMainDataTable, \"pcod\", name = \"PermitID\",          vars = c(\"GEAR_TYPE\", \"TRIP_SEQ\"), type = 'string', sep=\"_\") }"},{"path":"/reference/insert_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert plot from user folder — insert_plot","title":"Insert plot from user folder — insert_plot","text":"Insert plot user folder","code":""},{"path":"/reference/insert_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert plot from user folder — insert_plot","text":"","code":"insert_plot(out, project)"},{"path":"/reference/insert_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert plot from user folder — insert_plot","text":"String, plot file name. project Name project.","code":""},{"path":"/reference/insert_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Insert plot from user folder — insert_plot","text":"","code":"if (FALSE) { insert_plot(\"pollock_plot.png\") }"},{"path":"/reference/insert_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert table from user folder — insert_table","title":"Insert table from user folder — insert_table","text":"Insert table user folder","code":""},{"path":"/reference/insert_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert table from user folder — insert_table","text":"","code":"insert_table(out, project)"},{"path":"/reference/insert_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert table from user folder — insert_table","text":"String, table file name. project Name project.","code":""},{"path":"/reference/insert_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Insert table from user folder — insert_table","text":"","code":"if (FALSE) { insert_table(\"pollock_table.csv\") }"},{"path":"/reference/is_empty.html","id":null,"dir":"Reference","previous_headings":"","what":"Empty variable check — is_empty","title":"Empty variable check — is_empty","text":"Empty variable check","code":""},{"path":"/reference/is_empty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empty variable check — is_empty","text":"","code":"is_empty(x, trim = TRUE, ...)"},{"path":"/reference/is_empty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empty variable check — is_empty","text":"x x trim defaults true ... Additional arguments","code":""},{"path":"/reference/is_invalid_spat.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect basic spatial issues — is_invalid_spat","title":"Detect basic spatial issues — is_invalid_spat","text":"Predicate function returns TRUE certain spatial issues found.","code":""},{"path":"/reference/is_invalid_spat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect basic spatial issues — is_invalid_spat","text":"","code":"is_invalid_spat(spat)"},{"path":"/reference/is_invalid_spat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect basic spatial issues — is_invalid_spat","text":"spat Spatial data check.","code":""},{"path":"/reference/is_invalid_spat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect basic spatial issues — is_invalid_spat","text":"TRUE \"GEOMETRYCOLLECTION\" found, spatial  features \"POLYGON\" \"MULTIPOLYGON\", invalid geometries  found, empty geometries detected, longitude needs shifted Pacific view.","code":""},{"path":"/reference/is_leaf.html","id":null,"dir":"Reference","previous_headings":"","what":"Is list object a leaf node — is_leaf","title":"Is list object a leaf node — is_leaf","text":"Determines whether object list leaf node.","code":""},{"path":"/reference/is_leaf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is list object a leaf node — is_leaf","text":"","code":"is_leaf(x)"},{"path":"/reference/is_leaf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is list object a leaf node — is_leaf","text":"x object list.","code":""},{"path":"/reference/is_leaf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Is list object a leaf node — is_leaf","text":"TRUE list object leaf node, FALSE .","code":""},{"path":"/reference/is_leaf_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect potential tables in list node — is_leaf_table","title":"Detect potential tables in list node — is_leaf_table","text":"Determines whether object list can converted dataframe.","code":""},{"path":"/reference/is_leaf_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect potential tables in list node — is_leaf_table","text":"","code":"is_leaf_table(x)"},{"path":"/reference/is_leaf_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect potential tables in list node — is_leaf_table","text":"x object list.","code":""},{"path":"/reference/is_leaf_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect potential tables in list node — is_leaf_table","text":"TRUE leaf node can converted dataframe, FALSE .","code":""},{"path":"/reference/is_value_empty.html","id":null,"dir":"Reference","previous_headings":"","what":"Empty value check — is_value_empty","title":"Empty value check — is_value_empty","text":"Empty value check","code":""},{"path":"/reference/is_value_empty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empty value check — is_value_empty","text":"","code":"is_value_empty(x)"},{"path":"/reference/is_value_empty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empty value check — is_value_empty","text":"x value, input, argument check.","code":""},{"path":"/reference/jitter_lonlat.html","id":null,"dir":"Reference","previous_headings":"","what":"Jitter longitude and latitude variables — jitter_lonlat","title":"Jitter longitude and latitude variables — jitter_lonlat","text":"Jitter longitude latitude variables","code":""},{"path":"/reference/jitter_lonlat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jitter longitude and latitude variables — jitter_lonlat","text":"","code":"jitter_lonlat(dat, project, lon, lat, factor = 1, amount = NULL)"},{"path":"/reference/jitter_lonlat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Jitter longitude and latitude variables — jitter_lonlat","text":"dat Main data frame apply function. Table FishSET  database contain string `MainDataTable`. project Project name. lon String, variable name containing longitude. lat String, variable name containing latitude. factor Numeric, see jitter details. amount Numeric, see jitter details.  Default (NULL): factor * d/5 d smallest difference x values.","code":""},{"path":"/reference/jitter_lonlat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Jitter longitude and latitude variables — jitter_lonlat","text":"one FishSET confidentiality functions. \"jitters\"    longitude latitude using base R function jitter.","code":""},{"path":"/reference/jitter_lonlat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jitter longitude and latitude variables — jitter_lonlat","text":"","code":"if (FALSE) { jitter_lonlat(pollockMainDataTable, \"pollock\",               lon = \"LonLat_START_LON\", lat = \"LonLat_START_LAT\") }"},{"path":"/reference/lame_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect an unnecessary nested list — lame_list","title":"Detect an unnecessary nested list — lame_list","text":"list object contains unnamed list containing another list single  object, \"lame list\". example: list(list(1:10))). nested list example unnecessary since contains single vector,  therefore can removed. Pruning lame lists can help simplify list object.","code":""},{"path":"/reference/lame_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect an unnecessary nested list — lame_list","text":"","code":"lame_list(l)"},{"path":"/reference/lame_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect an unnecessary nested list — lame_list","text":"l list.","code":""},{"path":"/reference/lame_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect an unnecessary nested list — lame_list","text":"TRUE list object lame list, FALSE .","code":""},{"path":[]},{"path":"/reference/lame_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect an unnecessary nested list — lame_list","text":"","code":"if (FALSE) { lame_list(list(list(1:10))) lame_list(list(A = list(1:10))) lame_list(list(list(1:10), list(11:20))) }"},{"path":"/reference/list_depth.html","id":null,"dir":"Reference","previous_headings":"","what":"Find list depth — list_depth","title":"Find list depth — list_depth","text":"Iterates purrr::vec_depth() object list.","code":""},{"path":"/reference/list_depth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find list depth — list_depth","text":"","code":"list_depth(l)"},{"path":"/reference/list_depth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find list depth — list_depth","text":"l list.","code":""},{"path":"/reference/list_depth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find list depth — list_depth","text":"numeric vector list depths.","code":""},{"path":"/reference/list_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert leaf node to a dataframe — list_df","title":"Convert leaf node to a dataframe — list_df","text":"Determines whether leaf node contains object can converted dataframe.","code":""},{"path":"/reference/list_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert leaf node to a dataframe — list_df","text":"","code":"list_df(l)"},{"path":"/reference/list_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert leaf node to a dataframe — list_df","text":"l list.","code":""},{"path":"/reference/list_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert leaf node to a dataframe — list_df","text":"list.","code":""},{"path":[]},{"path":"/reference/list_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert leaf node to a dataframe — list_df","text":"","code":"if (FALSE) { list_df(list(A = list(X = 1:10, Y = letters[1:10]))) list_df(list(A = 1:10, B = \"Text\", C = c(\"text\", \"text\"))) # no conversion }"},{"path":"/reference/list_dirs.html","id":null,"dir":"Reference","previous_headings":"","what":"Find directories — list_dirs","title":"Find directories — list_dirs","text":"Find directories","code":""},{"path":"/reference/list_dirs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find directories — list_dirs","text":"","code":"list_dirs(   path = \".\",   pattern = NULL,   all.dirs = FALSE,   full.names = FALSE,   ignore.case = FALSE )"},{"path":"/reference/list_dirs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find directories — list_dirs","text":"path file path pattern Use define specific dirs search .dirs Logical full.names Logical, Full name directory name ignore.case Logical","code":""},{"path":"/reference/list_html.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an HTML list item — list_html","title":"Create an HTML list item — list_html","text":"Converts list object HTML list item (<li>). object dataframe matrix, converted HTML table first.","code":""},{"path":"/reference/list_html.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an HTML list item — list_html","text":"","code":"list_html(l)"},{"path":"/reference/list_html.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an HTML list item — list_html","text":"l list.","code":""},{"path":"/reference/list_html.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an HTML list item — list_html","text":"HTML string list item.","code":""},{"path":"/reference/list_html_r.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an un-ordered HTML list recursively — list_html_r","title":"Create an un-ordered HTML list recursively — list_html_r","text":"Applies list_html every level list object.","code":""},{"path":"/reference/list_html_r.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an un-ordered HTML list recursively — list_html_r","text":"","code":"list_html_r(l)"},{"path":"/reference/list_html_r.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an un-ordered HTML list recursively — list_html_r","text":"l list.","code":""},{"path":"/reference/list_html_r.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an un-ordered HTML list recursively — list_html_r","text":"list HTML list item strings.","code":""},{"path":"/reference/list_length.html","id":null,"dir":"Reference","previous_headings":"","what":"Find list length — list_length","title":"Find list length — list_length","text":"Iterates length() object list.","code":""},{"path":"/reference/list_length.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find list length — list_length","text":"","code":"list_length(l)"},{"path":"/reference/list_length.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find list length — list_length","text":"l list.","code":""},{"path":"/reference/list_length.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find list length — list_length","text":"numeric vector list lengths.","code":""},{"path":"/reference/list_logs.html","id":null,"dir":"Reference","previous_headings":"","what":"View list of all log files — list_logs","title":"View list of all log files — list_logs","text":"View list log files","code":""},{"path":"/reference/list_logs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View list of all log files — list_logs","text":"","code":"list_logs(project = NULL, chron = FALSE, modified = FALSE)"},{"path":"/reference/list_logs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View list of all log files — list_logs","text":"project Project name. Displays logs NULL. chron Logical, whether display logs chronological order (TRUE) reverse chronological order (FALSE). modified Logical, whether include date modified.","code":""},{"path":"/reference/list_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Display FishSET database tables by type — list_tables","title":"Display FishSET database tables by type — list_tables","text":"Show project table names table type. see tables projects  FishSETFolder, use fishset_tables.","code":""},{"path":"/reference/list_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display FishSET database tables by type — list_tables","text":"","code":"list_tables(project, type = \"main\")"},{"path":"/reference/list_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display FishSET database tables by type — list_tables","text":"project project name show main tables . type type fishset_db table search . Options include  \"main\" (MainDataTable), \"port\" (PortTable), \"spat\" (SpatTable), \"grid\"  (GridTable), \"aux\" (AuxTable) \"ec\" (ExpectedCatch),  \"altc\" (AltMatrix),  \"info\" (MainDataTableInfo), \"gc\" (ldglobalcheck), \"fleet\" (FleetTable),  \"filter\" (FilterTable), \"centroid\" (Centroid FishCentroid),  \"model\"  (ModelOut), \"model data\" \"model design\" (ModelInputData),  \"outsample\" (OutSampleDataTable).","code":""},{"path":"/reference/list_tables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display FishSET database tables by type — list_tables","text":"","code":"if (FALSE) { list_tables(\"pollock\", type = \"main\") list_tables(\"pollock\", \"ec\") }"},{"path":"/reference/list_to_html.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert list to HTML — list_to_html","title":"Convert list to HTML — list_to_html","text":"Converts list un-ordered HTML list (<ul>).","code":""},{"path":"/reference/list_to_html.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert list to HTML — list_to_html","text":"","code":"list_to_html(l)"},{"path":"/reference/list_to_html.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert list to HTML — list_to_html","text":"l list.","code":""},{"path":"/reference/list_to_html.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert list to HTML — list_to_html","text":"un-ordered HTML list.","code":""},{"path":[]},{"path":"/reference/list_to_html.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert list to HTML — list_to_html","text":"","code":"if (FALSE) {   l <- list(A = 'a text', B = list(b1 = 'b1 text', b2 = 'b2 text'),             C = list(data.frame(A = 1:10, B = letters[1:10])))   list_to_html(l) }"},{"path":"/reference/load_aux.html","id":null,"dir":"Reference","previous_headings":"","what":"Import, parse, and save auxiliary data to FishSET database — load_aux","title":"Import, parse, and save auxiliary data to FishSET database — load_aux","text":"Auxiliary data additional data connects primary dataset. Function pulls data, parses , saves data FishSET  database. project must exist running load_aux(). See  load_maindata create new project.","code":""},{"path":"/reference/load_aux.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import, parse, and save auxiliary data to FishSET database — load_aux","text":"","code":"load_aux(dat, aux, name, over_write = TRUE, project = NULL)"},{"path":"/reference/load_aux.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import, parse, and save auxiliary data to FishSET database — load_aux","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. aux File name, including path auxiliary data. name Name auxiliary data saved FishSET database. over_write Logical, TRUE, saves data previously saved data table FishSET database. project String, name project.","code":""},{"path":"/reference/load_aux.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import, parse, and save auxiliary data to FishSET database — load_aux","text":"Auxiliary data additional data beyond primary data    port data. Auxiliary data can data can merged    primary dataset (ex. prices date, vessel characteristics, fishery season).    auxiliary data haul trip level must    contain variable connect auxiliary data primary dataset.    function checks least one column name auxiliary data    matches column name primary dataset. function checks   row unique, variables empty, column names    case-insensitive unique. data issues resolved data    saved database. data saved FishSET database raw    data working data. naming convention auxiliary tables    \"projectNameAuxTable\". Date also added name raw data.    See table_view view/load auxiliary tables working    environment.","code":""},{"path":[]},{"path":"/reference/load_aux.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import, parse, and save auxiliary data to FishSET database — load_aux","text":"","code":"if (FALSE) { load_aux(pcodMainDataTable, name = 'FisherySeason', over_write = TRUE,           project = 'pcod') }"},{"path":"/reference/load_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Load data from FishSET database into the R environment — load_data","title":"Load data from FishSET database into the R environment — load_data","text":"Load data FishSET database R environment","code":""},{"path":"/reference/load_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load data from FishSET database into the R environment — load_data","text":"","code":"load_data(project, name = NULL)"},{"path":"/reference/load_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load data from FishSET database into the R environment — load_data","text":"project String, name project. name Optional, name table FishSET database. Use argument pulling raw dated table (working table).","code":""},{"path":"/reference/load_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load data from FishSET database into the R environment — load_data","text":"Data loaded working environment project ‘MainDataTable’.","code":""},{"path":"/reference/load_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load data from FishSET database into the R environment — load_data","text":"Pulls primary data table FishSET database loads working    environment project MainDataTable. example, project pollock,    data saved working environment 'pollockMainDataTable'.","code":""},{"path":"/reference/load_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load data from FishSET database into the R environment — load_data","text":"","code":"if (FALSE) { load_data('pollock')  load_data('pollock', 'pollockMainDataTable20190101') }"},{"path":"/reference/load_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Import, parse, and save gridded data to FishSET database — load_grid","title":"Import, parse, and save gridded data to FishSET database — load_grid","text":"Gridded data data varies two dimensions. Column names must zone  names. Load, parse, save gridded data FishSET database.  project must  exist running load_grid(). See load_maindata create new project.","code":""},{"path":"/reference/load_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import, parse, and save gridded data to FishSET database — load_grid","text":"","code":"load_grid(dat, grid, name, over_write = TRUE, project = NULL)"},{"path":"/reference/load_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import, parse, and save gridded data to FishSET database — load_grid","text":"dat Primary data containing information hauls trips.  Table FishSET database contains string 'MainDataTable'. grid File name, including path, gridded data. name Name gridded data saved FishSET database. over_write Logical, TRUE, saves dat previously saved data table  FishSET database. project String, name project.","code":""},{"path":"/reference/load_grid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import, parse, and save gridded data to FishSET database — load_grid","text":"Grid data optional data frame contains variable    varies map grid (ex. sea surface temperature, wind speed). Data can    also vary second dimension (e.g., date/time). dimensions    gridded data file need variables included primary data set.   grid locations (zones) must define columns optional second    dimension defines rows. row variable must exact name    variable main data frame linked . function    check column row variables match variable primary data set.   function checks row unique, variables empty,    column names case-insensitive unique. data issues    resolved data saved database. data saved    FishSET database raw data working data. cases,    table name project file name x. Date attached    name raw data. naming convention gridded tables    \"projectNameGridTable\". See table_view view/load gridded    tables working environment.","code":""},{"path":[]},{"path":"/reference/load_grid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import, parse, and save gridded data to FishSET database — load_grid","text":"","code":"if (FALSE) { load_grid(dat = 'pcodMainDataTable', name = 'SeaSurfaceTemp',            over_write = TRUE, project = 'pcod') }"},{"path":"/reference/load_maindata.html","id":null,"dir":"Reference","previous_headings":"","what":"Import, parse, and save data to the FishSET Database — load_maindata","title":"Import, parse, and save data to the FishSET Database — load_maindata","text":"load_maindata() saves main dataset FishSET Database (located FishSETFolder) required step. main data also loaded  working environment dataframe named \"projectMainDataTable\".  Running load_maindata() creates new project directory FishSETFolder. see list existing projects run projects() open FishSETFolder.","code":""},{"path":"/reference/load_maindata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import, parse, and save data to the FishSET Database — load_maindata","text":"","code":"load_maindata(dat, project, over_write = FALSE, compare = FALSE, y = NULL)"},{"path":"/reference/load_maindata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import, parse, and save data to the FishSET Database — load_maindata","text":"dat Primary data containing information hauls trips. can full path file, name main table FishSET database, dataframe object working environment. Main tables FishSET  database contain string 'MainDataTable'. complete list FishSET tables can display running fishset_tables(). project String, name project. contain spaces. over_write Logical, TRUE, saves data previously saved data  table FishSET database. Defaults FALSE. compare Logical, whether compare new dataframe previously saved  dataframe y. See fishset_compare. y Name previously saved table FishSET Database. y must  defined compare = TRUE.","code":""},{"path":"/reference/load_maindata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import, parse, and save data to the FishSET Database — load_maindata","text":"dataset saved FishSET database raw working tables.    table name project table type, 'MainDataTable'.    raw table original, unedited table. working table contains    changes made table uploading. eight digit date string    included name raw table (e.g. \"pollockMainDataTable20220210\").    main data loaded working environment ‘projectMainDataTable’.   fishset_compare argument compares dat existing FishSET    table y returns message noting basic differences two.   column names checked case-insensitivity uniqueness.","code":""},{"path":[]},{"path":"/reference/load_maindata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import, parse, and save data to the FishSET Database — load_maindata","text":"","code":"if (FALSE) { # upload data from filepath load_maindata(dat = \"PATH/TO/DATA\", project = \"pollock\")  # upload from dataframe in working environment load_maindata(dat = Mydata, project = 'pollock', over_write = TRUE,                compare = TRUE, y = 'MainDataTable01012011')                # upload from an exisitng FishSET main data table looad_maindata(dat = \"pollockMainDataTable\", project = \"pollock2020\") }"},{"path":"/reference/load_outsample.html","id":null,"dir":"Reference","previous_headings":"","what":"Import, parse, and save out-of-sample data to FishSET database — load_outsample","title":"Import, parse, and save out-of-sample data to FishSET database — load_outsample","text":"load_outsample() saves --sample dataset FishSET Database (located FishSETFolder) structure must match main dataset. project must exist  running load_outsample(). See load_maindata create new project. Note:  data --sample temporally upload new datafile, data --sample spatially upload main data file function.","code":""},{"path":"/reference/load_outsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import, parse, and save out-of-sample data to FishSET database — load_outsample","text":"","code":"load_outsample(dat, project, over_write = FALSE, compare = FALSE, y = NULL)"},{"path":"/reference/load_outsample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import, parse, and save out-of-sample data to FishSET database — load_outsample","text":"dat --sample data containing information hauls trips structure main data table.  can full path file, name --sample table FishSET database, dataframe object working environment. --sample tables FishSET  database contain string 'OutSampleDataTable'. complete list FishSET tables can viewed running fishset_tables(). project String, name project. over_write Logical, TRUE, saves data previously saved data  table FishSET database. Defaults FALSE. compare Logical, whether compare new dataframe previously saved  dataframe y. See fishset_compare. y Name previously saved table FishSET Database. y must  defined compare = TRUE.","code":""},{"path":"/reference/load_outsample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import, parse, and save out-of-sample data to FishSET database — load_outsample","text":"--sample dataset saved FishSET database raw working tables.    table name project table type, 'OutSampleDataTable'.    raw table original, unedited table. working table contains    changes made table uploading. eight digit date string    included name raw table (e.g. \"pollockOutSampleDataTable20220210\").    --sample data loaded working environment ‘projectOutSampleDataTable’.   fishset_compare argument compares dat existing FishSET    table y returns message noting basic differences two.   column names checked case-insensitivity uniqueness.","code":""},{"path":[]},{"path":"/reference/load_outsample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import, parse, and save out-of-sample data to FishSET database — load_outsample","text":"","code":"if (FALSE) { # upload data from filepath load_outsample(dat = \"PATH/TO/DATA\", project = \"pollock\")  # upload from dataframe in working environment load_outsample(dat = MyData, project = 'pollock', over_write = TRUE,                compare = TRUE, y = 'OutSampleDataTable01012011')                # upload from an exisitng FishSET out-of-sample data table load_outsample(dat = \"pollockOutSampleDataTable\", project = \"pollock\") }"},{"path":"/reference/load_port.html","id":null,"dir":"Reference","previous_headings":"","what":"Import, parse, and save port data to FishSET database — load_port","title":"Import, parse, and save port data to FishSET database — load_port","text":"project must exist running load_port(). See load_maindata create new project.","code":""},{"path":"/reference/load_port.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import, parse, and save port data to FishSET database — load_port","text":"","code":"load_port(   dat,   port_name,   project,   over_write = TRUE,   compare = FALSE,   y = NULL )"},{"path":"/reference/load_port.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import, parse, and save port data to FishSET database — load_port","text":"dat Dataset containing port data. minimum, must include three  columns, port names, latitude longitude ports. dat can filepath, existing FishSET table, dataframe working environment. port_name Variable containing port names. Names match port names  primary dataset. project String, name project. over_write Logical, TRUE, saves data table previously saved  FishSET database. compare Logical, new data compared previously saved  dataframe y. y Name previously saved table FishSET database. y must  defined compare TRUE.","code":""},{"path":"/reference/load_port.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import, parse, and save port data to FishSET database — load_port","text":"Runs series checks port data. function checks   row unique, variables empty, column names    case-insensitive unique. data issues resolved data    saved database. checks pass, runs fishset_compare function   saves new data frame FishSET database.  data saved    FishSET database raw data working data. naming convention    port tables \"projectPortTable\".  Date also attached    name raw data. See table_view view/load port tables    working environment.","code":""},{"path":[]},{"path":"/reference/load_port.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import, parse, and save port data to FishSET database — load_port","text":"","code":"if (FALSE) { load_port(PortTable, over_write = TRUE, project  ='pollock',           compare = TRUE, y = 'pollockPortTable01012011') }"},{"path":"/reference/load_spatial.html","id":null,"dir":"Reference","previous_headings":"","what":"Import, parse, and save spatial data — load_spatial","title":"Import, parse, and save spatial data — load_spatial","text":"Saves spatial table FishSETFolder geojson file. project must  exist running load_spatial(). See load_maindata  create new project.","code":""},{"path":"/reference/load_spatial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import, parse, and save spatial data — load_spatial","text":"","code":"load_spatial(   spat,   name = NULL,   over_write = TRUE,   project,   data.type = NULL,   lon = NULL,   lat = NULL,   id = NULL,   ... )"},{"path":"/reference/load_spatial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import, parse, and save spatial data — load_spatial","text":"spat File name, including path, spatial data. name Name spatial data saved FishSET project folder. empty contain spaces. over_write Logical, TRUE, saves spat previously  saved data table FishSET project folder. project String, name project. data.type Data type argument passed read_dat.  reading shape folder use data.type = \"shape\". lon Variable list spat containing longitude data.  Required csv files. Leave NULL spat shape  json file. lat Variable list spat containing latitude data.  Required csv files. Leave NULL spat shape  json file id Polygon ID column. Required csv files. Leave NULL  spat shape json file. ... Additional argument passed read_dat.","code":""},{"path":"/reference/load_spatial.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import, parse, and save spatial data — load_spatial","text":"Function import, parse, saved project folder `FishSETFolder`   directory. export  shape file, use write_dat specifying   `type='shp'`. load_spatial() performs basic quality check saving   spatial tables project data folder geojson file. saved,   spatial must pass checks check_spatdat. spatial   table converted sf object, checked unique rows   empty columns. naming convention spatial tables \"projectNameSpatTable\".   See table_view view/load spatial tables working   environment.","code":""},{"path":[]},{"path":"/reference/load_spatial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import, parse, and save spatial data — load_spatial","text":"","code":"if (FALSE) { # upload from filepath load_spatial(spat = \"FILE/PATH/TO/SPAT\", name = 'tenMinSqr',               over_write = TRUE, project = 'pcod')  # upload from object in working environment load_spatial(spat = NMFSAreas, name = \"NMFS\", project = \"pcod\")  # upload from an existing FishSET spatial table load_spatial(spat = \"pcodNMFSSpatTable\", name = \"NMFS\", project = \"pcod2020\") }"},{"path":"/reference/loc.html","id":null,"dir":"Reference","previous_headings":"","what":"Define FishSETFolder location — loc","title":"Define FishSETFolder location — loc","text":"Define FishSETFolder location","code":""},{"path":"/reference/loc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define FishSETFolder location — loc","text":"","code":"loc()"},{"path":"/reference/locdatabase.html","id":null,"dir":"Reference","previous_headings":"","what":"Define source location — locdatabase","title":"Define source location — locdatabase","text":"Define source location","code":""},{"path":"/reference/locdatabase.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define source location — locdatabase","text":"","code":"locdatabase(project)"},{"path":"/reference/locdatabase.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define source location — locdatabase","text":"project Project name","code":""},{"path":"/reference/loclog.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the location of the log folder — loclog","title":"Returns the location of the log folder — loclog","text":"Returns location log folder","code":""},{"path":"/reference/loclog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the location of the log folder — loclog","text":"","code":"loclog(project)"},{"path":"/reference/loclog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the location of the log folder — loclog","text":"project Project name","code":""},{"path":"/reference/loclog.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Returns the location of the log folder — loclog","text":"loc2 working environment, default location use","code":""},{"path":"/reference/loclog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns the location of the log folder — loclog","text":"","code":"if (FALSE) { loclog('pollock') # will return log folder location for project pollock within the fishset package }"},{"path":"/reference/locoutput.html","id":null,"dir":"Reference","previous_headings":"","what":"Output location — locoutput","title":"Output location — locoutput","text":"Output location","code":""},{"path":"/reference/locoutput.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Output location — locoutput","text":"","code":"locoutput(project)"},{"path":"/reference/locoutput.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Output location — locoutput","text":"project Project name","code":""},{"path":"/reference/locproject.html","id":null,"dir":"Reference","previous_headings":"","what":"Define projects folder location — locproject","title":"Define projects folder location — locproject","text":"Define projects folder location","code":""},{"path":"/reference/locproject.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define projects folder location — locproject","text":"","code":"locproject()"},{"path":"/reference/loc_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Define source location for data folder Returns the location of the data folder — loc_data","title":"Define source location for data folder Returns the location of the data folder — loc_data","text":"Define source location data folder Returns location data folder","code":""},{"path":"/reference/loc_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define source location for data folder Returns the location of the data folder — loc_data","text":"","code":"loc_data(project)"},{"path":"/reference/loc_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define source location for data folder Returns the location of the data folder — loc_data","text":"project Project name","code":""},{"path":"/reference/loc_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define source location for data folder Returns the location of the data folder — loc_data","text":"loc2 working environment, default location use","code":""},{"path":"/reference/loc_doc.html","id":null,"dir":"Reference","previous_headings":"","what":"Define source location for doc folder Returns the location of the doc folder — loc_doc","title":"Define source location for doc folder Returns the location of the doc folder — loc_doc","text":"Define source location doc folder Returns location doc folder","code":""},{"path":"/reference/loc_doc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define source location for doc folder Returns the location of the doc folder — loc_doc","text":"","code":"loc_doc(project)"},{"path":"/reference/loc_doc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define source location for doc folder Returns the location of the doc folder — loc_doc","text":"project Project name","code":""},{"path":"/reference/loc_doc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define source location for doc folder Returns the location of the doc folder — loc_doc","text":"loc2 working environment, default location use","code":""},{"path":"/reference/loc_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Define source location for MapViewer folder Returns the location of the MapViewer folder — loc_map","title":"Define source location for MapViewer folder Returns the location of the MapViewer folder — loc_map","text":"Define source location MapViewer folder Returns location MapViewer folder","code":""},{"path":"/reference/loc_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define source location for MapViewer folder Returns the location of the MapViewer folder — loc_map","text":"","code":"loc_map(project)"},{"path":"/reference/loc_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define source location for MapViewer folder Returns the location of the MapViewer folder — loc_map","text":"project Project name","code":""},{"path":"/reference/loc_map.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define source location for MapViewer folder Returns the location of the MapViewer folder — loc_map","text":"loc2 working environment, default location use","code":""},{"path":"/reference/loc_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define source location for MapViewer folder Returns the location of the MapViewer folder — loc_map","text":"","code":"if (FALSE) { loc_map() # will return output folder location within the fishset package loc2 <- getwd() loc_map() #will return output folder location as within the working directory }"},{"path":"/reference/loc_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Define source location for meta file — loc_meta","title":"Define source location for meta file — loc_meta","text":"Define source location meta file","code":""},{"path":"/reference/loc_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define source location for meta file — loc_meta","text":"","code":"loc_meta(project)"},{"path":"/reference/loc_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define source location for meta file — loc_meta","text":"project Project name.","code":""},{"path":"/reference/logit_c.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional logit likelihood — logit_c","title":"Conditional logit likelihood — logit_c","text":"Conditional logit likelihood","code":""},{"path":"/reference/logit_c.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional logit likelihood — logit_c","text":"","code":"logit_c(starts3, dat, otherdat, alts, project, expname, mod.name)"},{"path":"/reference/logit_c.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional logit likelihood — logit_c","text":"starts3 Starting values vector (num). likelihood, order takes: c([alternative-specific parameters], [travel-distance parameters]).  alternative-specific parameters travel-distance parameters length (# alternative-specific variables) (# travel-distance variables) respectively. dat Data matrix, see output shift_sort_x, alternatives distance. otherdat data used model (list containing objects `intdat` `griddat`).  likelihood, `intdat` 'travel-distance variables', alternative-invariant variables interacted travel distance form cost portion likelihood. variable name therefore corresponds data dimensions (number observations) (unity), returns single parameter.  `griddat` 'alternative-specific variables', vary across alternatives, e.g. catch rates. variable name therefore corresponds data dimensions (number observations) (number alternatives), returns single parameter variable (e.g. marginal utility catch).  objects number variables allowed, list matrices. Note variables (matrix) within `griddat` `intdat` naming restrictions. 'Alternative-specific variables' may correspond catches vary location, 'travel-distance variables' may vessel characteristics affect much disutility suffered traveling greater distance. Note likelihood 'alternative-specific variables' vary across alternatives variable may estimated previous procedure (.e. construction expected catch).  data, user can set `griddat` ones dimension (number observations) (number alternatives) `intdat` variables ones dimension (number observations) (unity). alts Number alternative choices model length equal unity (numeric vector). project Name project expname Expected catch table mod.name Name model run model result output table","code":""},{"path":"/reference/logit_c.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional logit likelihood — logit_c","text":"ld: negative log likelihood","code":""},{"path":[]},{"path":"/reference/logit_c.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional logit likelihood — logit_c","text":"","code":"if (FALSE) { data(zi) data(catch) data(choice) data(distance) data(si)  optimOpt <- c(1000,1.00000000000000e-08,1,0)  methodname <- 'BFGS'  kk <- 4  si2 <- matrix(sample(1:5,dim(si)[1]*kk,replace=TRUE),dim(si)[1],kk) zi2 <- sample(1:10,dim(zi)[1],replace=TRUE)  otherdat <- list(griddat=list(predicted_catch=as.matrix(predicted_catch),     si2=as.matrix(si2)), intdat=list(zi=as.matrix(zi),     zi2=as.matrix(zi2)))  initparams <- c(2.5, 2, -1, -2)  func <- logit_c  results <- discretefish_subroutine(catch,choice,distance,otherdat,     initparams,optimOpt,func,methodname) }"},{"path":"/reference/logit_correction.html","id":null,"dir":"Reference","previous_headings":"","what":"Full information model with Dahl's correction function — logit_correction","title":"Full information model with Dahl's correction function — logit_correction","text":"Full information model Dahl's correction function","code":""},{"path":"/reference/logit_correction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full information model with Dahl's correction function — logit_correction","text":"","code":"logit_correction(starts3, dat, otherdat, alts, project, expname, mod.name)"},{"path":"/reference/logit_correction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full information model with Dahl's correction function — logit_correction","text":"starts3 Starting values vector (num). likelihood, order takes: c([marginal utility catch], [catch-function parameters], [polynomial starting parameters], [travel-distance parameters], [catch sigma]).  number polynomial interaction terms currently set 2, given chosen degree 'polyn' (((polyn+1)*2) + 2)*(k) polynomial starting parameters, (k) equals number alternatives. marginal utility catch catch sigma length equal unity respectively. catch-function travel-distance parameters length (# catch variables)*(k) (# cost variables) respectively. dat Data matrix, see output shift_sort_x, alternatives distance. otherdat data used model (list containing objects `griddat`, `intdat`, `startloc`, `polyn`, `distance`).  catch-function variables (`griddat`) alternative-invariant variables interacted zonal constants form catch portion likelihood. variable name therefore corresponds data dimensions (number observations) (unity), returns (k) parameters (k) equals number alternatives. travel-distance variables alternative-invariant variables interacted travel distance form cost portion likelihood. variable name therefore corresponds data dimensions (number observations) (unity), returns single parameter. number catch-function travel-distance variables allowed, list matrices. Note variables (matrix) within `griddat` `intdat` naming restrictions.  Catch-function variables may correspond variables affect catches across locations, travel-distance variables may vessel characteristics affect much disutility suffered traveling greater distance. Note likelihood catch-function variables vary across observations location: allowed affect catches across locations due location-specific coefficients. data, user can set catch-function variables ones dimension (number observations) (number alternatives) travel-distance variables ones dimension (number observations) (unity).  variable startloc matrix dimension (number observations) (unity), corresponds starting location agent decides alternatives.  variable polyn vector length equal unity corresponding chosen polynomial degree.  variable distance matrix dimension (number observations) (number alternatives) corresponding distance alternative. alts Number alternative choices model length equal unity (numeric vector). project Name project expname Expected catch table mod.name Name model run model result output table","code":""},{"path":"/reference/logit_correction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Full information model with Dahl's correction function — logit_correction","text":"ld: negative log likelihood","code":""},{"path":[]},{"path":"/reference/logit_correction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full information model with Dahl's correction function — logit_correction","text":"","code":"if (FALSE) { data(zi) data(catch) data(choice) data(distance) data(si) data(startloc)  optimOpt <- c(1000,1.00000000000000e-08,1,0)  methodname <- 'BFGS'  polyn <- 3 kk <- 4  si2 <- sample(1:5,dim(si)[1],replace=TRUE) zi2 <- sample(1:10,dim(zi)[1],replace=TRUE)  otherdat <- list(griddat=list(si=as.matrix(si),si2=as.matrix(si2)),     intdat=list(zi=as.matrix(zi),zi2=as.matrix(zi2)),     startloc=as.matrix(startloc),polyn=polyn,     distance=as.matrix(distance))  initparams <- c(3, 0.5, 0.4, 0.3, 0.2, 0.55, 0.45, 0.35, 0.25,     rep(0, (((polyn+1)*2) + 2)*kk), -0.3,-0.4, 3)  func <- logit_correction  results <- discretefish_subroutine(catch,choice,distance,otherdat,     initparams,optimOpt,func,methodname) }"},{"path":"/reference/logit_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit predict — logit_predict","title":"Logit predict — logit_predict","text":"Prediction component logit models (non mixed) called Policy3, predict_model_tempNew.m","code":""},{"path":"/reference/logit_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit predict — logit_predict","text":"","code":"logit_predict(   project,   mod.name,   use.scalers = FALSE,   scaler.func = NULL,   outsample = FALSE,   outsample.mod.name = NULL )"},{"path":"/reference/logit_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit predict — logit_predict","text":"project Name project mod.name Name saved model use. Argument can name model can pull name  saved \"best\" model. Leave mod.name empty use saved \"best\" model. one model saved, mod.name numeric indicator model use. Use table_view(\"modelChosen\", project) view table saved models. use.scalers Input create_model_input(). Logical, data normalized? Defaults FALSE. Rescaling factors mean  numeric vector unless specified scaler.func. scaler.func Input create_model_input(). Function calculate rescaling factors. outsample Logical, FALSE predicting probabilities main data, TRUE predicting --sample data. outsample = FALSE  default setting. outsample.mod.name predicting --sample data, provide --sample model design name. outsample.mod.name = NULL default.","code":""},{"path":"/reference/logit_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit predict — logit_predict","text":"Returns probability logit model choice","code":""},{"path":"/reference/logit_zonal.html","id":null,"dir":"Reference","previous_headings":"","what":"Zonal logit with area-specific constants procedure — logit_zonal","title":"Zonal logit with area-specific constants procedure — logit_zonal","text":"Zonal logit area-specific constants procedure","code":""},{"path":"/reference/logit_zonal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zonal logit with area-specific constants procedure — logit_zonal","text":"","code":"logit_zonal(starts3, dat, otherdat, alts, project, expname, mod.name)"},{"path":"/reference/logit_zonal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zonal logit with area-specific constants procedure — logit_zonal","text":"starts3 Starting values vector (num). likelihood, order takes: c([area-specific parameters], [travel-distance parameters]).  area-specific parameters travel-distance parameters length (# area-specific parameters)*(k-1) (# travel-distance variables respectively, (k) equals number alternatives. dat Data matrix, see output shift_sort_x, alternatives distance. otherdat data used model (list containing objects `intdat` `griddat`).  likelihood, `intdat` 'travel-distance variables', alternative-invariant values interacted travel distance form cost portion likelihood. variable name therefore corresponds data dimensions (number observations) (unity), returns single parameter.  `griddat` 'area-specific parameters' vary across alternatives, e.g. vessel gross tonnage. constant name therefore corresponds data dimensions (number observations) (unity), returns (k-1) parameters (k) equals number alternatives, normalization parameters needed probabilities sum one. Interpretation therefore relative first alternative.  objects number variables allowed, list matrices. Note variables (matrix) within `griddat` `intdat` naming restrictions. 'Area-specific parametes ' may correspond variables impact average catches location, 'travel-distance variables' may vessel characteristics affect much disutility suffered traveling greater distance. Note likelihood 'area-specific parameters' vary across observations location: allowed affect alternatives differently due location-specific coefficients.  data, user can set `griddat` ones dimension (number observations) (unity) `intdat` variables ones dimension (number observations) (unity). alts Number alternative choices model length equal unity (numeric vector). project Name project expname Expected catch table mod.name Name model run model result output table","code":""},{"path":"/reference/logit_zonal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Zonal logit with area-specific constants procedure — logit_zonal","text":"ld: negative log likelihood","code":""},{"path":[]},{"path":"/reference/logit_zonal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zonal logit with area-specific constants procedure — logit_zonal","text":"","code":"if (FALSE) { data(zi) data(catch) data(choice) data(distance) data(si)  optimOpt <- c(1000,1.00000000000000e-08,1,0)  methodname <- 'BFGS'  si2 <- sample(1:5,dim(si)[1],replace=TRUE) zi2 <- sample(1:10,dim(zi)[1],replace=TRUE)  otherdat <- list(griddat=list(si=as.matrix(si),si2=as.matrix(si2)),     intdat=list(zi=as.matrix(zi),zi2=as.matrix(zi2)))  initparams <- c(1.5, 1.25, 1.0, 0.9, 0.8, 0.75, -1, -0.5)  func <- logit_zonal  results <- discretefish_subroutine(catch,choice,distance,otherdat,     initparams,optimOpt,func,methodname) }"},{"path":"/reference/log_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Update function calls saved in log file — log_call","title":"Update function calls saved in log file — log_call","text":"Update function calls saved log file","code":""},{"path":"/reference/log_call.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update function calls saved in log file — log_call","text":"","code":"log_call(project, fun.name)"},{"path":"/reference/log_call.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update function calls saved in log file — log_call","text":"project Name project fun.name Function name","code":""},{"path":"/reference/log_call.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update function calls saved in log file — log_call","text":"update log file","code":""},{"path":"/reference/log_func_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Log user-created functions or models — log_func_model","title":"Log user-created functions or models — log_func_model","text":"Log user-created functions models","code":""},{"path":"/reference/log_func_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log user-created functions or models — log_func_model","text":"","code":"log_func_model(x, project)"},{"path":"/reference/log_func_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log user-created functions or models — log_func_model","text":"x Name function. project Project name.","code":""},{"path":"/reference/log_func_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log user-created functions or models — log_func_model","text":"Logs function name, arguments, , call. Use function log user-defined likelihood functions.","code":""},{"path":"/reference/log_func_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log user-created functions or models — log_func_model","text":"","code":"if (FALSE) { my_func <- function(a, b) {   a + b } log_func_model(my_func) }"},{"path":"/reference/log_grid_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Log grid file — log_grid_info","title":"Log grid file — log_grid_info","text":"Writes grid information JSON file located project data directory.","code":""},{"path":"/reference/log_grid_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log grid file — log_grid_info","text":"","code":"log_grid_info(project, grid_info, mod_type = \"combine\")"},{"path":"/reference/log_grid_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log grid file — log_grid_info","text":"project Name project. grid_info List containing grid information. mod_type String, \"combine\" combined map files \"edit\"  edited map files.","code":""},{"path":"/reference/log_grid_info.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log grid file — log_grid_info","text":"grid log list containing information grid files    currently saved project data folder. grid entry contains three    fields: grid_name, closure_name, combined_areas.    grid_name name original grid object. two   fields empty, means grid file altered    original. closure_name name second    grid file containing closure areas combined grid_name.    combined_areas names/IDs closures areas     closure grid file combined grid_name.","code":""},{"path":[]},{"path":"/reference/log_rerun.html","id":null,"dir":"Reference","previous_headings":"","what":"Console function for rerunning project log — log_rerun","title":"Console function for rerunning project log — log_rerun","text":"Console function rerunning project log","code":""},{"path":"/reference/log_rerun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Console function for rerunning project log — log_rerun","text":"","code":"log_rerun(   log_file,   dat = NULL,   portTable = NULL,   aux = NULL,   gridfile = NULL,   spat = NULL,   ind = NULL,   run = FALSE )"},{"path":"/reference/log_rerun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Console function for rerunning project log — log_rerun","text":"log_file String, name log file starting date (YYYY-MM-DD) ending \".json\". dat String, new main data table rerun log portTable String, name port table. Defualts NULL. aux String, name auxiliary table. Defaults NULL. gridfile String, name gridded data table. Defaults NULL. spat String, name spatial data table. Defaults NULL. ind Numeric, indices function calls rerun. run Logical, whether run logged function calls (TRUE) simply list function calls (FALSE).","code":""},{"path":[]},{"path":"/reference/log_rerun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Console function for rerunning project log — log_rerun","text":"","code":"if (FALSE) { log_rerun(\"pollock_2020-10-23.json\", run = TRUE) # reruns entire log with original data table # runs log with new data table log_rerun(\"pollock_2020-10-23.json\", dat = \"pollockMainDataTable\", run = TRUE)  }"},{"path":"/reference/log_rerun_gui.html","id":null,"dir":"Reference","previous_headings":"","what":"Interactive function for rerunning project log — log_rerun_gui","title":"Interactive function for rerunning project log — log_rerun_gui","text":"Interactive function rerunning project log","code":""},{"path":"/reference/log_rerun_gui.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interactive function for rerunning project log — log_rerun_gui","text":"","code":"log_rerun_gui()"},{"path":[]},{"path":"/reference/log_rerun_gui.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interactive function for rerunning project log — log_rerun_gui","text":"","code":"if (FALSE) { log_rerun_gui() }"},{"path":"/reference/log_reset.html","id":null,"dir":"Reference","previous_headings":"","what":"Reset log file — log_reset","title":"Reset log file — log_reset","text":"Reset log file","code":""},{"path":"/reference/log_reset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reset log file — log_reset","text":"","code":"log_reset(project, over_write = FALSE)"},{"path":"/reference/log_reset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reset log file — log_reset","text":"project Project name. over_write Logical, whether write existing log file. applies log created reset day  project. See \"Details\".","code":""},{"path":"/reference/log_reset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reset log file — log_reset","text":"Logs saved project name date (date created, date modified).    example, \"pollock_2021-05-12.json\". Calls log functions    automatically appended existing project log file. Resetting log    file create new project log file current date. log    reset log_reset() run day log created   (log reset two times single day), unless    over_write = TRUE. replace day's log file.","code":""},{"path":[]},{"path":"/reference/log_reset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reset log file — log_reset","text":"","code":"if (FALSE) { log_reset(\"pollock\") }"},{"path":"/reference/long_expectations.html","id":null,"dir":"Reference","previous_headings":"","what":"Long expectations — long_expectations","title":"Long expectations — long_expectations","text":"Long expectations","code":""},{"path":"/reference/long_expectations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Long expectations — long_expectations","text":"","code":"long_expectations(   dat,   project,   catch,   price,   defineGroup,   temp.var,   temporal,   calc.method,   lag.method,   empty.catch,   empty.expectation,   dummy.exp )"},{"path":"/reference/long_expectations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Long expectations — long_expectations","text":"dat Main data frame containing data hauls trips. Table FishSET database contain string `MainDataTable`. project Name project. Used pull working alternative choice matrix FishSET database. catch Variable containing catch data. price Variable containing price/value data. Used calculating expected revenue. Leave null calculating expected catch. Multiplied catch generated revenue. defineGroup empty, data treated fleet temp.var Variable containing temporal data temporal Daily (Daily time line) sequential (sequential order) calc.method Select standard average (standardAverage), simple lag regression means (simpleLag), weights regressed groups (weights) lag.method Use regression entire group (simple) grouped time periods (grouped) empty.catch Replace empty catch NA, 0, mean catch (allCatch), mean grouped catch(groupCatch) empty.expectation replace (NULL) replace 0.0001 0 dummy.exp Logical, dummy variable outputted originally missing value. Defaults FALSE.","code":""},{"path":"/reference/long_expectations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Long expectations — long_expectations","text":"Expected catch matrix. Saved database via create_expectations","code":""},{"path":"/reference/lonlat_to_centroid.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign longitude and latitude points to zonal centroid — lonlat_to_centroid","title":"Assign longitude and latitude points to zonal centroid — lonlat_to_centroid","text":"Assign longitude latitude points zonal centroid","code":""},{"path":"/reference/lonlat_to_centroid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign longitude and latitude points to zonal centroid — lonlat_to_centroid","text":"","code":"lonlat_to_centroid(dat, project, lon, lat, spat, zone)"},{"path":"/reference/lonlat_to_centroid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign longitude and latitude points to zonal centroid — lonlat_to_centroid","text":"dat Main data frame apply function. Table FishSET  database contain string `MainDataTable`. project Project name. lon String, variable name containing longitude. lat String, variable name containing latitude. spat Spatial data table containing regulatory zones. can  \"spatial feature\" sf object. zone String, column name contain assigned zone. Must  spatial data table MainDataTable.","code":""},{"path":"/reference/lonlat_to_centroid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Assign longitude and latitude points to zonal centroid — lonlat_to_centroid","text":"one FishSET confidentiality functions. replaces    selected longitude latitude columns zonal centroid derived    spatial data table.","code":""},{"path":"/reference/lonlat_to_centroid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign longitude and latitude points to zonal centroid — lonlat_to_centroid","text":"","code":"if (FALSE) { lonlat_to_centroid(pollockMainDataTable, \"pollock\", spatdat,                    lon = \"LonLat_START_LON\", lat = \"LonLat_START_LAT\",                   zone = \"NMFS_AREA\") }"},{"path":"/reference/main_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"View list of MainDataTables in FishSET database — main_tables","title":"View list of MainDataTables in FishSET database — main_tables","text":"View list MainDataTables FishSET database","code":""},{"path":"/reference/main_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View list of MainDataTables in FishSET database — main_tables","text":"","code":"main_tables(project, show_all = TRUE)"},{"path":"/reference/main_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View list of MainDataTables in FishSET database — main_tables","text":"project project name filter main tables . show_all Logical, whether show main tables (including raw  final tables) just editable tables.","code":""},{"path":"/reference/main_tables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View list of MainDataTables in FishSET database — main_tables","text":"","code":"if (FALSE) { main_tables(\"pollock\") }"},{"path":"/reference/make_model_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Make model design file — make_model_design","title":"Make model design file — make_model_design","text":"Create list containing likelihood function, parameters, data pass model call function","code":""},{"path":"/reference/make_model_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make model design file — make_model_design","text":"","code":"make_model_design(   project,   catchID,   likelihood = NULL,   initparams = NULL,   optimOpt = c(100, 1e-08, 1, 1),   methodname = \"BFGS\",   mod.name = NULL,   vars1 = NULL,   vars2 = NULL,   priceCol = NULL,   expectcatchmodels = list(\"all\"),   startloc = NULL,   polyn = NULL,   spat = NULL,   spatID = NULL,   crs = NULL,   outsample = FALSE,   CV_dat = NULL )"},{"path":"/reference/make_model_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make model design file — make_model_design","text":"project String, name project. catchID String, variable dat contains catch data. likelihood String, name likelihood function. Details likelihood specific initial parameter specification can found discretefish_subroutine() documentation. initparams Vector list, initial parameter estimates revenue/location-specific covariates cost/distance. number parameter estimate varies likelihood function. See Details section information. initial parameters set 1 initparams == NULL. initparams single numeric value, used parameter. using parameter estimates previous model, initparams name model parameter estimates come . Examples: initparams = 'epm_mod1', initparams = list('epm_mod1', 'epm_mod2'). optimOpt String, optimization options (max function evaluations, max iterations, (reltol) tolerance x, trace) Note: add optim reference ?. methodname String, optimization method (see stats::optim() options). Defaults \"BFGS\". mod.name String, name model run model result output table. vars1 Character string, additional ‘travel-distance’ variables include model. depend likelihood. See Details section specify likelihood function. vars2 Character string, additional variables include model. depend likelihood. See Details section specify likelihood function. likelihood = 'logit_c', vars2 name gridded table saved FishSET Database, contain string \"GridTableWide\". See format_grid() details. priceCol Variable dat containing price information. Required specifying expected profit model likelihood (epm_normal, epm_weibull, epm_lognormal). expectcatchmodels List, name expected catch models include model run. Defaults models. list item string expected catch models include model. example, list(c('recent', 'older'), c('user1')) run one model medium long expected catch matrices, one model just user-defined expected catch matrix. Choices \"recent\", \"older\", \"oldest\", \"logbook\", \"\", \"individual\". See create_expectations() details different models. Option \"\" run expected catch matrices jointly. Option \"individual\" run model expected catch matrix separately. final option select one expected catch matrices run jointly. startloc Variable dat identifying location choice fish next made. Required logit_correction likelihood. Use create_startingloc() function create starting location vector. polyn Numeric, correction polynomial degree. Required logit_correction() likelihood. spat spatial data file containing information fishery management regulatory zones boundaries. required alt_var = \"nearest point\" used alternative choice matrix (see create_alternative_choice()). Defaults NULL. spatial file used assign observations zones. spatID Variable spat identifies individual areas zones. required alt_var = \"nearest point\" used alternative choice matrix (see create_alternative_choice()). Defaults NULL. crs coordinate reference system assigned creating distance matrix. Passed create_dist_matrix(). outsample Logical, indicates whether model design main data (FALSE) --sample data (TRUE). default outsample = FALSE. CV_dat Dataframe contains training testing data k-fold cross validation. Defaults CV_dat = NULL.","code":""},{"path":"/reference/make_model_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make model design file — make_model_design","text":"Function creates model matrix list contains data modeling choices. model design list saved FishSET database called discretefish_subroutine(). Alternative fishing options come Alternative Choice list, generated create_alternative_choice() function, expected catch matrices create_expectations() function. distance starting point alternative choices calculated. Model design list:","code":""},{"path":"/reference/make_model_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make model design file — make_model_design","text":"Function creates model matrix list contains data modeling choices. model design list saved FishSET database called discretefish_subroutine(). Alternative fishing options come Alternative Choice list, generated create_alternative_choice() function, expected catch matrices create_expectations() function. distance starting point alternative choices calculated.  Variable names details:","code":"\"travel-distance variables\" are     alternative-invariant variables that are     interacted with travel distance to form the cost     portion of the likelihood. Each variable name     therefore corresponds to data with dimensions     (number of observations) by (unity), and returns     a single parameter. \"alternative-specific variables\"     vary across alternatives, e.g. catch rates.     Each variable name therefore corresponds to data     with dimensions (number of observations) by     (number of alternatives), and returns a single     parameter for each variable (e.g. the marginal     utility from catch). \"travel-distance variables\" are     alternative-invariant variables that are     interacted with travel distance to form the cost     portion of the likelihood. Each variable name     therefore corresponds to data with dimensions     (number of observations) by (unity), and returns     a single parameter. \"average-catch variables\" are     alternative-invariant variables, e.g. vessel     gross tonnage. Each variable name therefore     corresponds to data with dimensions (number of     observations) by (unity), and returns (k-1)     parameters where (k) equals the number of     alternatives, as a normalization of parameters     is needed as the probabilities sum to one.     Interpretation is therefore relative to the     first alternative. \"travel-distance variables\" are     alternative-invariant variables that are     interacted with travel distance to form the     cost portion of the likelihood. Each variable     name therefore corresponds to     data with dimensions (number of observations)     by (unity), and returns a single parameter. \"catch-function variables\" are     alternative-invariant variables that are     interacted with zonal constants to form the     catch portion of the likelihood. Each variable     name therefore corresponds to data with     dimensions (number of observations) by (unity),     and returns (k) parameters where (k) equals     the number of alternatives. \"travel-distance variables\" are     alternative-invariant variables that are     interacted with travel distance to form the     cost portion of the likelihood. Each variable     name therefore corresponds to data with     dimensions (number of observations) by (unity),     and returns a single parameter. \"catch-function variables\" are     alternative-invariant variables that are     interacted with zonal constants to form the     catch portion of the likelihood. Each variable     name therefore corresponds to data with     dimensions (number of observations) by (unity),     and returns (k) parameters where (k) equals     the number of alternatives. \"travel-distance variables\" are     alternative-invariant variables that are     interacted with travel distance to form the cost     portion of the likelihood. Each variable name     therefore corresponds to data with dimensions     (number of observations) by (unity), and returns     a single parameter. \"catch-function variables\" are     alternative-invariant variables that are     interacted with zonal constants to form the catch     portion of the likelihood. Each variable name     therefore corresponds to data with dimensions     (number of observations) by (unity), and returns     (k) parameters where (k) equals the number of     alternatives. \"travel-distance variables\" are     alternative-invariant variables that are     interacted with travel distance to form the cost     portion of the likelihood. Each variable name     therefore corresponds to data with dimensions     (number of observations) by (unity), and returns     a single parameter. \"catch-function variables\" are     alternative-invariant variables that are     interacted with zonal constants to form the catch     portion of the likelihood. Each variable name     therefore corresponds to data with dimensions     (number of observations) by (unity), and returns     (k) parameters where (k) equals the number of     alternatives."},{"path":"/reference/make_model_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make model design file — make_model_design","text":"","code":"if (FALSE) { make_model_design(\"pollock\", catchID= \"OFFICIAL_TOTAL_CATCH\",     likelihood='logit_zonal',    vars1=NULL, vars2=NULL, initparams=c(-0.5,0.5),   optimOpt=c(100000, 1.0e-08, 1, 1), methodname = \"BFGS\", mod.name = \"logit4\" ) }"},{"path":"/reference/make_polygon.html","id":null,"dir":"Reference","previous_headings":"","what":"create a polygon — make_polygon","title":"create a polygon — make_polygon","text":"create polygon","code":""},{"path":"/reference/make_polygon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create a polygon — make_polygon","text":"","code":"make_polygon(coord)"},{"path":"/reference/make_polygon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create a polygon — make_polygon","text":"coord Longitude latitude coordinates forming polygon. Can  numeric vector even length numeric matrix two columns.","code":""},{"path":"/reference/make_polygon.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"create a polygon — make_polygon","text":"coordinates create open polygon function automatically closes gives warning.","code":""},{"path":"/reference/make_spat_area.html","id":null,"dir":"Reference","previous_headings":"","what":"Add an area/polygon to spatial data — make_spat_area","title":"Add an area/polygon to spatial data — make_spat_area","text":"Add area/polygon spatial data","code":""},{"path":"/reference/make_spat_area.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add an area/polygon to spatial data — make_spat_area","text":"","code":"make_spat_area(spat, project, coord, spat.id, new.id, combine)"},{"path":"/reference/make_spat_area.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add an area/polygon to spatial data — make_spat_area","text":"spat Spatial dataset add polygon . project Name project. coord Longitude latitude coordinates forming polygon. Can  numeric vector even length numeric matrix two columns. spat.id ID column spat new.id ID new polygon. combine Whether use combine_zone. turn  intersections poly spat new polygons.  Note new polygon IDs derived spat new.id  used.","code":""},{"path":"/reference/make_spat_area.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add an area/polygon to spatial data — make_spat_area","text":"Adds area/polygone spatial area","code":""},{"path":[]},{"path":"/reference/map_kernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Kernel density (hotspot) plot — map_kernel","title":"Kernel density (hotspot) plot — map_kernel","text":"Kernel density (hotspot) plot","code":""},{"path":"/reference/map_kernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kernel density (hotspot) plot — map_kernel","text":"","code":"map_kernel(   dat,   project,   latlon,   type = \"contours\",   group = NULL,   facet = FALSE,   date = NULL,   filter_date = NULL,   filter_value = NULL,   minmax = NULL )"},{"path":"/reference/map_kernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kernel density (hotspot) plot — map_kernel","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. latlon Character string, specified latitude longitude, decimal degrees. type String, plot type. Choices \"point\", \"contours\", \"gradient\". Note group, must facet choosing \"gradient\" (overlap polygons clearly). group Optional group argument. factor length (# observations), observation corresponds latlon coordinate index. Recall legend output names factor levels named (see ?factor). facet Optional facet parameter. TRUE mapping group separate facet. Defaults FALSE. date Optional date variable filter data . filter_date Whether filter data table \"year\", \"month\", \"year-month\". date filter_value must provided. Defaults NULL. filter_value Integer (4 digits year, 1-2 month). year, month, year-month filter data table . Use list using \"year-month\", format: list(year(s), month(s)). example, list(2011:2013, 5:7) filter data table May July, 2011-2013. minmax Optional map extent argument, vector (num) length 4 corresponding c(minlat, maxlat, minlon, maxlon).","code":""},{"path":"/reference/map_kernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kernel density (hotspot) plot — map_kernel","text":"Returns ggplot2 object. Map plot saved Output folder.","code":""},{"path":"/reference/map_kernel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kernel density (hotspot) plot — map_kernel","text":"","code":"if (FALSE) { map_kernel(pollockMainDataTable, project = 'pollock', type = 'contours', latlon = c('LonLat_START_LAT', 'LonLat_START_LON'), group = 'PORT_CODE', facet = TRUE, minmax = NULL, date = 'FISHING_START_DATE', filter_date = 'year-month', filter_value = list(2011, 2:4)) }"},{"path":"/reference/map_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Map observed vessel locations — map_plot","title":"Map observed vessel locations — map_plot","text":"Plot observed locations map. large datasets, best    plot subset points. Use percshown randomly subset    number points. predefined map extent needs adjusting,   use minmax.","code":""},{"path":"/reference/map_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map observed vessel locations — map_plot","text":"","code":"map_plot(dat, project, lat, lon, minmax = NULL, percshown = NULL)"},{"path":"/reference/map_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map observed vessel locations — map_plot","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, project name. lat Variable dat defines latitude, decimal degrees. lon Variable dat defines longitude, decimal degrees. minmax Optional map extent argument, vector (num) length four corresponding c(minlat, maxlat, minlon, maxlon). percshown Whole number, percent points show. Use option  lot data points.","code":""},{"path":"/reference/map_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map observed vessel locations — map_plot","text":"mapout: ggplot2 object","code":""},{"path":"/reference/map_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map observed vessel locations — map_plot","text":"","code":"if (FALSE) { map_plot(pollockMainDataTable, 'pollock', 'LonLat_START_LAT', 'LonLat_START_LON', percshown=10) }"},{"path":"/reference/map_viewer.html","id":null,"dir":"Reference","previous_headings":"","what":"Interactive vessel locations and fishery zones map — map_viewer","title":"Interactive vessel locations and fishery zones map — map_viewer","text":"View vessel locations fishery zones interactive map.","code":""},{"path":"/reference/map_viewer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interactive vessel locations and fishery zones map — map_viewer","text":"","code":"map_viewer(   dat,   project,   spat,   avd,   avm,   num_vars,   temp_vars,   id_vars,   lon_start,   lat_start,   lon_end = NULL,   lat_end = NULL )"},{"path":"/reference/map_viewer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interactive vessel locations and fishery zones map — map_viewer","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project Project name. spat Spatial data containing information fishery management  regulatory zones. Shape, json, geojson, csv formats supported. avd Variable name primary data file gives unique ID associated polygon. avm name property GeoJson file identifies  polygon cross reference dat. Variable name spatial file represents unique ID. num_vars List, name numeric variable(s) dat include plotting. temp_vars List, name temporal variable(s) dat include plotting. id_vars List, name categorical variable(s) dat group . lon_start String, variable dat identifies single  longitude point starting longitude decimal degrees. lat_start String, variable dat identifies single  latitude point starting latitude decimal degrees. lon_end String, variable dat identifies ending longitude decimal degrees. lat_end String, variable dat identifies ending latitude decimal degrees.","code":""},{"path":"/reference/map_viewer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interactive vessel locations and fishery zones map — map_viewer","text":"map_viewer function creates files required run MapViewer  program. Users can map points trip path. plot points, leave lon_end  lat_end NULL. creating inputs, map zones  opened default web browser. close server connection run  servr::daemon_stop() console. Lines map represent starting ending lat/long observation data set color coded based  selected variable. can take minute data loaded onto map. time, map can saved taking screen shot.","code":""},{"path":"/reference/map_viewer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interactive vessel locations and fishery zones map — map_viewer","text":"","code":"if (FALSE) { # Plot trip path map_viewer(scallopMainDataTable, 'scallop', \"scallopTMSSpatTable\",             avd = 'ZoneID', avm = 'TEN_ID', num_vars = 'LANDED_thousands',             temp_vars = 'DATE_TRIP', lon_start = 'previous_port_lon',             lat_start = 'previous_port_lat', lon_end = 'DDLON',             lat_end = 'DDLAT')     # Plot observed fishing locations         map_viewer(scallopMainDataTable, 'scallop', \"scallopTMSSpatTable\",             avd = 'ZoneID', avm = 'TEN_ID', num_vars = 'LANDED_thousands',             temp_vars = 'DATE_TRIP', lon_start = 'DDLON', lat_start = 'DDLAT')  #Plot haul path map_viewer(pollockMainDataTable, 'pollock', spat=spatdat, avd='NMFS_AREA', avm='NMFS_AREA', num_vars=c('HAUL','OFFICIAL_TOTAL_CATCH'), temp_vars='HAUL_DATE', id_vars=c('GEAR_TYPE', 'PORT'),         'Lon_Start', 'Lat_Start', 'Lon_End', 'Lat_End')  #Plot haul midpoint map_viewer(pollockMainDataTable, 'pollock', spat=spatdat, avd='NMFS_AREA', avm='NMFS_AREA', num_vars=c('HAUL','OFFICIAL_TOTAL_CATCH'), temp_vars='HAUL_DATE', id_vars=c('GEAR_TYPE', 'PORT'), 'Lon_Mid', 'Lat_Mid') }"},{"path":"/reference/medium_expectations.html","id":null,"dir":"Reference","previous_headings":"","what":"Medium expectations — medium_expectations","title":"Medium expectations — medium_expectations","text":"Medium expectations","code":""},{"path":"/reference/medium_expectations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Medium expectations — medium_expectations","text":"","code":"medium_expectations(   dat,   project,   catch,   price,   defineGroup,   temp.var,   temporal,   calc.method,   lag.method,   empty.catch,   empty.expectation,   dummy.exp )"},{"path":"/reference/medium_expectations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Medium expectations — medium_expectations","text":"dat Main data frame containing data hauls trips. Table FishSET database contain string `MainDataTable`. project Name project. Used pull working alternative choice matrix fishset_db database. catch Variable containing catch data. price Variable containing price/value data. Used calculating expected revenue. Leave null calculating expected catch. Multiplied catch generated revenue. defineGroup empty, data treated fleet temp.var Variable containing temporal data temporal Daily (Daily time line) sequential (sequential order) calc.method Select standard average (standardAverage), simple lag regression means (simpleLag), weights regressed groups (weights) lag.method Use regression entire group (simple) grouped time periods (grouped) empty.catch Replace empty catch NA, 0, mean catch (allCatch), mean grouped catch(groupCatch) empty.expectation replace (NULL) replace 0.0001 0 dummy.exp Logical, dummy variable outputted originally missing value. Defaults FALSE.","code":""},{"path":"/reference/medium_expectations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Medium expectations — medium_expectations","text":"Expected catch matrix. Saved database via create_expectations","code":""},{"path":"/reference/merge_dat.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge data tables using a left join — merge_dat","title":"Merge data tables using a left join — merge_dat","text":"Merge data tables using left join","code":""},{"path":"/reference/merge_dat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge data tables using a left join — merge_dat","text":"","code":"merge_dat(   dat,   other,   project,   main_key,   other_key,   other_type,   merge_type = \"left\" )"},{"path":"/reference/merge_dat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge data tables using a left join — merge_dat","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. second data table join MainDataTable. Use string  referencing table saved FishSET database. project Project name. main_key String, name column(s) MainDataTable join .  number columns must match other_key. other_key String, name column(s) table join  . number columns must match main_key. other_type String, type secondary data merged. Options  include \"aux\" (auxiliary), \"grid\" (gridded), \"spat\" (spatial), \"port\". merge_type String, type merge perform. \"left\" keeps rows dat merges shared rows . \"full\" keeps rows table.","code":""},{"path":"/reference/merge_dat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Merge data tables using a left join — merge_dat","text":"function merges two datasets using left join: columns rows    MainDataTable kept matching columns rows    secondary table joined.","code":""},{"path":"/reference/merge_dat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge data tables using a left join — merge_dat","text":"","code":"if (FALSE) {  pollockMainDataTable <-      merge_dat(\"pollockMainDataTable\", \"pollockPortTable\", \"pollock\",                main_key = \"PORT_CODE\", other_key = \"PORT_CODE\") }"},{"path":"/reference/merge_expected_catch.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge expected catch — merge_expected_catch","title":"Merge expected catch — merge_expected_catch","text":"Merge expected catch matrices primary dataset.","code":""},{"path":"/reference/merge_expected_catch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge expected catch — merge_expected_catch","text":"","code":"merge_expected_catch(   dat,   project,   zoneID,   date,   exp.name,   new.name = NULL,   ec.table = NULL,   log_fun = TRUE )"},{"path":"/reference/merge_expected_catch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge expected catch — merge_expected_catch","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. zoneID zone ID Variable dat identifies individual zones areas. date Date variable used create expected catch matrix. exp.name Name(s) expected catch matrix merge dat. new.name Optional, new name exp.name. order exp.name. ec.table Optional, name specific expected catch table use. Defaults projectnameExpectedCatch. log_fun internal use. Whether log function call.","code":""},{"path":"/reference/merge_expected_catch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge expected catch — merge_expected_catch","text":"Merges expected catch matrix created using create_expectations() primary dataset, dat.","code":""},{"path":"/reference/metaColLayoutServ.html","id":null,"dir":"Reference","previous_headings":"","what":"Arrange column UIs — metaColLayoutServ","title":"Arrange column UIs — metaColLayoutServ","text":"Arrange column UIs","code":""},{"path":"/reference/metaColLayoutServ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arrange column UIs — metaColLayoutServ","text":"","code":"metaColLayoutServ(id, cols)"},{"path":"/reference/metaColLayoutServ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arrange column UIs — metaColLayoutServ","text":"id ID string matches corresponding UI function:  metaColLayoutUI.","code":""},{"path":"/reference/metaColLayoutServ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Arrange column UIs — metaColLayoutServ","text":"module used metadata_gui function    FishSET app. arranges column text boxes  main panel.","code":""},{"path":"/reference/metaColLayoutUI.html","id":null,"dir":"Reference","previous_headings":"","what":"Arrange column UIs — metaColLayoutUI","title":"Arrange column UIs — metaColLayoutUI","text":"Arrange column UIs","code":""},{"path":"/reference/metaColLayoutUI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arrange column UIs — metaColLayoutUI","text":"","code":"metaColLayoutUI(id)"},{"path":"/reference/metaColLayoutUI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arrange column UIs — metaColLayoutUI","text":"id ID string matches corresponding server function:  metaColLayoutServ.","code":""},{"path":"/reference/metaColLayoutUI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Arrange column UIs — metaColLayoutUI","text":"module used metadata_gui function    FishSET app. arranges column text boxes main panel.","code":""},{"path":"/reference/metaCreateLoadServ.html","id":null,"dir":"Reference","previous_headings":"","what":"Load server for metadata gui (Create section) Contains actions needed to create new metadata. — metaCreateLoadServ","title":"Load server for metadata gui (Create section) Contains actions needed to create new metadata. — metaCreateLoadServ","text":"Load server metadata gui (Create section) Contains actions needed create new metadata.","code":""},{"path":"/reference/metaCreateLoadServ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load server for metadata gui (Create section) Contains actions needed to create new metadata. — metaCreateLoadServ","text":"","code":"metaCreateLoadServ(id, cols, meta)"},{"path":"/reference/metaCreateLoadServ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load server for metadata gui (Create section) Contains actions needed to create new metadata. — metaCreateLoadServ","text":"id ID string. recommended use informative unique  string \"meta_create\". cols Reactive values object containing column names FishSET  table. meta Reactive values object store metadata .","code":""},{"path":"/reference/metaCreateLoadServ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load server for metadata gui (Create section) Contains actions needed to create new metadata. — metaCreateLoadServ","text":"module used metadata_gui function    FishSET app. loads FishSET tables creates metadata   fields (text boxes) users can edit.","code":""},{"path":"/reference/metaCreateProjServ.html","id":null,"dir":"Reference","previous_headings":"","what":"Project server for metadata gui (Create section) — metaCreateProjServ","title":"Project server for metadata gui (Create section) — metaCreateProjServ","text":"Project server metadata gui (Create section)","code":""},{"path":"/reference/metaCreateProjServ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project server for metadata gui (Create section) — metaCreateProjServ","text":"","code":"metaCreateProjServ(id)"},{"path":"/reference/metaCreateProjServ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project server for metadata gui (Create section) — metaCreateProjServ","text":"id ID string matches corresponding UI function:  metaProjUI.","code":""},{"path":"/reference/metaCreateProjServ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Project server for metadata gui (Create section) — metaCreateProjServ","text":"module used metadata_gui function    FishSET app. creates UIs project name available   project tables.","code":""},{"path":"/reference/metaCreateSaveUI.html","id":null,"dir":"Reference","previous_headings":"","what":"Load and Save buttons for metadata gui (Create section) — metaCreateSaveUI","title":"Load and Save buttons for metadata gui (Create section) — metaCreateSaveUI","text":"Load Save buttons metadata gui (Create section)","code":""},{"path":"/reference/metaCreateSaveUI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load and Save buttons for metadata gui (Create section) — metaCreateSaveUI","text":"","code":"metaCreateSaveUI(id)"},{"path":"/reference/metaCreateSaveUI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load and Save buttons for metadata gui (Create section) — metaCreateSaveUI","text":"id ID string matches corresponding server functions:  metaCreateLoadServ metaSaveServ.","code":""},{"path":"/reference/metaCreateSaveUI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load and Save buttons for metadata gui (Create section) — metaCreateSaveUI","text":"module used metadata_gui function    FishSET app. creates buttons needed load save    metadata.","code":""},{"path":"/reference/metaCreateServ.html","id":null,"dir":"Reference","previous_headings":"","what":"Run metadata servers (Create section) — metaCreateServ","title":"Run metadata servers (Create section) — metaCreateServ","text":"Run metadata servers (Create section)","code":""},{"path":"/reference/metaCreateServ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run metadata servers (Create section) — metaCreateServ","text":"","code":"metaCreateServ(id, cols, meta)"},{"path":"/reference/metaCreateServ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run metadata servers (Create section) — metaCreateServ","text":"id ID string. recommended use informative unique  string \"meta_create\". cols Reactive values object containing column names FishSET  table. meta Reactive values object store metadata .","code":""},{"path":"/reference/metaCreateServ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run metadata servers (Create section) — metaCreateServ","text":"module used metadata_gui function    FishSET app. runs metadata server modules needed save,   edit, delete metadata.","code":""},{"path":"/reference/metadata_gui.html","id":null,"dir":"Reference","previous_headings":"","what":"Import, create, and edit metadata — metadata_gui","title":"Import, create, and edit metadata — metadata_gui","text":"metadata_gui allows users import metadata various file types, create save new metadata, edit metadata shiny application.  Metadata stored user's project folder.","code":""},{"path":"/reference/metadata_gui.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import, create, and edit metadata — metadata_gui","text":"","code":"metadata_gui()"},{"path":"/reference/metadata_gui.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import, create, and edit metadata — metadata_gui","text":"app two tabs: \"Create\" \"Edit\". Create tab allows users   create new metadata selected FishSET table. table loaded,   app creates several text boxes user can fill.    four metadata sections: , Column Description, Contact Info, .   Author author data. Date created date data created. Date modified last data data modified. Version current version data. Confidentiality Whether data contains confidential          information.  Column Description text box column data.       Include data type, unit, values (categorical) Contact Info  Person primary contact. Organization primary contact's organization. Address primary contact's /organization's address. Phone primary contact's work phone number. Email primary contact's work email.   License License data. Citation Citation data. relevant information.  Users can also import metadata file Create tab, example,     XML, CSV, JSON file. gets saved \"raw\" metadata separate    user-created metadata. see comprehensive list accepted file types,   see parse_meta read_dat. extract metadata   data file (.e. data metadata file,    metadata contained within data ), use Reader   parameters text box selectively parse file (see parse_meta   details). Edit tab allows users view, edit, /delete metadata saved    FishSET.","code":""},{"path":"/reference/metadata_gui.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import, create, and edit metadata — metadata_gui","text":"","code":"if (FALSE) { metadata_gui() }"},{"path":"/reference/metaDeleteServ.html","id":null,"dir":"Reference","previous_headings":"","what":"Server for deleting metadata — metaDeleteServ","title":"Server for deleting metadata — metaDeleteServ","text":"Server deleting metadata","code":""},{"path":"/reference/metaDeleteServ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Server for deleting metadata — metaDeleteServ","text":"","code":"metaDeleteServ(id, cols, meta)"},{"path":"/reference/metaDeleteServ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Server for deleting metadata — metaDeleteServ","text":"id ID string matches corresponding UI function:  metaDeleteUI. cols Reactive values object containing column names FishSET  table. meta Reactive values object store metadata .","code":""},{"path":"/reference/metaDeleteServ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Server for deleting metadata — metaDeleteServ","text":"module used metadata_gui function    FishSET app. allows users delete metadata    project folder.","code":""},{"path":"/reference/metaDeleteUI.html","id":null,"dir":"Reference","previous_headings":"","what":"UI for deleting metadata — metaDeleteUI","title":"UI for deleting metadata — metaDeleteUI","text":"UI deleting metadata","code":""},{"path":"/reference/metaDeleteUI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"UI for deleting metadata — metaDeleteUI","text":"","code":"metaDeleteUI(id)"},{"path":"/reference/metaDeleteUI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"UI for deleting metadata — metaDeleteUI","text":"id ID string matches corresponding server function:  metaDeleteServ.","code":""},{"path":"/reference/metaDeleteUI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"UI for deleting metadata — metaDeleteUI","text":"module used metadata_gui function    FishSET app. allows users delete metadata    project folder.","code":""},{"path":"/reference/metaEditLoadServ.html","id":null,"dir":"Reference","previous_headings":"","what":"Load server for metadata gui (Edit section) Contains actions needed to view, edit, and delete metadata entries. — metaEditLoadServ","title":"Load server for metadata gui (Edit section) Contains actions needed to view, edit, and delete metadata entries. — metaEditLoadServ","text":"Load server metadata gui (Edit section) Contains actions needed view, edit, delete metadata entries.","code":""},{"path":"/reference/metaEditLoadServ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load server for metadata gui (Edit section) Contains actions needed to view, edit, and delete metadata entries. — metaEditLoadServ","text":"","code":"metaEditLoadServ(id, cols, meta)"},{"path":"/reference/metaEditLoadServ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load server for metadata gui (Edit section) Contains actions needed to view, edit, and delete metadata entries. — metaEditLoadServ","text":"id ID string. recommended use informative unique  string \"meta_edit\". cols Reactive values object containing column names FishSET  table. meta Reactive values object store metadata .","code":""},{"path":"/reference/metaEditLoadServ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load server for metadata gui (Edit section) Contains actions needed to view, edit, and delete metadata entries. — metaEditLoadServ","text":"module used metadata_gui function    FishSET app. loads FishSET tables creates metadata   fields (text boxes) users can edit.","code":""},{"path":"/reference/metaEditProjServ.html","id":null,"dir":"Reference","previous_headings":"","what":"Project server for metadata gui (Edit section) — metaEditProjServ","title":"Project server for metadata gui (Edit section) — metaEditProjServ","text":"Project server metadata gui (Edit section)","code":""},{"path":"/reference/metaEditProjServ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project server for metadata gui (Edit section) — metaEditProjServ","text":"","code":"metaEditProjServ(id)"},{"path":"/reference/metaEditProjServ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project server for metadata gui (Edit section) — metaEditProjServ","text":"id ID string matches corresponding UI function:  metaProjUI.","code":""},{"path":"/reference/metaEditProjServ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Project server for metadata gui (Edit section) — metaEditProjServ","text":"module used metadata_gui function    FishSET app. creates UIs project name available   project tables.","code":""},{"path":"/reference/metaEditSaveUI.html","id":null,"dir":"Reference","previous_headings":"","what":"Load and Save buttons for metadata gui (Edit section) — metaEditSaveUI","title":"Load and Save buttons for metadata gui (Edit section) — metaEditSaveUI","text":"Load Save buttons metadata gui (Edit section)","code":""},{"path":"/reference/metaEditSaveUI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load and Save buttons for metadata gui (Edit section) — metaEditSaveUI","text":"","code":"metaEditSaveUI(id)"},{"path":"/reference/metaEditSaveUI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load and Save buttons for metadata gui (Edit section) — metaEditSaveUI","text":"id ID string matches corresponding server functions:  metaEditLoadServ metaSaveServ.","code":""},{"path":"/reference/metaEditSaveUI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load and Save buttons for metadata gui (Edit section) — metaEditSaveUI","text":"module used metadata_gui function    FishSET app. creates buttons needed load save    metadata.","code":""},{"path":"/reference/metaEditServ.html","id":null,"dir":"Reference","previous_headings":"","what":"Run metadata servers (Edit section) — metaEditServ","title":"Run metadata servers (Edit section) — metaEditServ","text":"Run metadata servers (Edit section)","code":""},{"path":"/reference/metaEditServ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run metadata servers (Edit section) — metaEditServ","text":"","code":"metaEditServ(id, cols, meta)"},{"path":"/reference/metaEditServ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run metadata servers (Edit section) — metaEditServ","text":"id ID string. recommended use informative unique  string \"meta_edit\". cols Reactive values object containing column names FishSET  table. meta Reactive values object store metadata .","code":""},{"path":"/reference/metaEditServ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run metadata servers (Edit section) — metaEditServ","text":"module used metadata_gui function    FishSET app. runs metadata server modules needed save,   edit, delete metadata.","code":""},{"path":"/reference/metaOut.html","id":null,"dir":"Reference","previous_headings":"","what":"Output UI for metadata — metaOut","title":"Output UI for metadata — metaOut","text":"Output UI metadata","code":""},{"path":"/reference/metaOut.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Output UI for metadata — metaOut","text":"","code":"metaOut(id)"},{"path":"/reference/metaOut.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Output UI for metadata — metaOut","text":"id ID string matches corresponding server functions:  metaCreateLoadServ metaEditLoadServ  metaSaveServ.","code":""},{"path":"/reference/metaOut.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Output UI for metadata — metaOut","text":"module used metadata_gui function    FishSET app. outputs metadata main panel.","code":""},{"path":"/reference/metaProjUI.html","id":null,"dir":"Reference","previous_headings":"","what":"Project UI for metadata gui — metaProjUI","title":"Project UI for metadata gui — metaProjUI","text":"Project UI metadata gui","code":""},{"path":"/reference/metaProjUI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project UI for metadata gui — metaProjUI","text":"","code":"metaProjUI(id)"},{"path":"/reference/metaProjUI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project UI for metadata gui — metaProjUI","text":"id ID string matches corresponding server function:  metaCreateProjServ  metaEditProjServ.","code":""},{"path":"/reference/metaProjUI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Project UI for metadata gui — metaProjUI","text":"module used metadata_gui function    FishSET app. creates UIs project name available   project tables.","code":""},{"path":"/reference/metaRawOut.html","id":null,"dir":"Reference","previous_headings":"","what":"Output UI for raw metadata — metaRawOut","title":"Output UI for raw metadata — metaRawOut","text":"Output UI raw metadata","code":""},{"path":"/reference/metaRawOut.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Output UI for raw metadata — metaRawOut","text":"","code":"metaRawOut(id)"},{"path":"/reference/metaRawOut.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Output UI for raw metadata — metaRawOut","text":"id ID string matches corresponding server functions:  metaRawUI metaRawServ.","code":""},{"path":"/reference/metaRawOut.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Output UI for raw metadata — metaRawOut","text":"module used metadata_gui function    FishSET app. outputs raw metadata main panel.","code":""},{"path":"/reference/metaRawServ.html","id":null,"dir":"Reference","previous_headings":"","what":"Server for handling raw metadata — metaRawServ","title":"Server for handling raw metadata — metaRawServ","text":"Server handling raw metadata","code":""},{"path":"/reference/metaRawServ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Server for handling raw metadata — metaRawServ","text":"","code":"metaRawServ(id, meta)"},{"path":"/reference/metaRawServ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Server for handling raw metadata — metaRawServ","text":"id ID string matches corresponding server functions:  metaRawUI metaRawOut. meta Reactive values object store metadata .","code":""},{"path":"/reference/metaRawServ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Server for handling raw metadata — metaRawServ","text":"module used metadata_gui function    FishSET app. imports saves raw metadata.","code":""},{"path":"/reference/metaRawUI.html","id":null,"dir":"Reference","previous_headings":"","what":"UIs for handling raw metadata — metaRawUI","title":"UIs for handling raw metadata — metaRawUI","text":"UIs handling raw metadata","code":""},{"path":"/reference/metaRawUI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"UIs for handling raw metadata — metaRawUI","text":"","code":"metaRawUI(id)"},{"path":"/reference/metaRawUI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"UIs for handling raw metadata — metaRawUI","text":"id ID string matches corresponding server functions:  metaRawServ metaRawOut.","code":""},{"path":"/reference/metaRawUI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"UIs for handling raw metadata — metaRawUI","text":"module used metadata_gui function    FishSET app. allows users import save raw metadata   file.","code":""},{"path":"/reference/metaSaveServ.html","id":null,"dir":"Reference","previous_headings":"","what":"Save server for metadata gui Contains actions needed to save metadata to meta log. — metaSaveServ","title":"Save server for metadata gui Contains actions needed to save metadata to meta log. — metaSaveServ","text":"Save server metadata gui Contains actions needed save metadata meta log.","code":""},{"path":"/reference/metaSaveServ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save server for metadata gui Contains actions needed to save metadata to meta log. — metaSaveServ","text":"","code":"metaSaveServ(id, cols)"},{"path":"/reference/metaSaveServ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save server for metadata gui Contains actions needed to save metadata to meta log. — metaSaveServ","text":"id ID string. recommended use informative unique  string \"meta_create\" \"meta_edit\". cols Reactive values object containing column names FishSET  table.","code":""},{"path":"/reference/metaSaveServ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Save server for metadata gui Contains actions needed to save metadata to meta log. — metaSaveServ","text":"module used metadata_gui function    FishSET app. saves new edited metadata project   folder.","code":""},{"path":"/reference/meta_file_exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if meta file exists for a project — meta_file_exists","title":"Check if meta file exists for a project — meta_file_exists","text":"Check meta file exists project","code":""},{"path":"/reference/meta_file_exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if meta file exists for a project — meta_file_exists","text":"","code":"meta_file_exists(project)"},{"path":"/reference/meta_file_exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if meta file exists for a project — meta_file_exists","text":"project Project name.","code":""},{"path":"/reference/meta_file_exists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if meta file exists for a project — meta_file_exists","text":"TRUE project meta file exists, FALSE .","code":""},{"path":"/reference/meta_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a meta list with column description section Used to create a new metadata entry. — meta_list","title":"Create a meta list with column description section Used to create a new metadata entry. — meta_list","text":"Create meta list column description section Used create new metadata entry.","code":""},{"path":"/reference/meta_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a meta list with column description section Used to create a new metadata entry. — meta_list","text":"","code":"meta_list(type, dat = NULL)"},{"path":"/reference/meta_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a meta list with column description section Used to create a new metadata entry. — meta_list","text":"type String dat Dataset","code":""},{"path":"/reference/meta_log_call.html","id":null,"dir":"Reference","previous_headings":"","what":"Log metadata to project folder Meta data is saved to the metadata `meta_log.json` file in a project's `doc/` directory. — meta_log_call","title":"Log metadata to project folder Meta data is saved to the metadata `meta_log.json` file in a project's `doc/` directory. — meta_log_call","text":"Log metadata project folder Meta data saved metadata `meta_log.json` file project's `doc/` directory.","code":""},{"path":"/reference/meta_log_call.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log metadata to project folder Meta data is saved to the metadata `meta_log.json` file in a project's `doc/` directory. — meta_log_call","text":"","code":"meta_log_call(   project,   meta,   dataset = NULL,   tab_name,   tab_type,   overwrite = FALSE,   raw = TRUE )"},{"path":"/reference/meta_log_call.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log metadata to project folder Meta data is saved to the metadata `meta_log.json` file in a project's `doc/` directory. — meta_log_call","text":"project Project name. meta Meta data list saved. dataset data object. Used create column description section metadata log entry. NULL, section left empty. may case saving raw metadata. add column descriptions,  use meta_form app. tab_name table name appears FishSET Database (e.g. \"projectMainDataTable\" main table). tab_type table type. Options include \"main\", \"spat\" (spatial),  \"port\", \"grid\" (gridded), \"aux\" (auxiliary). overwrite Logical, whether save existing metadata entry. raw Logical, whether raw metadata file saved.","code":""},{"path":"/reference/meta_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Print meta tables by project and/or type — meta_tables","title":"Print meta tables by project and/or type — meta_tables","text":"Print meta tables project /type","code":""},{"path":"/reference/meta_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print meta tables by project and/or type — meta_tables","text":"","code":"meta_tables(project, tab.type = NULL)"},{"path":"/reference/meta_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print meta tables by project and/or type — meta_tables","text":"project Name project. tab.type String, table type. Optional, used filter output. Options  include \"main\", \"spat\" (spatial), \"port\", \"grid\" (gridded), \"aux\"  (auxiliary).","code":""},{"path":"/reference/mixed_logit_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixed Logit predict — mixed_logit_predict","title":"Mixed Logit predict — mixed_logit_predict","text":"Prediction component mixed logit models alled Policy3, predict_model_tempNew.m","code":""},{"path":"/reference/mixed_logit_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mixed Logit predict — mixed_logit_predict","text":"","code":"mixed_logit_predict(project, logitEq, alts, mod.name, expected.catch = NULL)"},{"path":"/reference/mixed_logit_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixed Logit predict — mixed_logit_predict","text":"project Name project logitEq Parameter estimates alts Number alternatives choices model mod.name Name saved model use expected.catch Required conditional logit (logit_c) model.  Name expected catch table use.   Can expected catch short-term scenario (short), medium-term scenario (med),   long-term scenario (long), user-defined temporal parameters (user).","code":""},{"path":"/reference/mixed_logit_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mixed Logit predict — mixed_logit_predict","text":"Returns probability mixed logit model choice","code":""},{"path":"/reference/model_design_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Model Design List — model_design_list","title":"Get Model Design List — model_design_list","text":"Returns Model Design list FishSET database.","code":""},{"path":"/reference/model_design_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Model Design List — model_design_list","text":"","code":"model_design_list(project, name = NULL)"},{"path":"/reference/model_design_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Model Design List — model_design_list","text":"project Name project. name Name Model Design list FishSET database.  table name contain string \"ModelInputData\". NULL,  default table returned. Use tables_database see list  FishSET database tables project.","code":""},{"path":"/reference/model_design_outsample.html","id":null,"dir":"Reference","previous_headings":"","what":"Design hold-out model — model_design_outsample","title":"Design hold-out model — model_design_outsample","text":"Use selected model design settings create model design hold-data. hold-data can  --sample data subsetted data k-fold cross validation.","code":""},{"path":"/reference/model_design_outsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Design hold-out model — model_design_outsample","text":"","code":"model_design_outsample(   project,   mod.name,   outsample.mod.name = NULL,   CV = FALSE,   CV_dat = NULL,   use.scalers = FALSE,   scaler.func = NULL )"},{"path":"/reference/model_design_outsample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Design hold-out model — model_design_outsample","text":"project Name project mod.name Name saved model use. Argument can name model can pull name  saved \"best\" model. Leave mod.name empty use saved \"best\" model. one model saved, mod.name numeric indicator model use. Use table_view(\"modelChosen\", project) view table saved models. outsample.mod.name Name assigned --sample model design. Must unique already exist model design list. outsample.mod.name = NULL default name chosen based mod.name, default value. CV Logical, Indicates whether model design created cross validation TRUE, simple - -sample dataset. Defaults CV = TRUE. CV_dat Training testing dataset k-fold cross validation. use.scalers Input create_model_input(). Logical, data normalized? Defaults FALSE. Rescaling factors mean  numeric vector unless specified scaler.func. scaler.func Input create_model_input(). Function calculate rescaling factors.","code":""},{"path":"/reference/model_design_outsample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Design hold-out model — model_design_outsample","text":"function automatically pulls model settings selected model creates alternative choice matrix, expected catch/revenue matrices,  model design hold-dataset. hold-data set can --sample dataset subset main data cross validation. running --sample data, function requires filtered --sample data file (.rds file) exists output folder. cross validation, function called cross_validation() function. Note: --sample functions work single selected model time. run --sample functions new --sample dataset, start load_outsample() entirely new dataset filter_outsample().","code":""},{"path":"/reference/model_design_outsample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Design hold-out model — model_design_outsample","text":"","code":"if (FALSE) {  # For out-of-sample dataset model_design_outsample(\"scallop\", \"scallopModName\")  }"},{"path":"/reference/model_error_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve most recent summary of model error — model_error_summary","title":"Retrieve most recent summary of model error — model_error_summary","text":"Retrieve recent summary model error","code":""},{"path":"/reference/model_error_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve most recent summary of model error — model_error_summary","text":"","code":"model_error_summary(project, output = \"print\")"},{"path":"/reference/model_error_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve most recent summary of model error — model_error_summary","text":"project Name project output Output type. \"print\" returns formatted notes. \"table\" returns  dataframe. \"print\" recommended displaying summary table report.","code":""},{"path":"/reference/model_error_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve most recent summary of model error — model_error_summary","text":"","code":"if (FALSE) { model_error_summary(\"pollock\") }"},{"path":"/reference/model_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Load model comparison metrics to console for the defined project — model_fit","title":"Load model comparison metrics to console for the defined project — model_fit","text":"Load model comparison metrics console. Metrics displayed  model fun. Metrics produced discretefish_subroutine.","code":""},{"path":"/reference/model_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load model comparison metrics to console for the defined project — model_fit","text":"","code":"model_fit(project, CV = FALSE)"},{"path":"/reference/model_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load model comparison metrics to console for the defined project — model_fit","text":"project String, name project. CV Logical, CV = TRUE get model fit training data k-fold cross validation routine.","code":""},{"path":"/reference/model_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load model comparison metrics to console for the defined project — model_fit","text":"","code":"if (FALSE) { model_fit('pollock') }"},{"path":"/reference/model_fit_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve most recent summary of model fit — model_fit_summary","title":"Retrieve most recent summary of model fit — model_fit_summary","text":"Retrieve recent summary model fit","code":""},{"path":"/reference/model_fit_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve most recent summary of model fit — model_fit_summary","text":"","code":"model_fit_summary(project, output = \"print\")"},{"path":"/reference/model_fit_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve most recent summary of model fit — model_fit_summary","text":"project Name project output Output type. \"print\" returns formatted notes. \"table\" returns  dataframe. \"print\" recommended displaying summary table report.","code":""},{"path":"/reference/model_fit_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve most recent summary of model fit — model_fit_summary","text":"","code":"if (FALSE) { model_fit_summary(\"pollock\") }"},{"path":"/reference/model_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Return model names — model_names","title":"Return model names — model_names","text":"Returns model names saved model design file.","code":""},{"path":"/reference/model_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return model names — model_names","text":"","code":"model_names(project)"},{"path":"/reference/model_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return model names — model_names","text":"project Name project.","code":""},{"path":"/reference/model_out_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve most recent summary of model output — model_out_summary","title":"Retrieve most recent summary of model output — model_out_summary","text":"Retrieve recent summary model output","code":""},{"path":"/reference/model_out_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve most recent summary of model output — model_out_summary","text":"","code":"model_out_summary(project, output = \"print\")"},{"path":"/reference/model_out_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve most recent summary of model output — model_out_summary","text":"project Name project output Output type. \"print\" returns formatted notes. \"table\" returns  dataframe. \"print\" recommended displaying summary table report.","code":""},{"path":"/reference/model_out_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve most recent summary of model output — model_out_summary","text":"","code":"if (FALSE) { model_out_summary(\"pollock\") }"},{"path":"/reference/model_out_view.html","id":null,"dir":"Reference","previous_headings":"","what":"Load discrete choice model output to console for the defined project — model_out_view","title":"Load discrete choice model output to console for the defined project — model_out_view","text":"Returns output running discretefish_subroutine function.   table parameter must full name table name FishSET database.","code":""},{"path":"/reference/model_out_view.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load discrete choice model output to console for the defined project — model_out_view","text":"","code":"model_out_view(project, CV = FALSE)"},{"path":"/reference/model_out_view.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load discrete choice model output to console for the defined project — model_out_view","text":"project Name project CV Logical, CV = TRUE viewing model output training data k-fold cross validation","code":""},{"path":"/reference/model_out_view.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load discrete choice model output to console for the defined project — model_out_view","text":"Returns output running discretefish_subroutine. table  argument must full name table name FishSET database.  Output includes information model convergence, standard errors, t-stats, etc.","code":""},{"path":"/reference/model_out_view.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load discrete choice model output to console for the defined project — model_out_view","text":"","code":"if (FALSE) { model_out_view('pcod') }"},{"path":"/reference/model_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Load model parameter estimates, standard errors, and t-statistic to console for the defined project — model_params","title":"Load model parameter estimates, standard errors, and t-statistic to console for the defined project — model_params","text":"Returns parameter estimates, standard errors, t-statistic   running discretefish_subroutine function. table parameter must   full name table name FishSET database.","code":""},{"path":"/reference/model_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load model parameter estimates, standard errors, and t-statistic to console for the defined project — model_params","text":"","code":"model_params(project, output = \"list\")"},{"path":"/reference/model_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load model parameter estimates, standard errors, and t-statistic to console for the defined project — model_params","text":"project Name project output Options include list, table, print.","code":""},{"path":"/reference/model_params.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load model parameter estimates, standard errors, and t-statistic to console for the defined project — model_params","text":"Returns parameter estimates running discretefish_subroutine.  table argument must full name table name FishSET  database.","code":""},{"path":"/reference/model_params.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load model parameter estimates, standard errors, and t-statistic to console for the defined project — model_params","text":"","code":"if (FALSE) { model_params('pcod') }"},{"path":"/reference/model_prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Model prediction — model_prediction","title":"Model prediction — model_prediction","text":"Estimate redistributed fishing effort following policy change change factors influence fisher location choice.","code":""},{"path":"/reference/model_prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model prediction — model_prediction","text":"","code":"model_prediction(   project,   mod.name,   closures,   enteredPrice = NULL,   use.scalers = FALSE,   scaler.func = NULL )"},{"path":"/reference/model_prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model prediction — model_prediction","text":"project Name project mod.name Model name. Argument can name model name can pulled modelChosen table.  Leave mod.name empty use name saved \"best\" model. one model saved, mod.name numeric indicator model use. Use table_view(\"modelChosen\", project) view table saved models. closures closure scenarios enteredPrice NEED FIGURE EXACTLY use.scalers Input create_model_input(). Logical, data normalized? Defaults FALSE. Rescaling factors mean  numeric vector unless specified scaler.func. scaler.func Input create_model_input(). Function calculate rescaling factors.","code":""},{"path":"/reference/model_prediction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model prediction — model_prediction","text":"Calls logit_predict, epm_predict, predict_probability.    Closure scenarios TAC must define using zone_closure function function can run.","code":""},{"path":"/reference/moran_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate and view Moran's I statistic — moran_stats","title":"Calculate and view Moran's I statistic — moran_stats","text":"Wrapper function calculate global local Moran's discrete area.","code":""},{"path":"/reference/moran_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate and view Moran's I statistic — moran_stats","text":"","code":"moran_stats(   dat,   project,   varofint,   zoneid,   spat,   cat,   lon.dat = NULL,   lat.dat = NULL,   lon.spat = NULL,   lat.spat = NULL )"},{"path":"/reference/moran_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate and view Moran's I statistic — moran_stats","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MaindataTable'. project String, name project. varofint Numeric variable dat test spatial autocorrelation. zoneid Variable dat identifies individual zones areas. Define exists dat named `ZoneID`. Defaults NULL. spat Spatial data containing information fishery management regulatory zones. Shape, json, geojson, csv formats supported. cat Variable list spat identifies individual areas zones. spat class sf, cat name list containing information zones. lon.dat Longitude variable dat. lat.dat Latitude variable dat. lon.spat Variable list spat containing longitude data.  Required csv files. Leave NULL spat shape json file. lat.spat Variable list spat containing latitude data.  Required csv files. Leave NULL spat shape json file.","code":""},{"path":"/reference/moran_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate and view Moran's I statistic — moran_stats","text":"Returns plot map Moran’s . Output saved Output folder.","code":""},{"path":"/reference/moran_stats.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate and view Moran's I statistic — moran_stats","text":"Measure degree spatial autocorrelation. Function utilizes  localmoran knearneigh functions  spdep package. spatial input row-standardized spatial weights matrix computed nearest neighbor matrix, null setting  nb2listw function. function requires map  file lat/lon defining boundaries area/zones varofint  test spatial autocorrelation. zonal centroid included  map file, find_centroid function called calculate  centroid zone. variable interest associated area/zone assignment_column called assign observation  zone. Arguments identify centroid assign variable interest  area/zone optional default NULL.","code":""},{"path":"/reference/moran_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate and view Moran's I statistic — moran_stats","text":"","code":"if (FALSE) { moran_stats(pcodMainDataTable, project='pcod', varofint='OFFICIAL_MT_TONS', spat=spatdat, lon.dat='LonLat_START_LON', lat.dat ='LonLat_START_LAT', cat='NMFS_AREA') }"},{"path":"/reference/msg_print.html","id":null,"dir":"Reference","previous_headings":"","what":"Display temporary file using message or print — msg_print","title":"Display temporary file using message or print — msg_print","text":"shiny running, prints. Otherwise, uses message.","code":""},{"path":"/reference/msg_print.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display temporary file using message or print — msg_print","text":"","code":"msg_print(temp_file)"},{"path":"/reference/msg_print.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display temporary file using message or print — msg_print","text":"temp_file temporary file display. j","code":""},{"path":"/reference/mvgrnd.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate normal random generator — mvgrnd","title":"Multivariate normal random generator — mvgrnd","text":"Multivariate normal random generator","code":""},{"path":"/reference/mvgrnd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate normal random generator — mvgrnd","text":"","code":"mvgrnd(m, sigma, n)"},{"path":"/reference/mvgrnd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate normal random generator — mvgrnd","text":"m mean vector sigma variance-covariance matrix n number iterations","code":""},{"path":"/reference/name_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for unique and syntatcic column names — name_check","title":"Check for unique and syntatcic column names — name_check","text":"Used creating new columns.","code":""},{"path":"/reference/name_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for unique and syntatcic column names — name_check","text":"","code":"name_check(dat, names, repair = FALSE)"},{"path":"/reference/name_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for unique and syntatcic column names — name_check","text":"dat Dataset contain new columns. names New names added dataset. repair Logical, whether return repaired column names (repair = TRUE) just check unique column names (repair = FALSE).","code":""},{"path":"/reference/name_check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check for unique and syntatcic column names — name_check","text":"name_check() first checks see new column names unique   returns error . repair = TRUE, name_check()    check unique column names returns new column names   unique syntactic (see vec_as_names details).","code":""},{"path":"/reference/nan_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify, remove, or replace NaNs — nan_filter","title":"Identify, remove, or replace NaNs — nan_filter","text":"Replaces NaNs primary data chosen value removes rows  containing NaNs","code":""},{"path":"/reference/nan_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify, remove, or replace NaNs — nan_filter","text":"","code":"nan_filter(   dat,   project,   x = NULL,   replace = FALSE,   remove = FALSE,   rep.value = \"mean\",   over_write = FALSE )"},{"path":"/reference/nan_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify, remove, or replace NaNs — nan_filter","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project Project name. x Character string variables remove replace NaNs. replace Logical, TRUE, NaNs replaced. Defaults FALSE. remove Logical, TRUE, removes entire row dataset  NaN present. Defaults FALSE. rep.value Value replace NaNs numeric column. Defaults  mean value column. options include \"median\" numeric value, e.g. rep.value = 0. over_write Logical, TRUE, saves data previously saved  data table FishSET database. Defaults FALSE.","code":""},{"path":"/reference/nan_filter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify, remove, or replace NaNs — nan_filter","text":"replace remove FALSE statement  whether NaNs found returned. either replace remove TRUE modified primary dataset returned.","code":""},{"path":"/reference/nan_filter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify, remove, or replace NaNs — nan_filter","text":"check NaNs across dat run function specifying    dat (nan_filter(dataset, project)). function return    statement variables, , contain NaNs. remove NaNs, use    remove = TRUE. rows containing NaNs x removed    dat. replace NaNs, use replace = TRUE.    replace remove TRUE replace used.    replace FALSE rep.value defined,    NaNs replaced  mean value. modified dataset returned    replace = TRUE remove = TRUE. Save modified data    table FishSET database setting over_write = TRUE).","code":""},{"path":"/reference/nan_filter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify, remove, or replace NaNs — nan_filter","text":"","code":"if (FALSE) { nan_filter(pcodMainDataTable, 'pcod', 'OFFICIAL_TOTAL_CATCH_MT')  mod.dat <- nan_filter(pcodMainDataTable, 'pcod', 'OFFICIAL_TOTAL_CATCH_MT',                        replace = TRUE)                        mod.dat <- nan_filter(pcodMainDataTable, 'pcod', 'OFFICIAL_TOTAL_CATCH_MT',                       replace = TRUE, rep.value = 0)                        mod.dat <- nan_filter(pcodMainDataTable, 'pcod', 'OFFICIAL_TOTAL_CATCH_MT',                        remove = TRUE) }"},{"path":"/reference/nan_identify.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify NaNs and NAs — nan_identify","title":"Identify NaNs and NAs — nan_identify","text":"Check whether columns primary dataset contain NAs NaNs.    Returns column names containing NAs NaNs.","code":""},{"path":"/reference/nan_identify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify NaNs and NAs — nan_identify","text":"","code":"nan_identify(dat, project)"},{"path":"/reference/nan_identify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify NaNs and NAs — nan_identify","text":"dat Primary data containing information hauls trips.  Table FishSET database contains string 'MainDataTable'. project Project name.","code":""},{"path":"/reference/nan_identify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify NaNs and NAs — nan_identify","text":"Returns names columns containing NAs NaNs, .","code":""},{"path":"/reference/nan_identify.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify NaNs and NAs — nan_identify","text":"Check whether columns primary dataset contain NAs NaNs.","code":""},{"path":[]},{"path":"/reference/nan_identify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify NaNs and NAs — nan_identify","text":"","code":"if (FALSE) { nan_identify(pcodMainDataTable, \"pcod\") }"},{"path":"/reference/na_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify, remove, or replace NAs and NaNs — na_filter","title":"Identify, remove, or replace NAs and NaNs — na_filter","text":"Replaces NAs NaNs primary data chosen value removes rows  containing NAs NaNs.","code":""},{"path":"/reference/na_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify, remove, or replace NAs and NaNs — na_filter","text":"","code":"na_filter(   dat,   project,   x = NULL,   replace = FALSE,   remove = FALSE,   rep.value = \"mean\",   over_write = FALSE )"},{"path":"/reference/na_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify, remove, or replace NAs and NaNs — na_filter","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project Project name. x Character string. Column(s) dat remove replace NAs. replace Logical, TRUE, replaces NAs vector rep.value.  Defaults FALSE. remove Logical, TRUE removes entire row dat  NA present dat. Defaults FALSE. rep.value Value replace NAs numeric column. Defaults  mean value column. options include \"median\" numeric value, e.g. rep.value = 0. over_write Logical, TRUE, saves data previously saved  data table FishSET database.","code":""},{"path":"/reference/na_filter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify, remove, or replace NAs and NaNs — na_filter","text":"replace remove FALSE statement  whether NAs found returned. either replace remove TRUE modified primary dataset returned.","code":""},{"path":"/reference/na_filter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify, remove, or replace NAs and NaNs — na_filter","text":"check NAs across dat run function specifying    dat (na_filter(dataset, project)). function return statement    variables, , contain NAs. remove NAs, use remove = TRUE.    rows containing NAs x removed dat. replace    NAs, use replace = TRUE. replace = FALSE rep.value    defined, NAs replaced mean value. modified dataset   returned replace = TRUE remove = TRUE.    replace remove TRUE replace used.    Save modified data table FishSET database setting    over_write = TRUE).","code":""},{"path":"/reference/na_filter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify, remove, or replace NAs and NaNs — na_filter","text":"","code":"if (FALSE) { na_filter(pcodMainDataTable, 'pcod', 'OFFICIAL_TOTAL_CATCH_MT')  mod.dat <- na_filter(pcodMainDataTable, 'pcod', 'OFFICIAL_TOTAL_CATCH_MT',                       replace = TRUE)                       mod.dat <- na_filter(pcodMainDataTable,'pcod', 'OFFICIAL_TOTAL_CATCH_MT',                      replace = TRUE, rep.value = 0)                       mod.dat <- na_filter(pcodMainDataTable, 'pcod',                      c('OFFICIAL_TOTAL_CATCH_MT', 'CATCH_VALUE'),                       remove = TRUE) }"},{"path":"/reference/new_zone_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Create new zone IDs — new_zone_id","title":"Create new zone IDs — new_zone_id","text":"Creates new zone ID column combined zone file. Used combining regulatory zones closure areas.","code":""},{"path":"/reference/new_zone_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create new zone IDs — new_zone_id","text":"","code":"new_zone_id(   combined,   id,   grid = NULL,   closure = NULL,   inter = NULL,   recast = TRUE )"},{"path":"/reference/new_zone_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create new zone IDs — new_zone_id","text":"combined Combined version grid closure file. id Character, name zone ID column. grid Grid file containing regulatory zones. closure Closure file containing closure areas. recast Logical, TRUE combined passed  recast_multipoly.","code":""},{"path":"/reference/new_zone_id.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create new zone IDs — new_zone_id","text":"function assigns new zone ID intersection grid    closure creates new, non-contiguous polygons. ID naming    convection original name regulatory zone followed    decimal number. example, closure area bi-sects regulatory    zone , resulting zone IDs \".1\" \".2\".","code":""},{"path":[]},{"path":"/reference/nfreq_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create one or more binned frequency tables — nfreq_table","title":"Create one or more binned frequency tables — nfreq_table","text":"Create one binned frequency, relative frequency, density table.","code":""},{"path":"/reference/nfreq_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create one or more binned frequency tables — nfreq_table","text":"","code":"nfreq_table(   dataset,   var,   group = NULL,   bins = 30,   type = \"dens\",   v_id = NULL,   format_lab = \"decimal\",   format_tab = \"wide\" )"},{"path":"/reference/nfreq_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create one or more binned frequency tables — nfreq_table","text":"dataset Primary data containing information hauls trips. Table FishSET database contain string `MainDataTable`. var String, name numeric variable bin. group String, name variable(s) group var . bins Integer, number bins create. type String, type binned frequency table create. \"freq\" creates frequency table, \"perc\" creates relative frequency table, \"dens\" creates density table. v_id String, name vessel ID column (used detect confidential information). format_lab Formatting option bin labels. Options include  \"decimal\" \"scientific\". format_tab Format table \"wide\" \"long\"","code":""},{"path":"/reference/nmfs_manage_simple.html","id":null,"dir":"Reference","previous_headings":"","what":"Shape file for NMFS fishing zones — nmfs_manage_simple.json","title":"Shape file for NMFS fishing zones — nmfs_manage_simple.json","text":"Simple feature collection 25 features 2 fields","code":""},{"path":"/reference/nmfs_manage_simple.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Shape file for NMFS fishing zones — nmfs_manage_simple.json","text":"shape file","code":""},{"path":"/reference/numeric_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Find numeric columns in data frame — numeric_cols","title":"Find numeric columns in data frame — numeric_cols","text":"Find numeric columns data frame","code":""},{"path":"/reference/numeric_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find numeric columns in data frame — numeric_cols","text":"","code":"numeric_cols(dat, out = \"names\")"},{"path":"/reference/numeric_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find numeric columns in data frame — numeric_cols","text":"dat MainDataTable, dataframe, list check. Whether return column \"names\" (default) logical vector  (\"logical\").","code":""},{"path":"/reference/numeric_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find numeric columns in data frame — numeric_cols","text":"","code":"if (FALSE) { numeric_cols(pollockMainDataTable) }"},{"path":"/reference/num_breaks.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot breaks for numeric variable — num_breaks","title":"Plot breaks for numeric variable — num_breaks","text":"Plot breaks numeric variable","code":""},{"path":"/reference/num_breaks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot breaks for numeric variable — num_breaks","text":"","code":"num_breaks(per)"},{"path":"/reference/num_breaks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot breaks for numeric variable — num_breaks","text":"per period set breaks .","code":""},{"path":"/reference/n_breaks.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot breaks — n_breaks","title":"Plot breaks — n_breaks","text":"Plot breaks","code":""},{"path":"/reference/n_breaks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot breaks — n_breaks","text":"","code":"n_breaks(x)"},{"path":"/reference/n_breaks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot breaks — n_breaks","text":"x Value determine breaks","code":""},{"path":"/reference/order_factor.html","id":null,"dir":"Reference","previous_headings":"","what":"Order variable — order_factor","title":"Order variable — order_factor","text":"Order variable","code":""},{"path":"/reference/order_factor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Order variable — order_factor","text":"","code":"order_factor(dat, fac, val, rev = FALSE)"},{"path":"/reference/order_factor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Order variable — order_factor","text":"dat dataframe containing variable order. fac variable name order. val value variable order . rev logical, reverse order.","code":""},{"path":"/reference/order_factor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Order variable — order_factor","text":"Returns entire dataframe ordered factor.","code":""},{"path":"/reference/outlier_boxplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Boxplot to assess outliers — outlier_boxplot","title":"Boxplot to assess outliers — outlier_boxplot","text":"Boxplot assess outliers","code":""},{"path":"/reference/outlier_boxplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Boxplot to assess outliers — outlier_boxplot","text":"","code":"outlier_boxplot(dat, project, x = NULL)"},{"path":"/reference/outlier_boxplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Boxplot to assess outliers — outlier_boxplot","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. x Variables dat check outliers. Leave  x = NULL plot numeric variables. specify multiple variables  use c('var1', 'var2')","code":""},{"path":"/reference/outlier_boxplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Boxplot to assess outliers — outlier_boxplot","text":"Box whisker plot numeric variables. Saved `output` folder.","code":""},{"path":"/reference/outlier_boxplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Boxplot to assess outliers — outlier_boxplot","text":"Creates visual representation five summary statistics:    median, two hinges (first third quartiles), two whiskers (extends    1.5*IQR IQR distance first third quartiles.   \"Outlying\" points, beyond two whiskers (1.5*IQR) shown    individually.","code":""},{"path":"/reference/outlier_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate outliers in plot format — outlier_plot","title":"Evaluate outliers in plot format — outlier_plot","text":"Visualize spread data measures identify outliers.","code":""},{"path":"/reference/outlier_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate outliers in plot format — outlier_plot","text":"","code":"outlier_plot(   dat,   project,   x,   dat.remove = \"none\",   sd_val = NULL,   x.dist = \"normal\",   date = NULL,   group = NULL,   pages = \"single\",   output.screen = FALSE,   log_fun = TRUE )"},{"path":"/reference/outlier_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate outliers in plot format — outlier_plot","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. x Variable dat check outliers. dat.remove Outlier measure. Values outside measure removed.  Users can use predefined values (see ) user-defined distance  mean. user-defined values, dat.remove numeric  value. example, dat.remove = 6 result value outside  6SD mean class outliers. User-defined standard deviations  mean can also applied using sd_val. Pre-defined choices:  \"none\", \"5_95_quant\", \"25_75_quant\", \"mean_2SD\",  \"median_2SD\", \"mean_3SD\", \"median_3SD\". See  Details section information. sd_val Optional. Number standard deviations mean defining outliers.  Example, sd_val = 6 mean values outside +/- 6 SD mean  outliers. x.dist Distribution data. Choices include: \"normal\",  \"lognormal\", \"exponential\", \"Weibull\", \"Poisson\",  \"negative binomial\". date (Optional) date variable group histogram year. group (Optional) additional variable group histogram . pages Whether output plots single page (\"single\",  default) multiple pages (\"multi\"). output.screen Logical, true, return plots screen. FALSE,  returns plot 'output' folder png file. log_fun Logical, whether log function call (internal use).","code":""},{"path":"/reference/outlier_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate outliers in plot format — outlier_plot","text":"Plot data","code":""},{"path":"/reference/outlier_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate outliers in plot format — outlier_plot","text":"function returns three plots: data, probability plot,   Q-Q plot. data plot returns x row number.   Red points data points removed based dat.remove.   Blue points data points within bounds dat.remove.   dat.remove \"none\", blue points shown.  probability plot histogram data, applying   dat.remove, fitted probability distribution based   x.dist. group groups histogram variable dat,   date groups histogram year. Q-Q plot plots   sampled quantiles theoretical quantiles, applying dat.remove.     dat.remove choices : numeric value: Remove data points outside +/- `x`SD mean none:          data points removed 5_95_quant:    Removes data points outside 5th 95th quantiles 25_75_quant:   Removes data points outside 25th 75th quantiles mean_2SD:      Removes data points outside +/- 2SD mean median_2SD:    Removes data points outside +/- 2SD median mean_3SD:      Removes data points outside +/- 3SD mean median_3SD:    Removes data points outside +/- 3SD median distribution choices : normal lognormal exponential Weibull Poisson negative binomial","code":""},{"path":"/reference/outlier_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate outliers in plot format — outlier_plot","text":"","code":"if (FALSE) {  outlier_plot(pollockMainDataTable, 'pollock', x = 'Haul', dat.remove = 'mean_2SD',               x.dist = 'normal', output.screen = TRUE) # user-defined outlier         outlier_plot(pollockMainDataTable, 'pollock', x = 'Haul', dat.remove = 6,               x.dist = 'lognormal', output.screen = TRUE) }"},{"path":"/reference/outlier_plot_int.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate outliers through plots — outlier_plot_int","title":"Evaluate outliers through plots — outlier_plot_int","text":"Evaluate outliers plots","code":""},{"path":"/reference/outlier_plot_int.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate outliers through plots — outlier_plot_int","text":"","code":"outlier_plot_int(   dat,   x,   dat_remove = \"none\",   x_dist = \"normal\",   sd_val = NULL,   plot_type )"},{"path":"/reference/outlier_plot_int.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate outliers through plots — outlier_plot_int","text":"dat Main data frame apply function. Table fishet_db  database contain string `MainDataTable`. x Column dataframe check outliers. dat_remove Defines method subset data. Choices include: 'none',  '5_95_quant', '25_75_quant', 'mean_2SD', 'median_2SD', 'mean_3SD', 'median_3SD'. x_dist Distribution data. Choices include: 'normal', 'lognormal',  'exponential', 'weibull', 'poisson', 'negative binomial'. sd_val User-defined rule. plot_type plot return.","code":""},{"path":"/reference/outlier_plot_int.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate outliers through plots — outlier_plot_int","text":"Plot data","code":""},{"path":"/reference/outlier_plot_int.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate outliers through plots — outlier_plot_int","text":"function returns three plots, data, probability plot,   Q-Q plot. data plot value x row number.   Red points data without points removed. blue points   subsetted data. `dat_remove` `none`, blue points   shown. probability plot histogram data fitted   probability distribution based `x_dist`. Q-Q plot plots  sampled quantiles theoretical quantiles.","code":""},{"path":"/reference/outlier_remove.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove outliers from data table — outlier_remove","title":"Remove outliers from data table — outlier_remove","text":"Remove outliers based outlier measure.","code":""},{"path":"/reference/outlier_remove.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove outliers from data table — outlier_remove","text":"","code":"outlier_remove(   dat,   project,   x,   dat.remove = \"none\",   sd_val = NULL,   over_write = FALSE )"},{"path":"/reference/outlier_remove.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove outliers from data table — outlier_remove","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. x Variable dat containing potential outliers. dat.remove Defines measure subset data. Users can use  predefined values (see ) user-defined standard deviations  mean. user-defined values, dat.remove numeric value.  example, dat.remove=6 result value outside 6SD  mean class outliers. User-defined standard deviations  mean can also applied using sd_val. Predefined choices:  \"none\", \"5_95_quant\", \"25_75_quant\", \"mean_2SD\",  \"median_2SD\", \"mean_3SD\", \"median_3SD\". sd_val Optional. Number standard deviations mean defining  outliers. example, sd_val=6 mean values outside +/- 6 SD  mean outliers. over_write Logical, TRUE, saves data previously saved  data table FishSET database.","code":""},{"path":"/reference/outlier_remove.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove outliers from data table — outlier_remove","text":"Returns modified primary dataset. Modified dataset saved    FishSET database.","code":""},{"path":"/reference/outlier_remove.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove outliers from data table — outlier_remove","text":"dat.remove choices : numeric value: Remove data points outside +/- `x`SD mean none:        data points removed 5_95_quant:  Removes data points outside 5th 95th quantiles 25_75_quant: Removes data points outside 25th 75th quantiles mean_2SD:    Removes data points outside +/- 2SD mean median_2SD:  Removes data points outside +/- 2SD median mean_3SD:    Removes data points outside +/- 3SD mean median_3SD:  Removes data points outside +/- 3SD median","code":""},{"path":"/reference/outlier_remove.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove outliers from data table — outlier_remove","text":"","code":"if (FALSE) { pollockMainDataTable <- outlier_remove(pollockMainDataTable, 'pollock', 'dist',     dat.remove = 'mean_2SD', save.output = TRUE) }"},{"path":"/reference/outlier_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate outliers in Data — outlier_table","title":"Evaluate outliers in Data — outlier_table","text":"outlier_table() returns summary table shows summary statistics variable applying several outlier filters.","code":""},{"path":"/reference/outlier_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate outliers in Data — outlier_table","text":"","code":"outlier_table(dat, project, x, sd_val = NULL, log_fun = TRUE)"},{"path":"/reference/outlier_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate outliers in Data — outlier_table","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. x Variable column number dat check outliers. sd_val Optional. Number standard deviations mean defining  outliers. example, sd_val = 4 mean values outside +/- 4  SD mean outliers. log_fun Logical, whether log function call (internal use).","code":""},{"path":"/reference/outlier_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate outliers in Data — outlier_table","text":"Table evaluating whether outliers may exist selected data    column.","code":""},{"path":"/reference/outlier_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate outliers in Data — outlier_table","text":"Returns table summary statistics (mean, median, standard   deviation, minimum, maximum, number NAs, skew data)   x values outside outlier measure removed.   Outlier measures include 5-95% quantiles, 25-75% quantiles, mean +/-2SD,   mean +/-3SD, median +/-2SD, median +/-3SD. one variable can   checked time. Table saved Output folder.","code":""},{"path":"/reference/outlier_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate outliers in Data — outlier_table","text":"","code":"if (FALSE) { outlier_table(pollockMainDataTable, 'pollock', x = 'HAUL') }"},{"path":"/reference/parseDeleteEvent.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracts the row id number from the id string — parseDeleteEvent","title":"Extracts the row id number from the id string — parseDeleteEvent","text":"Extracts row id number id string","code":""},{"path":"/reference/parseDeleteEvent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracts the row id number from the id string — parseDeleteEvent","text":"","code":"parseDeleteEvent(idstr)"},{"path":"/reference/parseDeleteEvent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracts the row id number from the id string — parseDeleteEvent","text":"idstr id string formated id_INDEX","code":""},{"path":"/reference/parseDeleteEvent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracts the row id number from the id string — parseDeleteEvent","text":"INDEX id string id_INDEX","code":""},{"path":"/reference/parse_data_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse data name for logging — parse_data_name","title":"Parse data name for logging — parse_data_name","text":"Parse data name logging","code":""},{"path":"/reference/parse_data_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse data name for logging — parse_data_name","text":"","code":"parse_data_name(dat, type, project)"},{"path":"/reference/parse_data_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse data name for logging — parse_data_name","text":"dat Data table parsed. type String, data type: \"main\", \"aux\", \"grid\", \"port\", \"spat\". project project name.","code":""},{"path":"/reference/parse_data_name.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parse data name for logging — parse_data_name","text":"called shiny app running, data table name pulled    FishSET project settings file. Otherwise, data table caller    environment used.","code":""},{"path":"/reference/parse_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse metadata from a data file — parse_meta","title":"Parse metadata from a data file — parse_meta","text":"General purpose meta parsing function. parse_meta attempts parse file based file extension.","code":""},{"path":"/reference/parse_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse metadata from a data file — parse_meta","text":"","code":"parse_meta(file, ..., simplify_meta = FALSE)"},{"path":"/reference/parse_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse metadata from a data file — parse_meta","text":"file String, file path. ... Additional arguments passed parsing function based file extension. See . simplify_meta Logical, attempt simplify metadata output. uses simplify_list. can useful metadata  tabular.","code":""},{"path":"/reference/parse_meta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parse metadata from a data file — parse_meta","text":"Function supports xls, xlsx, csv, tsv, excel, json, xlm extensions. #' Extension-specific notes: txt:   sep Field separator character. defaults comment = \"#\".  comment comment character used separate (\"comment-\")    metadata data. text commented-read. d_list Logical, metadata stored description list (.e. Field: value, value   format). colon (\":\") used field name set TRUE. xls, xlsx:     range cell range read (e.g. \"A1:C5\"). See    read_excel details.","code":""},{"path":[]},{"path":"/reference/parse_meta_delim.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse metadata from a delimited file — parse_meta_delim","title":"Parse metadata from a delimited file — parse_meta_delim","text":"Use function metadata located file data  data stored delimited file (csv, tsv).","code":""},{"path":"/reference/parse_meta_delim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse metadata from a delimited file — parse_meta_delim","text":"","code":"parse_meta_delim(file, sep = NULL, comment = \"#\", is_list = FALSE, ...)"},{"path":"/reference/parse_meta_delim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse metadata from a delimited file — parse_meta_delim","text":"file String, file path metadata. sep String, field separator character. defaults comment = \"#\". comment String, comment character used separate (\"comment-\")  metadata data. text commented-read. is_list Logical, metadata stored list (.e. Field: value, Field: value) format). colon (\":\") used field name set TRUE. ... Additional arguments passed read.delim.","code":""},{"path":"/reference/parse_meta_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse metadata from an excel file — parse_meta_excel","title":"Parse metadata from an excel file — parse_meta_excel","text":"Use function metadata located file data. Correct specification range parameter key.","code":""},{"path":"/reference/parse_meta_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse metadata from an excel file — parse_meta_excel","text":"","code":"parse_meta_excel(file, range = NULL, ...)"},{"path":"/reference/parse_meta_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse metadata from an excel file — parse_meta_excel","text":"file String, file path. range String, cell range read (e.g. \"A1:C5\"). See  read_excel details. ... Additional arguments passed read_excel.","code":""},{"path":"/reference/parse_meta_json.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse metadata from json file — parse_meta_json","title":"Parse metadata from json file — parse_meta_json","text":"Use function metadata located file data  data stored JSON file.","code":""},{"path":"/reference/parse_meta_json.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse metadata from json file — parse_meta_json","text":"","code":"parse_meta_json(file, meta_ind = NULL, simplifyVector = TRUE, flatten = FALSE)"},{"path":"/reference/parse_meta_json.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse metadata from json file — parse_meta_json","text":"file String, file path. meta_ind Integer string. simplifyVector Logical, simplifies nested lists vectors  data frames. flatten Automatically flatten mested data frames single  non-nested data frame. See fromJSON.","code":""},{"path":"/reference/parse_meta_xml.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse metadata from xml file — parse_meta_xml","title":"Parse metadata from xml file — parse_meta_xml","text":"Use function metadata located file data  data stored xml file.","code":""},{"path":"/reference/parse_meta_xml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse metadata from xml file — parse_meta_xml","text":"","code":"parse_meta_xml(file, meta_ind = NULL)"},{"path":"/reference/parse_meta_xml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse metadata from xml file — parse_meta_xml","text":"file String, file path. meta_ind Integer string.","code":""},{"path":"/reference/parse_notes.html","id":null,"dir":"Reference","previous_headings":"","what":"Selectively display a note section — parse_notes","title":"Selectively display a note section — parse_notes","text":"Selectively display note section","code":""},{"path":"/reference/parse_notes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Selectively display a note section — parse_notes","text":"","code":"parse_notes(project, date = NULL, section, output = \"print\")"},{"path":"/reference/parse_notes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Selectively display a note section — parse_notes","text":"project project name. date Date pull notes . NULL recent version notes project retrieved. section note section display. Options include \"upload\" Upload data, \"quality\" Data quality evaluation, \"explore\" Data exploration, \"fleet\" Fleet functions, \"analysis\" Simple analysis, \"new_variable\" Create new variable, \"alt_choice\" Alternative choice, \"models\", \"bookmark\". output Output type. \"print\" returns formatted notes. \"string\" returns  character vector notes. \"print\" recommended displaying notes report.","code":""},{"path":"/reference/parse_notes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Selectively display a note section — parse_notes","text":"","code":"if (FALSE) { parse_notes(\"pollock\", type = \"explore\") }"},{"path":"/reference/perc_of_total.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate grouped percentages — perc_of_total","title":"Calculate grouped percentages — perc_of_total","text":"Calculate grouped percentages","code":""},{"path":"/reference/perc_of_total.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate grouped percentages — perc_of_total","text":"","code":"perc_of_total(   dat,   value_var,   group = NULL,   drop = FALSE,   val_type = \"perc\",   output = \"dataset\" )"},{"path":"/reference/perc_of_total.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate grouped percentages — perc_of_total","text":"dat Data table summarize. value_var String, variable name(s) calculating total. group String, grouping variable(s) group `value_var` . drop Logical, whether drop total column. val_type String, whether convert value output percentage  \"perc\" proportion \"prop\". output String, whether add new variables dataset (\"dataset\") return summary table (\"summary\")","code":""},{"path":"/reference/period_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for valid period — period_check","title":"Check for valid period — period_check","text":"Check valid period","code":""},{"path":"/reference/period_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for valid period — period_check","text":"","code":"period_check(period, date)"},{"path":"/reference/period_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for valid period — period_check","text":"period String, name period create. used fleet functions summarize data period. date String, name date variable used create period variable.","code":""},{"path":"/reference/period_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for valid period — period_check","text":"period code used format date. Assign output variable   used inside function.","code":""},{"path":"/reference/plot_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Import and format plots to notebook file — plot_format","title":"Import and format plots to notebook file — plot_format","text":"Import format plots notebook file","code":""},{"path":"/reference/plot_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import and format plots to notebook file — plot_format","text":"","code":"plot_format(x, project)"},{"path":"/reference/plot_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import and format plots to notebook file — plot_format","text":"x Name plot saved output project Name project","code":""},{"path":"/reference/plot_format.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import and format plots to notebook file — plot_format","text":"","code":"if (FALSE) { plot_format(\"pollock_species_catch_2020-05-29.png\") plot_format(pull_output(\"pollock\", \"species_catch\", type = \"plot\")) }"},{"path":"/reference/plot_spat.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot spatial dataset — plot_spat","title":"Plot spatial dataset — plot_spat","text":"Simple plotting function viewing spatial data.","code":""},{"path":"/reference/plot_spat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot spatial dataset — plot_spat","text":"","code":"plot_spat(spat)"},{"path":"/reference/plot_spat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot spatial dataset — plot_spat","text":"spat Spatial dataset view. Must object class sf  sfc.","code":""},{"path":"/reference/plot_spat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot spatial dataset — plot_spat","text":"","code":"if (FALSE) { plot_spat(pollockNMFSSpatTable) }"},{"path":"/reference/policy_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Policy change metrics — policy_metrics","title":"Policy change metrics — policy_metrics","text":"Policy change metrics","code":""},{"path":"/reference/policy_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Policy change metrics — policy_metrics","text":"","code":"policy_metrics(   dat,   project,   tripID = \"row\",   vesselID,   catchID,   datevar = NULL,   price = NULL )"},{"path":"/reference/policy_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Policy change metrics — policy_metrics","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Name project tripID Trip identifier. Can 'row' name names variables define trips.  tripID='row' row  primary dataset considered unique trip vesselID Vessel identifier. Variable name primary dataset contains unique vessel identifier. catchID Name variable primary dataset contains catch data. datevar Name variable containing date data. Used split data years. price Name variable containing data revenue price data.","code":""},{"path":"/reference/policy_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Policy change metrics — policy_metrics","text":"Tables containing basic metrics effects proposed zone closures.","code":""},{"path":"/reference/policy_metrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Policy change metrics — policy_metrics","text":"policy change metrics reflect impact proposed policies absence changes fisher behavior.     Policy scenarios defined using zone_closure() function.      Percent vessels calculated unique vessel identifiers grouped year zone. Trips identified using      tripID argument, otherwise row assumed trip. price defined percent revenue loss      reported NA.","code":""},{"path":"/reference/polyval.html","id":null,"dir":"Reference","previous_headings":"","what":"polyval — polyval","title":"polyval — polyval","text":"polyval","code":""},{"path":"/reference/polyval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"polyval — polyval","text":"","code":"polyval(coef, z)"},{"path":"/reference/polyval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"polyval — polyval","text":"coef coeffient z numeric","code":""},{"path":"/reference/predict_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Map of predicted probabilities — predict_map","title":"Map of predicted probabilities — predict_map","text":"Create map showing predicted probabilities zone","code":""},{"path":"/reference/predict_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map of predicted probabilities — predict_map","text":"","code":"predict_map(   project,   mod.name = NULL,   policy.name = NULL,   spat,   zone.spat,   outsample = FALSE,   outsample_pred = NULL )"},{"path":"/reference/predict_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map of predicted probabilities — predict_map","text":"project Name project mod.name Name model policy.name Name policy scenario spat spatial data file containing information fishery management  regulatory zones boundaries. `sf` objects recommended, `sp` objects  can used well. See [dat_to_sf()] convert spatial table read  csv file `sf` object. upload spatial data FishSETFolder  see [load_spatial()]. zone.spat Name zone ID column `spat`. outsample Logical, indicating predict_map() used creating map --sample predicted fishing probabilities outsample = TRUE policy scenario outsample = FALSE. outsample_pred dataframe fishing location predicted probabilities --sample data. outsample_pred = NULL default plotting policy scenarios.","code":""},{"path":"/reference/predict_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map of predicted probabilities — predict_map","text":"map showing predicted probabilities","code":""},{"path":"/reference/predict_map.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Map of predicted probabilities — predict_map","text":"function requires model prediction output tables exist FishSET database  plotting policy scenario maps.","code":""},{"path":"/reference/predict_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map of predicted probabilities — predict_map","text":"","code":"if (FALSE) {  predict_map(project = \"scallop\", policy.name = \"logit_c_mod1 closure_1\",              spat = spat, zone.spat = \"TEN_ID\")  }"},{"path":"/reference/predict_outsample.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict out-of-sample data — predict_outsample","title":"Predict out-of-sample data — predict_outsample","text":"Calculate predicted probabilities --sample dataset","code":""},{"path":"/reference/predict_outsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict out-of-sample data — predict_outsample","text":"","code":"predict_outsample(   project,   mod.name,   outsample.mod.name,   use.scalers = FALSE,   scaler.func = NULL )"},{"path":"/reference/predict_outsample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict out-of-sample data — predict_outsample","text":"project Name project mod.name Name saved model use. Argument can name model can pull name  saved \"best\" model. Leave mod.name empty use saved \"best\" model. one model saved, mod.name numeric indicator model use. Use table_view(\"modelChosen\", project) view table saved models. outsample.mod.name Name saved --sample model design. use.scalers Input create_model_input(). Logical, data normalized? Defaults FALSE. Rescaling factors mean  numeric vector unless specified scaler.func. scaler.func Input create_model_input(). Function calculate rescaling factors.","code":""},{"path":"/reference/predict_outsample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict out-of-sample data — predict_outsample","text":"function predicts --sample fishing probabilities calculates model prediction performance (percent absolute prediction error).","code":""},{"path":"/reference/predict_outsample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict out-of-sample data — predict_outsample","text":"","code":"if (FALSE) {  predict_outsample(\"scallop1\", \"logit_c_mod1\", \"logit_c_mod1_outsample\")  }"},{"path":"/reference/predict_probability.html","id":null,"dir":"Reference","previous_headings":"","what":"Subfunction of model_prediction for summing predictions with closures — predict_probability","title":"Subfunction of model_prediction for summing predictions with closures — predict_probability","text":"Subfunction model_prediction summing predictions closures","code":""},{"path":"/reference/predict_probability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subfunction of model_prediction for summing predictions with closures — predict_probability","text":"","code":"predict_probability(   probLogit,   probDataModelIn,   probDataModelOut,   zoneClose,   tacAllowed,   zoneClosedFish )"},{"path":"/reference/predict_probability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subfunction of model_prediction for summing predictions with closures — predict_probability","text":"probLogit Parameter estimates probDataModelIn Parameter estimates closed zones probDataModelOut Parameter estiumates open zones zoneClose Sum probabilitys 0 fishing allowed tacAllowed Decimal (percent) TAC allowed zoneClosedFish Index zones closed fishing","code":""},{"path":"/reference/predict_probability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subfunction of model_prediction for summing predictions with closures — predict_probability","text":"List   probPredict: Prediction location fishing   sumPredctIn: Total probablilty fishing inside closers   sumPredictOut: Total probablitily fishing outside closures","code":""},{"path":"/reference/pred_prob_outputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize predicted probabilities — pred_prob_outputs","title":"Summarize predicted probabilities — pred_prob_outputs","text":"Create summary table figures predicted probabilities fishing per zone model policy scenario.  table figures include base case scenario, proportion observations zone. table also includes squared error predicted probabilities base case probabilities. first figure option displays predicted probabilities model, second figure option shows predicted probabilities model policy.","code":""},{"path":"/reference/pred_prob_outputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize predicted probabilities — pred_prob_outputs","text":"","code":"pred_prob_outputs(project, mod.name = NULL, output_option = \"table\")"},{"path":"/reference/pred_prob_outputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize predicted probabilities — pred_prob_outputs","text":"project Name project mod.name Name model output_option \"table\" return summary table (default); \"model_fig\" predicted probabilities; \"policy_fig\"  return predicted probabilities model/policy scenario.","code":""},{"path":"/reference/pred_prob_outputs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize predicted probabilities — pred_prob_outputs","text":"model prediction summary table (default), model prediction figure, policy prediction figure. See output_option argument.","code":""},{"path":"/reference/pred_prob_outputs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize predicted probabilities — pred_prob_outputs","text":"function requires model prediction output tables exist FishSET database. tables  present database function terminate return error message.","code":""},{"path":"/reference/pred_prob_outputs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize predicted probabilities — pred_prob_outputs","text":"","code":"if (FALSE) {  pred_prob_outputs(project = \"scallop\")  }"},{"path":"/reference/pretty_lab.html","id":null,"dir":"Reference","previous_headings":"","what":"Format numbers in table — pretty_lab","title":"Format numbers in table — pretty_lab","text":"Format numeric columns.","code":""},{"path":"/reference/pretty_lab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format numbers in table — pretty_lab","text":"","code":"pretty_lab(tab, cols = \"all\", type = \"pretty\", ignore = NULL)"},{"path":"/reference/pretty_lab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format numbers in table — pretty_lab","text":"tab Table format. cols Character string columns format. defaults \"\" include numeric variables tab. ignore = TRUE columns listed cols formatted  columns tab formatted. type type formatting apply. \"pretty\" uses  prettyNum uses commas (\",\") mark big intervals. \"scientific\" uses scientific notation. \"decimal\" simply rounds two decimal places. ignore Logical, whether exclude columns listed cols apply formatting columns tab.","code":""},{"path":"/reference/pretty_tab.html","id":null,"dir":"Reference","previous_headings":"","what":"Format table for R Markdown — pretty_tab","title":"Format table for R Markdown — pretty_tab","text":"Format table R Markdown","code":""},{"path":"/reference/pretty_tab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format table for R Markdown — pretty_tab","text":"","code":"pretty_tab(tab, full_width = FALSE)"},{"path":"/reference/pretty_tab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format table for R Markdown — pretty_tab","text":"tab Table format. full_width Logical, whether table fill entire width  page.","code":""},{"path":"/reference/pretty_tab_sb.html","id":null,"dir":"Reference","previous_headings":"","what":"Scroll box for R Markdown table — pretty_tab_sb","title":"Scroll box for R Markdown table — pretty_tab_sb","text":"Allows tables become scrollable. Useful large tables.","code":""},{"path":"/reference/pretty_tab_sb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scroll box for R Markdown table — pretty_tab_sb","text":"","code":"pretty_tab_sb(tab, width = \"100%\", height = \"500px\", full_width = FALSE)"},{"path":"/reference/pretty_tab_sb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scroll box for R Markdown table — pretty_tab_sb","text":"tab Table format. width character string indicating width box. Can pixels (e.g. \"50px\") percentage (e.g. \"50%\"). height character string indicating height box. Can pixels (e.g. \"50px\") percentage (e.g. \"50%\"). full_width Logical, whether table fill entire width  page.","code":""},{"path":"/reference/previous_loc.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Previous Location/Area Variable — previous_loc","title":"Create Previous Location/Area Variable — previous_loc","text":"Creates variable previous port/zone (previous area) previous longitude/latitude vessel.","code":""},{"path":"/reference/previous_loc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Previous Location/Area Variable — previous_loc","text":"","code":"previous_loc(   dat,   spat,   project,   starting_port,   v_id,   tripID,   haulID,   zoneID = NULL,   spatID = NULL,   date = NULL,   lon = NULL,   lat = NULL )"},{"path":"/reference/previous_loc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Previous Location/Area Variable — previous_loc","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. spat spatial data file containing information fishery management regulatory zones boundaries. sf objects recommended, sp objects can used well. See dat_to_sf() convert spatial table read csv file sf object. upload spatial data FishSETFolder see load_spatial(). project String, name project. starting_port name starting (disembarking) port dat. v_id name variable dat uniquely identifies vessels. tripID Variable name dat uniquely identifies trips. haulID Variable name dat uniquely identifies hauls. zoneID Name zone ID column dat. Used identify previous area. Required previous area variable. spatID Name zone ID column spat. spat used assign ports spatial areas. Required previous area variable. date Optional, date variable order hauls . lon Longitude variable dat. Required previous location variable. lat Latitude variable dat. Required previous location variable.","code":""},{"path":"/reference/previous_loc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Previous Location/Area Variable — previous_loc","text":"previous_loc() can create previous area location variable. \"Previous area\" defined port zone vessel last visited. first area trip disembarking port (starting_port). port within zone, zone returned. port within zone, name port returned. \"Previous location\" defined previous longitude latitude vessel. first set coordinates location port. Users must port table saved FishSET database use function (see load_port()). variable can used define distance matrix (see create_alternative_choice()).","code":""},{"path":"/reference/projects.html","id":null,"dir":"Reference","previous_headings":"","what":"Display projects names — projects","title":"Display projects names — projects","text":"Display projects names","code":""},{"path":"/reference/projects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display projects names — projects","text":"","code":"projects()"},{"path":"/reference/projects.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Display projects names — projects","text":"Lists unique project names currently FishSET Database.","code":""},{"path":"/reference/projects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display projects names — projects","text":"","code":"if (FALSE) { projects() }"},{"path":"/reference/project_exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if project exists — project_exists","title":"Check if project exists — project_exists","text":"Check project exists","code":""},{"path":"/reference/project_exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if project exists — project_exists","text":"","code":"project_exists(project)"},{"path":"/reference/project_exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if project exists — project_exists","text":"project Project name.","code":""},{"path":"/reference/project_files.html","id":null,"dir":"Reference","previous_headings":"","what":"List output files by project name — project_files","title":"List output files by project name — project_files","text":"List output files project name","code":""},{"path":"/reference/project_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List output files by project name — project_files","text":"","code":"project_files(project)"},{"path":"/reference/project_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List output files by project name — project_files","text":"project Project name","code":""},{"path":"/reference/project_files.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List output files by project name — project_files","text":"","code":"if (FALSE) { project_files(\"pollock\") }"},{"path":"/reference/project_logs.html","id":null,"dir":"Reference","previous_headings":"","what":"List logs by project — project_logs","title":"List logs by project — project_logs","text":"List logs project","code":""},{"path":"/reference/project_logs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List logs by project — project_logs","text":"","code":"project_logs(project, modified = FALSE)"},{"path":"/reference/project_logs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List logs by project — project_logs","text":"project Name project. modified Logical, whether show modification date. Returns data frame.","code":""},{"path":"/reference/project_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Display database table names by project — project_tables","title":"Display database table names by project — project_tables","text":"Display database table names project","code":""},{"path":"/reference/project_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display database table names by project — project_tables","text":"","code":"project_tables(project, ...)"},{"path":"/reference/project_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display database table names by project — project_tables","text":"project Name project. ... String, additional characters match .","code":""},{"path":[]},{"path":"/reference/project_tables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display database table names by project — project_tables","text":"","code":"if (FALSE) { project_tables(\"pollock\") project_tables(\"pollock\", \"main\") }"},{"path":"/reference/proj_settings_exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if option file exists for a project — proj_settings_exists","title":"Check if option file exists for a project — proj_settings_exists","text":"Check option file exists project","code":""},{"path":"/reference/proj_settings_exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if option file exists for a project — proj_settings_exists","text":"","code":"proj_settings_exists(project)"},{"path":"/reference/proj_settings_exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if option file exists for a project — proj_settings_exists","text":"project Project name.","code":""},{"path":"/reference/proj_settings_exists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if option file exists for a project — proj_settings_exists","text":"TRUE project options file exists, FALSE .","code":""},{"path":"/reference/pull_log.html","id":null,"dir":"Reference","previous_headings":"","what":"pull log file — pull_log","title":"pull log file — pull_log","text":"pull log file","code":""},{"path":"/reference/pull_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pull log file — pull_log","text":"","code":"pull_log(project, log_date = NULL)"},{"path":"/reference/pull_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pull log file — pull_log","text":"project Project name. log_date Date log pulled. NULL, recent  log file retrieved.","code":""},{"path":"/reference/pull_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve/display meta data by project — pull_meta","title":"Retrieve/display meta data by project — pull_meta","text":"Retrieve/display meta data project","code":""},{"path":"/reference/pull_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve/display meta data by project — pull_meta","text":"","code":"pull_meta(project, tab.name = NULL, tab.type = NULL, format = FALSE)"},{"path":"/reference/pull_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve/display meta data by project — pull_meta","text":"project Project name. tab.name String, table name. Optional, used filter output specific table. tab.type String, table type. Optional, used filter output. Options  include \"main\", \"spat\" (spatial), \"port\", \"grid\" (gridded), \"aux\" (auxiliary). format Logical, whether format output using pander. Useful displaying reports.","code":""},{"path":"/reference/pull_notes.html","id":null,"dir":"Reference","previous_headings":"","what":"Pull notes from output folder — pull_notes","title":"Pull notes from output folder — pull_notes","text":"Pull notes output folder","code":""},{"path":"/reference/pull_notes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pull notes from output folder — pull_notes","text":"","code":"pull_notes(project, date = NULL, output = \"print\")"},{"path":"/reference/pull_notes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pull notes from output folder — pull_notes","text":"project String, project name. date String, date pull notes . NULL, recent note file  retrieved. output Output type. \"print\" returns formatted notes. \"string\" returns  character vector notes. \"print\" recommended displaying notes report.","code":""},{"path":"/reference/pull_notes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pull notes from output folder — pull_notes","text":"Notes saved output folder project name date. date   specified recent notes file project name pulled. Notes   also saved FishSET app session; one session occurred day,    session's notes pulled listed chronological order.","code":""},{"path":"/reference/pull_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve output file name by project, function, and type — pull_output","title":"Retrieve output file name by project, function, and type — pull_output","text":"Retrieve output file name project, function, type","code":""},{"path":"/reference/pull_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve output file name by project, function, and type — pull_output","text":"","code":"pull_output(project, fun = NULL, date = NULL, type = \"plot\", conf = TRUE)"},{"path":"/reference/pull_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve output file name by project, function, and type — pull_output","text":"project Name project fun Name function. date Output file date \" recent output file pulled. type Whether return \"plot\" (.png), \"table\" (.csv), \"notes\" (.txt) \"\" files matching project name, function,  date. conf Logical, whether return suppressed confidential data.  Unsuppressed output pulled suppressed output available.","code":""},{"path":"/reference/pull_output.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve output file name by project, function, and type — pull_output","text":"","code":"if (FALSE) { pull_output(\"pollock\", \"species_catch\", type = \"plot\") }"},{"path":"/reference/pull_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Import and format plots to notebook file — pull_plot","title":"Import and format plots to notebook file — pull_plot","text":"Import format plots notebook file","code":""},{"path":"/reference/pull_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import and format plots to notebook file — pull_plot","text":"","code":"pull_plot(project, fun, date = NULL, conf = TRUE)"},{"path":"/reference/pull_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import and format plots to notebook file — pull_plot","text":"project Project name. fun String, name function created plot. date date plot created. NULL, recent  version retrieved. conf Logical, whether return suppressed confidential data.  Unsuppressed output pulled suppressed output available.","code":""},{"path":"/reference/pull_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import and format plots to notebook file — pull_plot","text":"","code":"if (FALSE) { pull_plot(\"pollock\", \"density_plot\") }"},{"path":"/reference/pull_shiny_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve output file name by project, function, and type — pull_shiny_output","title":"Retrieve output file name by project, function, and type — pull_shiny_output","text":"Retrieve output file name project, function, type","code":""},{"path":"/reference/pull_shiny_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve output file name by project, function, and type — pull_shiny_output","text":"","code":"pull_shiny_output(project, fun = NULL, type = \"plot\", conf = TRUE)"},{"path":"/reference/pull_shiny_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve output file name by project, function, and type — pull_shiny_output","text":"project Name project fun Name function. type Whether return \"plot\" (.png), \"table\" (.csv), \"notes\" (.txt) \"\" files matching project name, function, date. conf Logical, whether return suppressed confidential data.  Unsuppressed output pulled suppressed output available.","code":""},{"path":"/reference/pull_shiny_output.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve output file name by project, function, and type — pull_shiny_output","text":"","code":"if (FALSE) { pull_output(\"pollock\", \"species_catch\", type = \"plot\") }"},{"path":"/reference/pull_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Import and format table to notebook file — pull_table","title":"Import and format table to notebook file — pull_table","text":"Import format table notebook file","code":""},{"path":"/reference/pull_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import and format table to notebook file — pull_table","text":"","code":"pull_table(project, fun, date = NULL, conf = TRUE)"},{"path":"/reference/pull_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import and format table to notebook file — pull_table","text":"project Project name. fun String, name function created table. date date table created. NULL, recent  version retrieved. conf Logical, whether return suppressed confidential data.  Unsuppressed output pulled suppressed output available.","code":""},{"path":"/reference/pull_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import and format table to notebook file — pull_table","text":"","code":"if (FALSE) { pull_table(\"pollock\", \"vessel_count\") }"},{"path":"/reference/qaqc_helper.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for testing data quality issues in MainDataTable — qaqc_helper","title":"Helper function for testing data quality issues in MainDataTable — qaqc_helper","text":"Helper function testing data quality issues MainDataTable","code":""},{"path":"/reference/qaqc_helper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for testing data quality issues in MainDataTable — qaqc_helper","text":"","code":"qaqc_helper(dat, fun, output = \"logical\")"},{"path":"/reference/qaqc_helper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function for testing data quality issues in MainDataTable — qaqc_helper","text":"dat Dataframe test quality issues. fun function custom function returns single logical value  apply column dat. three quick options  common checks: \"NA\", \"NaN\", \"Inf\". output \"logical\" returns single logical value column dat. \"names\" returns column names evaluate TRUE.","code":""},{"path":"/reference/qaqc_helper.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Helper function for testing data quality issues in MainDataTable — qaqc_helper","text":"Returns vector logical values (output = \"logical\") vector    column names condition evaluated fun returns TRUE    (output = \"names\").","code":""},{"path":[]},{"path":"/reference/quietly_test.html","id":null,"dir":"Reference","previous_headings":"","what":"quietly_test capture console messages if exist and print to shiny app — quietly_test","title":"quietly_test capture console messages if exist and print to shiny app — quietly_test","text":"quietly_test capture console messages exist print shiny app","code":""},{"path":"/reference/quietly_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"quietly_test capture console messages if exist and print to shiny app — quietly_test","text":"","code":"quietly_test(.f, show_msg = FALSE)"},{"path":"/reference/quietly_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"quietly_test capture console messages if exist and print to shiny app — quietly_test","text":".f function name show_msg Logical, whether show messages shiny app.","code":""},{"path":"/reference/quiet_safe_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Quietly and safely test function — quiet_safe_test","title":"Quietly and safely test function — quiet_safe_test","text":"Used package functions: safely catches errors quietly catches warnings messages. capture results.","code":""},{"path":"/reference/quiet_safe_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quietly and safely test function — quiet_safe_test","text":"","code":"quiet_safe_test(.f)"},{"path":"/reference/quiet_safe_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quietly and safely test function — quiet_safe_test","text":".f Name function quietly safely test.","code":""},{"path":[]},{"path":"/reference/randomize_lonlat_zone.html","id":null,"dir":"Reference","previous_headings":"","what":"Randomize latitude and longitude points by zone — randomize_lonlat_zone","title":"Randomize latitude and longitude points by zone — randomize_lonlat_zone","text":"Randomize latitude longitude points zone","code":""},{"path":"/reference/randomize_lonlat_zone.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randomize latitude and longitude points by zone — randomize_lonlat_zone","text":"","code":"randomize_lonlat_zone(dat, project, spat, lon, lat, zone)"},{"path":"/reference/randomize_lonlat_zone.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randomize latitude and longitude points by zone — randomize_lonlat_zone","text":"dat Main data frame apply function. Table FishSET  database contain string `MainDataTable`. project Project name. spat Spatial data table containing regulatory zones. can  \"spatial feature\" sf object. lon String, variable name containing longitude. lat String, variable name containing latitude. zone String, column name contain assigned zone. Must  spatial data table MainDataTable.","code":""},{"path":"/reference/randomize_lonlat_zone.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Randomize latitude and longitude points by zone — randomize_lonlat_zone","text":"one FishSET confidentiality functions. replaces    longitude latitude values randomly sampled coordinates   regulatory zone observation occurred .","code":""},{"path":"/reference/randomize_lonlat_zone.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Randomize latitude and longitude points by zone — randomize_lonlat_zone","text":"","code":"if (FALSE) { randomize_lonlat_zone(pollockMainDataTable, \"pollock\", spatdat,                     lon = \"LonLat_START_LON\", lat = \"LonLat_START_LAT\",                    zone = \"NMFS_AREA\") }"},{"path":"/reference/randomize_value_range.html","id":null,"dir":"Reference","previous_headings":"","what":"Randomize variable value by percentage range — randomize_value_range","title":"Randomize variable value by percentage range — randomize_value_range","text":"Randomize variable value percentage range","code":""},{"path":"/reference/randomize_value_range.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randomize variable value by percentage range — randomize_value_range","text":"","code":"randomize_value_range(dat, project, value, perc = NULL)"},{"path":"/reference/randomize_value_range.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randomize variable value by percentage range — randomize_value_range","text":"dat Main data frame apply function. Table FishSET  database contain string `MainDataTable`. project Project name. value String, name variable jitter. perc Numeric, vector percentages randomly adjust column values .  Defaults range 0.05 - 0.15 (.e. 5-15 percent original value).","code":""},{"path":"/reference/randomize_value_range.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Randomize variable value by percentage range — randomize_value_range","text":"one FishSET confidentiality functions. adjusts    value adding substracting (chosen random value) percentage value. percentage   randomly sampled range percentages provided \"perc\" argument.","code":""},{"path":"/reference/randomize_value_range.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Randomize variable value by percentage range — randomize_value_range","text":"","code":"if (FALSE) { randomize_value_range(pollockMainDataTable, \"pollock\", \"LBS_270_POLLOCK_LBS\") }"},{"path":"/reference/randomize_value_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Randomize value between rows — randomize_value_row","title":"Randomize value between rows — randomize_value_row","text":"Randomize value rows","code":""},{"path":"/reference/randomize_value_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randomize value between rows — randomize_value_row","text":"","code":"randomize_value_row(dat, project, value)"},{"path":"/reference/randomize_value_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randomize value between rows — randomize_value_row","text":"dat Main data frame apply function. Table FishSET  database contain string `MainDataTable`. project Project name. value String, variable name randomly distributed rows.","code":""},{"path":"/reference/randomize_value_row.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Randomize value between rows — randomize_value_row","text":"one FishSET confidentiality functions. useful   randomly assigning ID values observations.","code":""},{"path":"/reference/randomize_value_row.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Randomize value between rows — randomize_value_row","text":"","code":"if (FALSE) { randomize_value_row(pollockMainDataTable, \"pollock\", \"PERMIT\") }"},{"path":"/reference/read_dat.html","id":null,"dir":"Reference","previous_headings":"","what":"Import data from local file directory or webpage into the R environment — read_dat","title":"Import data from local file directory or webpage into the R environment — read_dat","text":"Import data local file directory webpage R environment","code":""},{"path":"/reference/read_dat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import data from local file directory or webpage into the R environment — read_dat","text":"","code":"read_dat(   x,   data.type = NULL,   is.map = FALSE,   drv = NULL,   dbname = NULL,   user = NULL,   password = NULL,   ... )"},{"path":"/reference/read_dat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import data from local file directory or webpage into the R environment — read_dat","text":"x Name path dataset read . load data directly  webpage, x web address. data.type Optional. Data type can defined user based  file extension. undefined, data.type string  last period equal sign. data.type must defined x  path shape folder, file Google spreadsheet use  data.type = 'google', correct extension derived  x. R, comma-delimited, tab-delimited, excel, Matlab, json,  geojson, sas, spss, stata, html, XML data extensions  specified. .map logical, .json file extension, set .map = TRUE  data spatial file. Spatial files ending .json read  properly unless .map = TRUE. drv Use sql files. Database driver. dbname Use sql files. required, database name. user Use sql files.  required, user name SQL database. password Use sql files. required, SQL database password. ... Optional arguments","code":""},{"path":"/reference/read_dat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import data from local file directory or webpage into the R environment — read_dat","text":"Uses appropriate function read data based data type.   Use write_dat save data data folder    project directory. Supported data types include shape, csv,    json, matlab, R, spss, stata files. Use data.type = 'shape'    x path shape folder. Use data.type = 'google'    file Google spreadsheet. sql files, use data.type = 'sql'. function connect    specified DBI pull table. Users must specify DBI driver    (drv), example: RSQLite::SQLite(),    RPostgreSQL::PostgreSQL(), odbc::odbc(). arguments    may required, including database name (dbname), user id    (user), password (password). Additional arguments can added, skip lines skip = 2    header header = FALSE. specify separator argument    delimited file, include tab-delimited, specify data.type = 'delim'. details, see load loading R objects,    read_csv reading comma separated value files,   read_tsv reading tab separated value files,   read_delim reading delimited files,   read_excel reading excel files (xls, xlsx),    st_read reading geojson , GeoPackage files,    shape files, readMat reading matlab data files,   read_dta reading stata data files,   read_spss reading spss data files,   read_sas reading sas data files,    fromJSON reading json files.   read_xml reading XML files. processing    may required. read_html reading html tables.   See read_sheet range_read    reading google spreadsheets. Google spreadsheets require data.type    specified. Use data.type = 'google'. read_ods    reading open document spreadsheets.","code":""},{"path":"/reference/read_dat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import data from local file directory or webpage into the R environment — read_dat","text":"","code":"if (FALSE) { # Read in shape file dat <- read_dat('C:/data/nmfs_manage_simple', data.type = 'shape')  # Read in spatial data file in json format dat <- read_dat('C:/data/nmfs_manage_simple.json', is.map = TRUE)  # read in data directly from web page dat <- read_dat(\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/test.txt\",                  data.type = 'delim', sep = '', header = FALSE) }"},{"path":"/reference/recast_multipoly.html","id":null,"dir":"Reference","previous_headings":"","what":"Recast multi-polygons — recast_multipoly","title":"Recast multi-polygons — recast_multipoly","text":"Re-cast intersecting multi-polygons polygons. Used combining  regulatory zones closure areas.","code":""},{"path":"/reference/recast_multipoly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recast multi-polygons — recast_multipoly","text":"","code":"recast_multipoly(grid, closure, combined, id, inter)"},{"path":"/reference/recast_multipoly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recast multi-polygons — recast_multipoly","text":"grid Grid file containing regulatory zones. closure Closure file containing closure areas. combined Combined version grid closure file. id Character, name zone ID column.","code":""},{"path":"/reference/recast_multipoly.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Recast multi-polygons — recast_multipoly","text":"function primarily used extract polygons    ID re-labeling process performed new_zone_id.   polygon grid intersected closure, extracted   multi-polygon given unique ID.","code":""},{"path":[]},{"path":"/reference/remove_model_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove a model design from list in ModelInputData table — remove_model_design","title":"Remove a model design from list in ModelInputData table — remove_model_design","text":"Remove model design list ModelInputData table","code":""},{"path":"/reference/remove_model_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove a model design from list in ModelInputData table — remove_model_design","text":"","code":"remove_model_design(project, names)"},{"path":"/reference/remove_model_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove a model design from list in ModelInputData table — remove_model_design","text":"project Name project. names Names model designs deleted table","code":""},{"path":"/reference/replace_sup_code.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace suppression code — replace_sup_code","title":"Replace suppression code — replace_sup_code","text":"function replaces default suppression code table.","code":""},{"path":"/reference/replace_sup_code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace suppression code — replace_sup_code","text":"","code":"replace_sup_code(output, code = NA)"},{"path":"/reference/replace_sup_code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace suppression code — replace_sup_code","text":"output Table containing suppressed values. code replacement suppression code. code = NA default;  ideal plotting ggplot automatically removes NAs.","code":""},{"path":"/reference/replace_sup_code.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Replace suppression code — replace_sup_code","text":"Suppressed values represented `-999` default. ideal  plotting. NAs -- default `replace_sup_code()`-- better  alternative plots can easily removed.","code":""},{"path":"/reference/replace_sup_code.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replace suppression code — replace_sup_code","text":"","code":"if (FALSE) { summary_tab <- replace_sup_code(summary_tab, code = NA) }"},{"path":"/reference/repmat.html","id":null,"dir":"Reference","previous_headings":"","what":"R verions of matlabs repmat — repmat","title":"R verions of matlabs repmat — repmat","text":"R verions matlabs repmat","code":""},{"path":"/reference/repmat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"R verions of matlabs repmat — repmat","text":"","code":"repmat(X, m, n)"},{"path":"/reference/repmat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"R verions of matlabs repmat — repmat","text":"X matrix m nrows n n cols","code":""},{"path":"/reference/reset_confid_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Reset confidentiality cache tables — reset_confid_cache","title":"Reset confidentiality cache tables — reset_confid_cache","text":"function deletes confidentiality check tables stored  \"confid_cache.json\" file located project output folder.  Resetting cache recommended long period use check  tables can accumulate time.","code":""},{"path":"/reference/reset_confid_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reset confidentiality cache tables — reset_confid_cache","text":"","code":"reset_confid_cache(project)"},{"path":"/reference/reset_confid_cache.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reset confidentiality cache tables — reset_confid_cache","text":"project Project name","code":""},{"path":[]},{"path":"/reference/roll_catch.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply moving average function to catch — roll_catch","title":"Apply moving average function to catch — roll_catch","text":"Apply moving average function catch","code":""},{"path":"/reference/roll_catch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply moving average function to catch — roll_catch","text":"","code":"roll_catch(   dat,   project,   catch,   date,   group = NULL,   combine = FALSE,   k = 10,   fun = \"mean\",   filter_date = NULL,   date_value = NULL,   filter_by = NULL,   filter_value = NULL,   filter_expr = NULL,   facet_by = NULL,   scale = \"fixed\",   align = \"center\",   conv = \"none\",   tran = \"identity\",   format_lab = \"decimal\",   output = \"tab_plot\",   ... )"},{"path":"/reference/roll_catch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply moving average function to catch — roll_catch","text":"dat Main data frame apply function. Table FishSET database contain string `MainDataTable`. project Name project. catch Variable name names containing catch data. Multiple variables can entered vector. date Date variable aggregate . group Variable name names group . Plot display two grouping variables. combine Whether combine variables listed group. passed \"fill\" \"color\" aesthetic plots. k width window. fun function applied window. Defaults mean. filter_date type filter apply table. \"date_range\" option subset  data two date values entered filter_val. options include \"year-day\",  \"year-week\", \"year-month\", \"year\", \"month\", \"week\", \"day\". argument filter_value must  provided. date_value String containing start end date using filter_date = \"date_range\",  e.g. c(\"2011-01-01\", \"2011-03-15\"). filter_date = \"period\" \"year-period\", use integers  (4 digits year, 1-2 day, month, week). Use list using two-part filter, e.g. \"year-week\", format list(year, period) vector using single period, c(period).  example, list(2011:2013, 5:7) filter data table weeks 5 7  years 2011-2013 filter_date = \"year-week\".c(2:5) filter data February May filter_date = \"month\". filter_by String, variable name filter . filter_value vector values filter `MainDataTable` using variable  filter_by. filter_expr String, valid R expression filter `MainDataTable` using variable  filter_by. facet_by Variable name facet . can variable exists dataset, variable created roll_catch() \"year\", \"month\", \"species\" one variable entered catch. scale Scale argument passed facet_grid. Options include \"free\", \"free_x\", \"free_y\". Defaults \"fixed\". align Indicates whether results window left-aligned (\"left\"), right-aligned (\"right\"), centered (\"center\"). Defaults \"center\". conv Convert catch variable \"tons\", \"metric_tons\", using function. Defaults FALSE. tran function transform y-axis. Options include log, log2, log10, sqrt. format_lab Formatting option y-axis labels. Options include  \"decimal\" \"scientific\". output Whether display \"plot\", \"table\", . Defaults (\"tab_plot\"). ... Additional arguments passed rollapply","code":""},{"path":"/reference/roll_catch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply moving average function to catch — roll_catch","text":"","code":"if (FALSE) { roll_catch(pollockMainDataTable, project = \"pollock\", catch = \"LBS_270_POLLOCK_LBS\",   date = \"FISHING_START_DATE\", group = \"GEAR_TYPE\", k = 15 )  roll_catch(pollockMainDataTable, project = \"pollock\", catch = c(\"LBS_270_POLLOCK_LBS\",   \"LBS_110_PACIFIC_COD_LBS\"), date = \"FISHING_START_DATE\", group = \"GEAR_TYPE\", k = 5,   filter_date = \"month\", date_value = 4:6, facet_by = \"month\", conv = \"tons\" ) }"},{"path":"/reference/roll_catch_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Create and format roll_catch plot — roll_catch_plot","title":"Create and format roll_catch plot — roll_catch_plot","text":"Create format roll_catch plot","code":""},{"path":"/reference/roll_catch_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create and format roll_catch plot — roll_catch_plot","text":"","code":"roll_catch_plot(   roll_tab,   catch,   date,   group,   facet_by,   fun,   k,   conv,   tran,   format_lab,   scale )"},{"path":"/reference/roll_catch_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create and format roll_catch plot — roll_catch_plot","text":"roll_tab Table containing rolling summary catch. catch String, name catch variable(s). date String, name date column. group String, name grouping variable(s). facet_by String, name facet variable(s). fun String, name summary function. k Numeric, width window. conv String, convert pounds \"tons\" \"metric_tons\". tran function transform y-axis. Options include log, log2,  log10, sqrt. format_lab Formatting option y-axis labels. Options include  \"decimal\" \"scientific\". scale Scale argument passed facet_grid.Options include  \"free\", \"free_x\", \"free_y\". Defaults \"fixed\".","code":""},{"path":"/reference/roll_cc.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply window_cc — roll_cc","title":"Apply window_cc — roll_cc","text":"Used roll_catch() count unique vessels within rolling window  multiple columns catch.","code":""},{"path":"/reference/roll_cc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply window_cc — roll_cc","text":"","code":"roll_cc(dat, k, align)"},{"path":"/reference/roll_cc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply window_cc — roll_cc","text":"dat Dataframe used calculate rolling catch. k Window width. align Window alignment.","code":""},{"path":[]},{"path":"/reference/run_confid_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether confidentiality rules should be applied — run_confid_check","title":"Check whether confidentiality rules should be applied — run_confid_check","text":"Check whether confidentiality rules applied","code":""},{"path":"/reference/run_confid_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether confidentiality rules should be applied — run_confid_check","text":"","code":"run_confid_check(project)"},{"path":"/reference/run_confid_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether confidentiality rules should be applied — run_confid_check","text":"project Name project.","code":""},{"path":"/reference/run_confid_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether confidentiality rules should be applied — run_confid_check","text":"TRUE confidentiality settings exists check = TRUE,  FALSE settings exists yet check = FALSE.","code":""},{"path":"/reference/run_fishset_gui.html","id":null,"dir":"Reference","previous_headings":"","what":"Guided user interface for FishSET functions — run_fishset_gui","title":"Guided user interface for FishSET functions — run_fishset_gui","text":"Runs functions associated loading data, exploring data, checking data quality issues, generating new variables, basic data analysis function.","code":""},{"path":"/reference/run_fishset_gui.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Guided user interface for FishSET functions — run_fishset_gui","text":"","code":"run_fishset_gui()"},{"path":"/reference/run_fishset_gui.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Guided user interface for FishSET functions — run_fishset_gui","text":"Opens interactive page allows users select functions run clicking check boxes. Data can modified saved. Plot table output saved output folder. Functions calls logged log file.","code":""},{"path":"/reference/run_fishset_gui.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Guided user interface for FishSET functions — run_fishset_gui","text":"","code":"if (FALSE) { run_fishset_gui() }"},{"path":"/reference/run_policy.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs policy scenarios — run_policy","title":"Runs policy scenarios — run_policy","text":"Estimate redistributed fishing effort welfare loss/gain changes policy change factors influence fisher location choice.","code":""},{"path":"/reference/run_policy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs policy scenarios — run_policy","text":"","code":"run_policy(   project,   mod.name = NULL,   betadraws = 1000,   marg_util_income = NULL,   income_cost = NULL,   zone.dat = NULL,   group_var = NULL,   enteredPrice = NULL,   expected.catch = NULL,   use.scalers = FALSE,   scaler.func = NULL )"},{"path":"/reference/run_policy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs policy scenarios — run_policy","text":"project Name project mod.name Model name. Argument can name model name  can pulled `modelChosen` table. Leave mod.name empty use  name saved `best` model. one model saved,  mod.name numeric indicator model use. Use table_view(\"modelChosen\", project) view table saved models. betadraws Integer indicating number times run welfare simulation. Default value betadraws = 1000 marg_util_income conditional zonal logit models. Name coefficient use  marginal utility income. income_cost conditional zonal logit models. Logical indicating whether coefficient marginal utility income relates cost (TRUE) revenue (FALSE). zone.dat Variable primary data table contains unique zone ID. group_var Categorical variable primary data table group welfare outputs. enteredPrice Price data. Leave NULL using price data primary  dataset. expected.catch Required conditional logit (logit_c) model. Name expected catch table use. Can expected catch  short-term scenario (short), medium-term scenario (med),  long-term scenario (long), user-defined temporal parameters  (user). use.scalers Input create_model_input(). Logical, data normalized? Defaults FALSE. Rescaling factors mean  numeric vector unless specified scaler.func. scaler.func Input create_model_input(). Function calculate rescaling factors.","code":""},{"path":"/reference/run_policy.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Runs policy scenarios — run_policy","text":"run_policy wrapper function model_prediction welfare_predict.    model_prediction estimates redistributed fishing effort policy changes, welfare_predict    simulates welfare loss/gain.","code":""},{"path":"/reference/save_closure_scenario.html","id":null,"dir":"Reference","previous_headings":"","what":"Save unique closure scenarios — save_closure_scenario","title":"Save unique closure scenarios — save_closure_scenario","text":"Used save unique closures scenarios closures yaml file located project output folder.","code":""},{"path":"/reference/save_closure_scenario.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save unique closure scenarios — save_closure_scenario","text":"","code":"save_closure_scenario(project, c_list)"},{"path":"/reference/save_closure_scenario.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save unique closure scenarios — save_closure_scenario","text":"project Name project. c_list List closure scenarios check save.","code":""},{"path":"/reference/save_dat.html","id":null,"dir":"Reference","previous_headings":"","what":"Save modified primary data table to FishSET database — save_dat","title":"Save modified primary data table to FishSET database — save_dat","text":"Save modified primary data table FishSET database","code":""},{"path":"/reference/save_dat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save modified primary data table to FishSET database — save_dat","text":"","code":"save_dat(dat, project)"},{"path":"/reference/save_dat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save modified primary data table to FishSET database — save_dat","text":"dat Name data frame working environment save FishSET database. project String, name project.","code":""},{"path":"/reference/save_dat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Save modified primary data table to FishSET database — save_dat","text":"Use function save modified data FishSET database. primary    data saved automatically data upload data check functions.    therefore advisable save modified data database    moving modeling functions. Users use primary data   working environment assessing data quality issues, modifying data,    generating new variables. Pulling primary data FishSET    database function without manually saving result loss changes.","code":""},{"path":"/reference/save_dat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save modified primary data table to FishSET database — save_dat","text":"","code":"if (FALSE) { save_dat(pollockMainDataTable, 'pollock') }"},{"path":"/reference/save_grid_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Save grid file to project data directory — save_grid_cache","title":"Save grid file to project data directory — save_grid_cache","text":"Save grid file project data directory","code":""},{"path":"/reference/save_grid_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save grid file to project data directory — save_grid_cache","text":"","code":"save_grid_cache(project, grid_list, grid_info, mod_type = \"combine\")"},{"path":"/reference/save_grid_cache.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save grid file to project data directory — save_grid_cache","text":"project Name project. grid_list List containing grid files. grid_info List containing grid information. mod_type String, \"combine\" combined map files \"edit\"  edited map files.","code":""},{"path":"/reference/save_grid_cache.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Save grid file to project data directory — save_grid_cache","text":"function references grid log determine whether grid  file saved. grid file unique saved, otherwise  action taken.","code":""},{"path":[]},{"path":"/reference/save_nplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Save table to output folder — save_nplot","title":"Save table to output folder — save_nplot","text":"Save table output folder","code":""},{"path":"/reference/save_nplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save table to output folder — save_nplot","text":"","code":"save_nplot(project, func_name, plot_list, id = \"num\", ...)"},{"path":"/reference/save_nplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save table to output folder — save_nplot","text":"project name project. func_name Name function used create plot. ... addition arguments passed ggsave.","code":""},{"path":"/reference/save_nplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save table to output folder — save_nplot","text":"","code":"if (FALSE) { save_nplot(project, \"species_catch\", plot_list) }"},{"path":"/reference/save_ntable.html","id":null,"dir":"Reference","previous_headings":"","what":"Save list of tables to output folder — save_ntable","title":"Save list of tables to output folder — save_ntable","text":"Save list tables output folder","code":""},{"path":"/reference/save_ntable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save list of tables to output folder — save_ntable","text":"","code":"save_ntable(table, project, func_name, id = \"num\", ...)"},{"path":"/reference/save_ntable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save list of tables to output folder — save_ntable","text":"table List containing tables save. project project name. func_name Name function used create table. id String, id append function name. Options include \"seq\"  save list entry number \"name\" save list entry name. ... addition arguments passed write.csv.","code":""},{"path":"/reference/save_ntable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save list of tables to output folder — save_ntable","text":"","code":"if (FALSE) { save_ntable(tab_list, project, \"species_catch\") }"},{"path":"/reference/save_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Save plot to output folder — save_plot","title":"Save plot to output folder — save_plot","text":"Save plot output folder","code":""},{"path":"/reference/save_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save plot to output folder — save_plot","text":"","code":"save_plot(project, func_name, ...)"},{"path":"/reference/save_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save plot to output folder — save_plot","text":"project name project. func_name Name function used create plot. ... addition arguments passed ggsave.","code":""},{"path":"/reference/save_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save plot to output folder — save_plot","text":"","code":"if (FALSE) { save_plot(project, \"species_catch\") }"},{"path":"/reference/save_raw_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a meta data file to project folder — save_raw_meta","title":"Save a meta data file to project folder — save_raw_meta","text":"Raw (.e. original pre-existing) meta data can saved project folder.  add additional meta data (e.g. column descriptions), see ...","code":""},{"path":"/reference/save_raw_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a meta data file to project folder — save_raw_meta","text":"","code":"save_raw_meta(   file,   project,   dataset = NULL,   tab.name = NULL,   tab.type,   parse = FALSE,   overwrite = FALSE,   ... )"},{"path":"/reference/save_raw_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a meta data file to project folder — save_raw_meta","text":"file String, file path. project Project name. dataset Optional, data.frame associated meta data. Used  add column names meta file. tab.name table name appears FishSET Database (e.g. \"projectMainDataTable\" main table). tab.type table type. Options include \"main\", \"spat\" (spatial),  \"port\", \"grid\" (gridded), \"aux\" (auxiliary). parse Logical, whether parse meta data data file. See  parse_meta. overwrite Logical, whether overwrite existing meta table entry. ... Additional arguments passed parse_meta.","code":""},{"path":[]},{"path":"/reference/save_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Save table to output folder — save_table","title":"Save table to output folder — save_table","text":"Save table output folder","code":""},{"path":"/reference/save_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save table to output folder — save_table","text":"","code":"save_table(table, project, func_name, ...)"},{"path":"/reference/save_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save table to output folder — save_table","text":"table table name. project project name. func_name function name. ... addition arguments passed write.csv.","code":""},{"path":"/reference/save_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save table to output folder — save_table","text":"","code":"if (FALSE) { save_table(count, project, \"species_catch\") }"},{"path":"/reference/scallop.html","id":null,"dir":"Reference","previous_headings":"","what":"Northeast Scallop Data — scallop","title":"Northeast Scallop Data — scallop","text":"subset anonymized scallop data","code":""},{"path":"/reference/scallop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Northeast Scallop Data — scallop","text":"","code":"scallop"},{"path":"/reference/scallop.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Northeast Scallop Data — scallop","text":"`scallop` data.frame 10,000 rows 31 columns: TRIPID Randomly assigned trip ID number. DATE_TRIP Date landing. PERMIT.y Randomly assigned six-digit vessel fishing permit number. TRIP_LENGTH Days calculated elapsed time    date-time sailed date-time landed; measure days absent. GEARCODE Fishing gear used trip. port_lat Latitude geoid. port_lon longitude geoid. previous_port_lat Previous latitude geoid. previous_port_lon Previous longitude geoid. Plan Code Portion VMS declaration code identifies    fishery declared trip. Program Code Portion VMS declaration code identifies    program within declared fishery. scallops, program code delineates    LA LAGC trips, well access area trips trips. TRIP_COST_WINSOR_2020_DOL estimated real composite trip cost    VTR trip record generated using methods described    Commercial Trip Cost Estimation 2007-2019 PDF file. However, values    Winsorized gear type method avoiding unreasonably high    low trip costs, replacing value within gear-group less    1st percentile greater 99th percentile 1st    99th percentile value, respectively. DDLAT latitude reported VTR (Vessel Trip Reports). DDLON longitude reported VTR (Vessel Trip Reports). NAME Name wind lease found within given ten minute square. ZoneID FishSET's version ten minute square. POUNDS Live pounds. LANDED Landed pounds dealer report. LANDED_OBSCURED Landed pounds dealer report (jittered/obscured). DOLLAR_OBSCURED value catch paid dealer,    dealer report (jittered/obscured). DOLLAR_2020_OBSCURED value catch paid dealer,    dealer report (2020 dollars, jittered/obscured). DOLLAR_ALL_SP_2020_OBSCURED value catch species caught    (2020 dollars, jittered/obscured).","code":""},{"path":"/reference/scallop.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Northeast Scallop Data — scallop","text":"Add source ","code":""},{"path":"/reference/scallop_ports.html","id":null,"dir":"Reference","previous_headings":"","what":"Ports from the NE scallop fishery — scallop_ports","title":"Ports from the NE scallop fishery — scallop_ports","text":"dataset containing names lat/lon coordinates ports used US northeast scallop fishery.","code":""},{"path":"/reference/scallop_ports.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ports from the NE scallop fishery — scallop_ports","text":"","code":"scallop_ports"},{"path":"/reference/scallop_ports.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Ports from the NE scallop fishery — scallop_ports","text":"data frame (tibble) 40 observations 3 variables. [,1] Port names  [,2] Longitude  [,3] Latitude","code":""},{"path":"/reference/scallop_ports.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Ports from the NE scallop fishery — scallop_ports","text":"NEED ADD SOURCE DESCRIPTION","code":""},{"path":"/reference/seasonalID.html","id":null,"dir":"Reference","previous_headings":"","what":"Create single binary fishery season identifier variable — seasonalID","title":"Create single binary fishery season identifier variable — seasonalID","text":"Create single binary fishery season identifier variable","code":""},{"path":"/reference/seasonalID.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create single binary fishery season identifier variable — seasonalID","text":"","code":"seasonalID(   dat,   project,   seasonal.dat = NULL,   start,   end,   overlap = FALSE,   name = NULL )"},{"path":"/reference/seasonalID.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create single binary fishery season identifier variable — seasonalID","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. seasonal.dat Data table containing date fishery season(s). Data table can pulled FishSET database. Leave seasonal.dat NULL supplying start end dates start end arguments. start Date, supplied string (example: start='2011/04/22', start='04222011'),  variable seasonal.dat identifies start date fishery season end DDate, supplied string (example: start='2011/04/22', start='04222011'),  variable seasonal.dat identifies end date fishery season overlap Logical. trip haul dates start end fishery season date starts ends within fishery season dates included? FALSE indicates inlude hauls/trips fall completely within bounds fishery season date. Defaults FALSE. name String  Seasonal identifier name","code":""},{"path":"/reference/seasonalID.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create single binary fishery season identifier variable — seasonalID","text":"Returns binary variable within (1) outside (0) fishery season.","code":""},{"path":"/reference/seasonalID.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create single binary fishery season identifier variable — seasonalID","text":"Uses supplied dates table fishery season dates create fishery season identifier variables. Output binary variable called name `SeasonID` name supplied.  row dat, function matches fishery season dates provided seasonal.dat earliest date variable dat.","code":""},{"path":"/reference/seasonalID.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create single binary fishery season identifier variable — seasonalID","text":"","code":"if (FALSE) { #Example using a table stored in the FishSET database pcodMainDataTable <- season_ID(\"pcodMainDataTable\", 'pcod', seasonal_dat='seasonTable',       start='SeasonStart', end='SeasonEnd', name='2001A') #Example using manually entered dates pcodMainDataTable <- season_ID(\"pcodMainDataTable\", 'pcod', seasonal.dat=NULL,      start='04152011', end='06302011', name='2001A') }"},{"path":"/reference/select_model.html","id":null,"dir":"Reference","previous_headings":"","what":"View model metrics and record best model interactively — select_model","title":"View model metrics and record best model interactively — select_model","text":"Model metrics displayed table R Shiny application.   Check boxes next models allow users record preferred best model.","code":""},{"path":"/reference/select_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View model metrics and record best model interactively — select_model","text":"","code":"select_model(project, overwrite_table = FALSE)"},{"path":"/reference/select_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View model metrics and record best model interactively — select_model","text":"project String, name project. overwrite_table Logical, best model table written ? table exists  value FALSE, appends new results existing table. Defaults FALSE.","code":""},{"path":"/reference/select_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"View model metrics and record best model interactively — select_model","text":"Opens interactive data table displays model measures fit model run saved model measures fit table   FishSET database. name table contain string '.mod'. Users can delete models table select   preferred model checking \"selected\" box. table saved FishSET database two new columns added, TRUE/FALSE   selected column date selected. table saved phrase 'modelChosen' FishSET database. function can   also called indirectly discretefish_subroutine specifying select.model argument TRUE.   'modelChosen' table used functions. purpose function 'modelChosen' table save reference preferred model.","code":""},{"path":"/reference/select_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View model metrics and record best model interactively — select_model","text":"","code":"if (FALSE) { select_model(\"pollock\", overwrite_table = FALSE) }"},{"path":"/reference/select_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Interactive application to select variables to include/exclude in primary dataset — select_vars","title":"Interactive application to select variables to include/exclude in primary dataset — select_vars","text":"Opens R Shiny web application. application select   variables primary dataset retained.","code":""},{"path":"/reference/select_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interactive application to select variables to include/exclude in primary dataset — select_vars","text":"","code":"select_vars(dat, project)"},{"path":"/reference/select_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interactive application to select variables to include/exclude in primary dataset — select_vars","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project.","code":""},{"path":"/reference/select_vars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interactive application to select variables to include/exclude in primary dataset — select_vars","text":"Opens interactive table allows users select variables included clicking check boxes.   Data loaded FishSET database running function. Select variables used   generate variables, rates cpue, variables included models.   Removed variables can added back dataset later date using add_vars function.","code":""},{"path":"/reference/select_vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interactive application to select variables to include/exclude in primary dataset — select_vars","text":"","code":"if (FALSE) { select_vars(pcodMainDataTable, \"pcod\") }"},{"path":"/reference/set_confid_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Set confidentiality parameters — set_confid_check","title":"Set confidentiality parameters — set_confid_check","text":"function specifics whether check confidentiality  rule applied.","code":""},{"path":"/reference/set_confid_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set confidentiality parameters — set_confid_check","text":"","code":"set_confid_check(project, check = TRUE, v_id = NULL, rule = \"n\", value = NULL)"},{"path":"/reference/set_confid_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set confidentiality parameters — set_confid_check","text":"project Name project. check Logical, whether check confidentiality. v_id String, column name containing vessel identifier. rule String, confidentiality rule apply. See \"Details\" .  rule = \"n\" suppresses values containing fewer n vessels.  rule = \"k\" suppresses values single vessel contains k percent  total catch. value threshold confidentiality. rule = \"n\" must  integer least 2. rule = \"k\" numeric value  0 100.","code":""},{"path":"/reference/set_confid_check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set confidentiality parameters — set_confid_check","text":"rule = \"n\" counts number vessel strata    suppresses values fewer n vessels present.   rule = \"k\", \"Majority allocation rule\", vessel's share    catch calculated strata. vessel's total catch share greater    equal k percent value suppressed.","code":""},{"path":"/reference/set_confid_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set confidentiality parameters — set_confid_check","text":"","code":"if (FALSE) { set_confid_check(\"pollock\", check = TRUE, v_id = \"PERMIT\", rule = \"n\", value = 3L) }"},{"path":"/reference/set_quants.html","id":null,"dir":"Reference","previous_headings":"","what":"Create factor variable from quantiles — set_quants","title":"Create factor variable from quantiles — set_quants","text":"Create factor variable numeric data.  Numeric variable split categories based quantile categories.","code":""},{"path":"/reference/set_quants.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create factor variable from quantiles — set_quants","text":"","code":"set_quants(   dat,   project,   x,   quant.cat = c(0.1, 0.2, 0.25, 0.33, 0.4),   custom.quant = NULL,   name = \"set_quants\" )"},{"path":"/reference/set_quants.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create factor variable from quantiles — set_quants","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. x Variable transform quantiles. quant.cat Quantile options: \"0.2\", \"0.25\", \"0.33\", \"0.4\" 0.1:  (0%, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%) 0.2:  (0%, 20%, 40%, 60%, 80%, 100%) 0.25: (0%, 25%, 50%, 75%, 100%) 0.33: (0%, 33%, 66%, 100%) 0.4:  (0%, 10%, 50%, 90%, 100%) custom.quant Vector, user defined quantiles. name String, name created vector. Defaults name function defined.","code":""},{"path":"/reference/set_quants.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create factor variable from quantiles — set_quants","text":"Primary dataset quantile variable added.","code":""},{"path":"/reference/set_quants.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create factor variable from quantiles — set_quants","text":"","code":"if (FALSE) { pollockMainDataTable <- set_quants(pollockMainDataTable, 'pollock', 'HAUL',     quant.cat=.2, 'haul.quant') }"},{"path":"/reference/set_user_locoutput.html","id":null,"dir":"Reference","previous_headings":"","what":"Set user folder directory — set_user_locoutput","title":"Set user folder directory — set_user_locoutput","text":"Set user folder directory","code":""},{"path":"/reference/set_user_locoutput.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set user folder directory — set_user_locoutput","text":"","code":"set_user_locoutput(loc_dir, project)"},{"path":"/reference/set_user_locoutput.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set user folder directory — set_user_locoutput","text":"loc_dir Local user directory project Name project.","code":""},{"path":"/reference/set_user_locoutput.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set user folder directory — set_user_locoutput","text":"function saves local user directory project settings file  valid folder directory. directory path used inserting plots   tables folder outside FishSET package FishSET RMarkdown   Template.","code":""},{"path":[]},{"path":"/reference/shift_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Shift longitude predicate Detects whether longitude coordinates should be re-centered to Pacific view — shift_long","title":"Shift longitude predicate Detects whether longitude coordinates should be re-centered to Pacific view — shift_long","text":"Shift longitude predicate Detects whether longitude coordinates re-centered Pacific view","code":""},{"path":"/reference/shift_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shift longitude predicate Detects whether longitude coordinates should be re-centered to Pacific view — shift_long","text":"","code":"shift_long(spat)"},{"path":"/reference/shift_long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shift longitude predicate Detects whether longitude coordinates should be re-centered to Pacific view — shift_long","text":"spat Spatial data check.","code":""},{"path":"/reference/shift_long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shift longitude predicate Detects whether longitude coordinates should be re-centered to Pacific view — shift_long","text":"TRUE longitude shifted pacific view (.e.  longitude values < 0).","code":""},{"path":"/reference/shift_sort_x.html","id":null,"dir":"Reference","previous_headings":"","what":"shift_sort_x — shift_sort_x","title":"shift_sort_x — shift_sort_x","text":"Shifts choices chosen zone automatically first     one choice possibilities distances.","code":""},{"path":"/reference/shift_sort_x.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"shift_sort_x — shift_sort_x","text":"","code":"shift_sort_x(x, ch, y, distance, alts, ab)"},{"path":"/reference/shift_sort_x.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"shift_sort_x — shift_sort_x","text":"x Matrix choice possibilities create_logit_input. ch Data corresponding actual zonal choice. y Data corresponding actual catch. distance Data corresponding distance. alts Number alternative choices model. ab Number cost parameters + number alts.","code":""},{"path":"/reference/shift_sort_x.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"shift_sort_x — shift_sort_x","text":"d: matrix choice possibilities distance. IMPORTANT NOTE: choice probabilities distances sorted even though   column names distances remain unchanged.","code":""},{"path":"/reference/short_expectations.html","id":null,"dir":"Reference","previous_headings":"","what":"Short expectations — short_expectations","title":"Short expectations — short_expectations","text":"Short expectations","code":""},{"path":"/reference/short_expectations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Short expectations — short_expectations","text":"","code":"short_expectations(   dat,   project,   catch,   price,   defineGroup,   temp.var,   temporal,   calc.method,   lag.method,   empty.catch,   empty.expectation,   dummy.exp )"},{"path":"/reference/short_expectations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Short expectations — short_expectations","text":"dat Main data frame containing data hauls trips. Table FishSET database contain string `MainDataTable`. project Name project. Used pull working alternative choice matrix FishSET database. catch Variable containing catch data. price Variable containing price/value data. Used calculating expected revenue. Leave null calculating expected catch. Multiplied catch generated revenue. defineGroup empty, data treated fleet temp.var Variable containing temporal data temporal Daily (Daily time line) sequential (sequential order) calc.method Select standard average (standardAverage), simple lag regression means (simpleLag), weights regressed groups (weights) lag.method Use regression entire group (simple) grouped time periods (grouped) empty.catch Replace empty catch NA, 0, mean catch (allCatch), mean grouped catch(groupCatch) empty.expectation replace (NULL) replace 0.0001 0 dummy.exp Logical, dummy variable outputted. true, output dummy variable originally missing value.","code":""},{"path":"/reference/short_expectations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Short expectations — short_expectations","text":"Expected catch matrix. Saved database via create_expectations","code":""},{"path":"/reference/simpleCap.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert case to upper — simpleCap","title":"Convert case to upper — simpleCap","text":"Convert case upper","code":""},{"path":"/reference/simpleCap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert case to upper — simpleCap","text":"","code":"simpleCap(x)"},{"path":"/reference/simpleCap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert case to upper — simpleCap","text":"x Variable","code":""},{"path":"/reference/simplify_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Simplify a list — simplify_list","title":"Simplify a list — simplify_list","text":"Cleans list converts applicable leaf nodes dataframes.","code":""},{"path":"/reference/simplify_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simplify a list — simplify_list","text":"","code":"simplify_list(l, format = FALSE)"},{"path":"/reference/simplify_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simplify a list — simplify_list","text":"l list. format Logical, whether print list using pandoc markdown.","code":""},{"path":"/reference/simplify_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simplify a list — simplify_list","text":"list","code":""},{"path":[]},{"path":"/reference/simplify_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simplify a list — simplify_list","text":"","code":"if (FALSE) { simplify_list(list(A = 1:10, B = 11:20))  simplify_list(list(A = list(X = 1:10, Y = letters[1:10])))  simplify_list(list(A = 1:10, B = \"Text\", C = c(\"text\", \"text\"))) }"},{"path":"/reference/sim_welfare.html","id":null,"dir":"Reference","previous_headings":"","what":"Welfare simulator — sim_welfare","title":"Welfare simulator — sim_welfare","text":"Welfare simulator","code":""},{"path":"/reference/sim_welfare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Welfare simulator — sim_welfare","text":"","code":"sim_welfare(project, X, alts, beta_j, scenario)"},{"path":"/reference/sim_welfare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Welfare simulator — sim_welfare","text":"project Name project X Independent variables RUM alts Number alternative zones beta_j Output mvrgrnd scenario Scenario list created welfare_predict","code":""},{"path":"/reference/sim_welfare.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Welfare simulator — sim_welfare","text":"Subfunction welfare_predict","code":""},{"path":"/reference/skewness.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate skewness — skewness","title":"Calculate skewness — skewness","text":"Calculate skewness","code":""},{"path":"/reference/skewness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate skewness — skewness","text":"","code":"skewness(x, na.rm = FALSE)"},{"path":"/reference/skewness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate skewness — skewness","text":"x variable interest na.rm set FALSE","code":""},{"path":"/reference/spars.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for sparsity functions — spars","title":"Helper function for sparsity functions — spars","text":"Helper function sparsity functions","code":""},{"path":"/reference/spars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for sparsity functions — spars","text":"","code":"spars(x, dname)"},{"path":"/reference/spars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function for sparsity functions — spars","text":"x Name table dname time period","code":""},{"path":"/reference/sparsetable.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate sparsity in data over time in table format — sparsetable","title":"Evaluate sparsity in data over time in table format — sparsetable","text":"Create table data sparsity predefined time periods.","code":""},{"path":"/reference/sparsetable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate sparsity in data over time in table format — sparsetable","text":"","code":"sparsetable(dat, project, timevar, zonevar, var)"},{"path":"/reference/sparsetable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate sparsity in data over time in table format — sparsetable","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. timevar Variable dat containing temporal data zonevar Variable dat containing zone observation assigned var Variable dat containing catch data","code":""},{"path":"/reference/sparsplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate sparsity in data over time in plot format — sparsplot","title":"Evaluate sparsity in data over time in plot format — sparsplot","text":"Evaluate sparsity data time plot format","code":""},{"path":"/reference/sparsplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate sparsity in data over time in plot format — sparsplot","text":"","code":"sparsplot(project, x = NULL)"},{"path":"/reference/sparsplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate sparsity in data over time in plot format — sparsplot","text":"project String, name project. x Output sparsetable. x null, sparsity table pulled output folder exists.","code":""},{"path":"/reference/sparsplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate sparsity in data over time in plot format — sparsplot","text":"Returns plot sparsity values time. Requires sparsity table generated sparsetable.","code":""},{"path":"/reference/spatial_hist.html","id":null,"dir":"Reference","previous_headings":"","what":"Histogram of latitude and longitude by grouping variable — spatial_hist","title":"Histogram of latitude and longitude by grouping variable — spatial_hist","text":"Histogram latitude longitude grouping variable","code":""},{"path":"/reference/spatial_hist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Histogram of latitude and longitude by grouping variable — spatial_hist","text":"","code":"spatial_hist(dat, project, group = NULL)"},{"path":"/reference/spatial_hist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Histogram of latitude and longitude by grouping variable — spatial_hist","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. group Column dat containing grouping categories.","code":""},{"path":"/reference/spatial_hist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Histogram of latitude and longitude by grouping variable — spatial_hist","text":"Returns histogram latitude longitude grouping variable.   Output returned console saved Output folder.","code":""},{"path":"/reference/spatial_hist.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Histogram of latitude and longitude by grouping variable — spatial_hist","text":"Returns histogram observed lat/lon split grouping variable.   Output printed console saved Output folder.  Function used   assess spatial variance/clumping selected grouping variable.","code":""},{"path":"/reference/spatial_hist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Histogram of latitude and longitude by grouping variable — spatial_hist","text":"","code":"if (FALSE) { spatial_hist(pollockMainDataTable, 'pollock', 'GEAR_TYPE') }"},{"path":"/reference/spatial_qaqc.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial data quality checks — spatial_qaqc","title":"Spatial data quality checks — spatial_qaqc","text":"function performs spatial quality checks outputs summary tables  plots. Checks include percent observations land, outside regulatory zone (spat), zone boundary. observation occurs outside  regulatory zones summary information distance nearest zone  provided. spatial_qaqc can filter observations within distance specified filter_dist.","code":""},{"path":"/reference/spatial_qaqc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spatial data quality checks — spatial_qaqc","text":"","code":"spatial_qaqc(   dat,   project,   spat,   lon.dat,   lat.dat,   lon.spat = NULL,   lat.spat = NULL,   id.spat = NULL,   epsg = NULL,   date = NULL,   group = NULL,   filter_dist = NULL )"},{"path":"/reference/spatial_qaqc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial data quality checks — spatial_qaqc","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project Name project. spat Spatial data containing information fishery management  regulatory zones. sf objects recommended, sp objects can used well. using spatial table read csv file, arguments lon.spat lat.spat required. upload spatial data FishSETFolder see load_spatial. lon.dat Longitude variable dat. lat.dat Latitude variable dat. lon.spat Variable list spat containing longitude data.   Required spatial tables read csv files. Leave NULL   spat sf  sp object. lat.spat Variable list spat containing latitude data.  Required spatial tables read csv files. Leave NULL  spat sf sp object. id.spat Polygon ID column. Required spatial tables read csv  files. Leave NULL spat sf sp object. epsg EPSG number. Manually set epsg code, applied  spat dat. epsg specified defined  spat, spat epsg applied dat. addition, epsg specified epsg defined spat, default epsg value applied spat dat (epsg = 4326). See http://spatialreference.org/ help identify optimal epsg number. date String, name date variable. Used summarize year. NULL first date column used. Returns error date columns can found. group String, optional. Name variable group spatial summary . filter_dist (Optional) Numeric, distance value filter primary data (meters). Rows containing distance values greater equal filter_dist removed data. action saved filter table.","code":""},{"path":"/reference/spatial_qaqc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spatial data quality checks — spatial_qaqc","text":"list plots /dataframes depending whether spatial data  quality issues detected. list includes:  dataset Primary data. five logical columns added       spatial issues found: \"ON_LAND\" (obs fall land), \"OUTSIDE_ZONE\"       (obs occur sea outside zone), \"ON_ZONE_BOUNDARY\" (obs occurs       zone boundary), \"EXPECTED_LOC\" (whether obs occurs sea, within zone,       zone boundary), \"NEAREST_ZONE_DIST_M\" (distance meters       nearest zone. Applies obs outside zone land). spatial_summary Dataframe containing percentage observations        occur sea within zones, land, outside zones sea,        zone boundary year /group. total number observations        year/group \"N\" column. outside_plot Plot observations outside regulatory zones. land_plot Plot observations fall land. land_out_plot Plot observations occur land outside       regulatory zones (combines outside_plot land_plot occur). boundary_plot Plot observations fall zone boundary. expected_plot Plot observations occur sea within zones. distance_plot Histogram distance form nearest zone (meters) year        observations outside regulatory grid. distance_freq Binned frequency table distance values. distance_summary Dataframe containing minimum, 1st quartile,        median, mean, 3rd quartile, maximum distance values year /group.","code":""},{"path":"/reference/spatial_qaqc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spatial data quality checks — spatial_qaqc","text":"","code":"if (FALSE) { # run spatial checks spatial_qaqc(\"pollockMainDataTable\", \"pollock\", spat = NMFS_AREAS,               lon.dat = \"LonLat_START_LON\", lat.dat = \"LonLat_START_LAT\")               # filter obs by distance spat_out <-       spatial_qaqc(pollockMainDataTable, \"pollock\", spat = NMFS_AREAS,                   lon.dat = \"LonLat_START_LON\", lat.dat = \"LonLat_START_LAT\",                   filter_dist = 100) mod.dat <- spat_out$dataset }"},{"path":"/reference/spatial_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize variable over data and time — spatial_summary","title":"Summarize variable over data and time — spatial_summary","text":"View summary exploratory statistics selected variable date zone.","code":""},{"path":"/reference/spatial_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize variable over data and time — spatial_summary","text":"","code":"spatial_summary(   dat,   project,   stat.var = c(\"length\", \"no_unique_obs\", \"perc_total\", \"mean\", \"median\", \"min\", \"max\",     \"sum\"),   variable,   spat,   lon.spat = NULL,   lat.spat = NULL,   lon.dat = NULL,   lat.dat = NULL,   cat )"},{"path":"/reference/spatial_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize variable over data and time — spatial_summary","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. stat.var Options \"length\", \"no_unique_obs\", \"perc_total\", \"mean\", \"median\", \"min\", \"max\", \"sum\". variable Variable dat summarize date zone. spat Spatial data containing information fishery management regulatory zones. Shape, json, geojson, csv formats supported. Leave NULL variable ‘ZoneID’ assigning observations zones exists dat. lon.spat Variable list spat containing longitude data. Required csv files.  Leave NULL spat shape json file variable ‘ZoneID’ exists dat. lat.spat Variable list spat containing latitude data. Required csv files. Leave NULL spat shape json file, variable ‘ZoneID’ exists dat. lon.dat Longitude variable dat. Leave NULL variable ‘ZoneID’ (zonal  assignment) exists dat. lat.dat Latitude variable dat. Leave NULL variable ‘ZoneID’ (zonal  assignments) exists dat. cat Variable list spat identifies individual areas zones. spat class sf, cat name list containing information zones. Leave NULL variable ‘ZoneID’ exists dat.","code":""},{"path":"/reference/spatial_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize variable over data and time — spatial_summary","text":"Returns two plots, variable aggregated stat.var plotted date zone.","code":""},{"path":"/reference/spatial_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize variable over data and time — spatial_summary","text":"stat.var details:","code":""},{"path":[]},{"path":"/reference/spat_qaqc_gui.html","id":null,"dir":"Reference","previous_headings":"","what":"GUI for spatial data checks — spat_qaqc_gui","title":"GUI for spatial data checks — spat_qaqc_gui","text":"Runs spatial checks performed spatial_qaqc shiny application.","code":""},{"path":"/reference/spat_qaqc_gui.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GUI for spatial data checks — spat_qaqc_gui","text":"","code":"spat_qaqc_gui(dataset, project, spatdat, checks = NULL)"},{"path":"/reference/spat_qaqc_gui.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GUI for spatial data checks — spat_qaqc_gui","text":"dataset Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project Name project. spatdat Spatial data containing information fishery management  regulatory zones. See read_dat details importing  spatial data. checks (Optional) list spatial data quality checks outputted spatial_qaqc.","code":""},{"path":[]},{"path":"/reference/species_catch.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize species catch — species_catch","title":"Summarize species catch — species_catch","text":"species_catch summarizes catch (numeric variables) main table. can summarize period date provided, grouping  variables, filter period value. several options  customizing table plot output.","code":""},{"path":"/reference/species_catch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize species catch — species_catch","text":"","code":"species_catch(   dat,   project,   species,   date = NULL,   period = NULL,   fun = \"sum\",   group = NULL,   sub_date = NULL,   filter_date = NULL,   date_value = NULL,   filter_by = NULL,   filter_value = NULL,   filter_expr = NULL,   facet_by = NULL,   type = \"bar\",   conv = \"none\",   tran = \"identity\",   format_lab = \"decimal\",   value = \"count\",   position = \"stack\",   combine = FALSE,   scale = \"fixed\",   output = \"tab_plot\",   format_tab = \"wide\" )"},{"path":"/reference/species_catch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize species catch — species_catch","text":"dat Primary data containing information hauls trips.  Table FishSET database contains string 'MainDataTable'. project String, name project. species Variable dat containing species catch vector  species variables (pounds). date Variable dat containing dates aggregate . period Time period count . Options include 'year', 'month', 'week'  (week year), 'weekday', 'day' (day month), 'day_of_year'.  date required. fun String, name function aggregate . Defaults  sum. group Grouping variable name(s). two grouping variables available  line plots one bar plots. bar plots, one species  entered first group variable passed 'fill'. multiple species  entered, species passed \"fill\" grouping variable dropped. exception occurs facetting species, grouping variable  passed \"fill\". line plots, first grouping variable passed  \"fill\" second \"linetype\" single species column entered  facetting species. Otherwise species passed \"fill\", first  group variable \"linetype\", second dropped. sub_date Date variable used subsetting, grouping, splitting date. filter_date type filter apply `MainDataTable`. filter  range dates, use filter_date = \"date_range\". filter given  period, use \"year-day\", \"year-week\", \"year-month\", \"year\", \"month\", \"week\",  \"day\".  argument date_value must provided. date_value argument paired filter_date. filter date range, set filter_date = \"date_range\" enter  start-  end-date date_value string:  date_value = c(\"2011-01-01\", \"2011-03-15\"). filter period (e.g. \"year\", \"year-month\"), use integers (4 digits year, 1-2  digits referencing day, month, week). Use vector filtering  single period: date_filter = \"month\" date_value = c(1, 3, 5).  filter data January, March, May. Use list using year-period type filter, e.g. \"year-week\",  format: list(year, period). example, filter_date = \"year-month\" date_value = list(2011:2013, 5:7) filter data table  May July years 2011-2013. filter_by String, variable name filter `MainDataTable` . argument  filter_value must provided. filter_value vector values filter `MainDataTable` using  variable filter_by. example, filter_by = \"GEAR_TYPE\",  filter_value = 1 include observations gear type 1. filter_expr String, valid R expression filter `MainDataTable`  using variable filter_by. facet_by Variable name facet . Accepts two variables.  can variables exist dat, variable created  species_catch() \"year\", \"month\", \"week\"  date variable added sub_date. Facetting \"species\"  available multiple catch columns included \"species\".  first variable facetted row second column. type Plot type, options include \"bar\" (default) \"line\". conv Convert catch variable \"tons\", \"metric_tons\",  using function entered string. Defaults \"none\"  conversion. tran function transform y-axis. Options include log, log2,  log10, sqrt. format_lab Formatting option y-axis labels. Options include  \"decimal\" \"scientific\". value Whether calculate raw \"count\" \"percent\"  total catch. position Positioning bar plot. Options include 'stack', 'dodge',  'fill'. combine Whether combine variables listed group.  passed \"fill\" \"color\" aesthetic plots. scale Scale argument passed facet_grid. Defaults  \"fixed\". output Output \"plot\" \"table\". Defaults  (\"tab_plot\"). format_tab table output formatted. Options include 'wide'  (default) 'long'.","code":""},{"path":"/reference/species_catch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize species catch — species_catch","text":"species_catch() aggregates catch using one columns    catch data. Users can aggregate time period, group, .    multiple catch variables entered, new column \"species\" created    used group values plots. \"species\" column can also used split    (facet) plot. table output,   \"species\" column kept format_tab = \"long\", .e. column    species names (\"species\") column containing catch (\"catch\").  format_tab = \"wide\", species given column catch. data can filtered date /variable. filter_date specifies type date filter apply--date-range period.  date_value contain values filter data . filter    variable, enter name string filter_by include    values filter filter_value. Plots can handle two grouping variables, limit tables.    Grouping variables can merged one variable using combine;    case number variables  can joined, three   recommended. faceting, variable (including ones listed group)    can used, \"year\", \"month\", \"week\" also available provided date    variable added sub_date. Currently, combined variables    faceted. list containing table plot printed console    viewer default.","code":""},{"path":"/reference/species_catch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize species catch — species_catch","text":"","code":"if (FALSE) { # summarizing one catch column by one group variable species_catch(pollockMainDataTable, species = \"OFFICIAL_TOTAL_CATCH_MT\",               group = \"GEAR_TYPE\", ouput = \"tab_plot\")  # summarizing three catch columns by month species_catch('pollockMainDataTable',                species = c('HAUL_LBS_270_POLLOCK_LBS',                            'HAUL_LBS_110_PACIFIC_COD_LBS',                            'HAUL_LBS_OTHER_LBS'),                date = 'HAUL_DATE', period = 'month_num', output = 'plot',                conv = 'tons')  # filtering by variable species_catch(pollockMainDataTable, species = \"OFFICAL_TOTAL_CATCH_MT\",               group = \"GEAR_TYPE\", filter_by = \"PORT_CODE\",                filter_value = \"Dutch Harbor\")                 # filtering by date  species_catch(pollockMainDataTable, species = \"OFFICAL_TOTAL_CATCH_MT\",                sub_date = \"HAUL_DATE\", filter_date = \"month\", date_value = 7:10) }"},{"path":"/reference/split_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Perfom quality check for split_dat — split_check","title":"Perfom quality check for split_dat — split_check","text":"Perfom quality check split_dat","code":""},{"path":"/reference/split_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perfom quality check for split_dat — split_check","text":"","code":"split_check(main, split, key, arg)"},{"path":"/reference/split_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perfom quality check for split_dat — split_check","text":"main String, column names MainDataTable. split String, column names \"split_by\" argument. key String, column names \"key\" argument. arg String, whether \"aux\" \"split_by\" argument used.","code":""},{"path":"/reference/split_dat.html","id":null,"dir":"Reference","previous_headings":"","what":"Separate secondary data table from MainDataTable — split_dat","title":"Separate secondary data table from MainDataTable — split_dat","text":"Separate secondary data table MainDataTable","code":""},{"path":"/reference/split_dat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Separate secondary data table from MainDataTable — split_dat","text":"","code":"split_dat(dat, aux = NULL, project, split_by = NULL, key, output = \"main\")"},{"path":"/reference/split_dat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Separate secondary data table from MainDataTable — split_dat","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. aux Auxiliary data table fishset_db environment. Use string referencing  table saved FishSET database. column names \"aux\" used find separate auxiliary table MainDataTable. project String, name project. split_by String, columns MainDataTable split . columns  separated MainDataTable. Must contain values \"key\". key String, column(s) link main auxiliary data tables. using \"aux\" method, \"key\"  must match column MainDataTable \"aux\" data table. using \"split_by\", \"key\" must match column \"MainDataTable also included \"split_by\". output String, return either \"main\" data table, \"aux\" data table, \"\" main aux data tables list.","code":""},{"path":"/reference/split_dat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Separate secondary data table from MainDataTable — split_dat","text":"function separates auxiliary data (gridded port data) MainDatatable.   Users can either input secondary data table (environment fishset_db) determine   columns remove passing string columns names \"split_by\". Use either   \"aux\" \"split_by\" method. Defaults \"aux\" method arguments used.","code":""},{"path":"/reference/split_dat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Separate secondary data table from MainDataTable — split_dat","text":"","code":"if (FALSE) { split_dat(\"pollockMainDataTable\", \"pollock\", aux = \"pollockPortTable\", key = \"PORT_CODE\") }"},{"path":"/reference/subset_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset dataset by date value/range — subset_date","title":"Subset dataset by date value/range — subset_date","text":"Subset dataset date value/range","code":""},{"path":"/reference/subset_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset dataset by date value/range — subset_date","text":"","code":"subset_date(dataset, date, filter, value)"},{"path":"/reference/subset_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset dataset by date value/range — subset_date","text":"dataset `MainDataTable` filter. date String, name date variable subset . filter String, filter type. value range dates filter = \"date_range\", integer using period filter.","code":""},{"path":"/reference/subset_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset `MainDataTable` by variable — subset_var","title":"Subset `MainDataTable` by variable — subset_var","text":"Subset `MainDataTable` variable","code":""},{"path":"/reference/subset_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset `MainDataTable` by variable — subset_var","text":"","code":"subset_var(dataset, filter_by = NULL, filter_value = NULL, filter_expr = NULL)"},{"path":"/reference/subset_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset `MainDataTable` by variable — subset_var","text":"dataset dataset `MainDataTable` filter. filter_by String, name variable used subset `MainDataTable`. filter_value Vector values subset (inclusive). filter_expr String, valid R expression used subset `MainDataTable`.","code":""},{"path":"/reference/sub_date_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check subset date variable — sub_date_check","title":"Check subset date variable — sub_date_check","text":"Check subset date variable","code":""},{"path":"/reference/sub_date_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check subset date variable — sub_date_check","text":"","code":"sub_date_check(sub_date, date, filter_date, group, facet_by)"},{"path":"/reference/sub_date_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check subset date variable — sub_date_check","text":"sub_date String, name date column subset . date String, name date column used creating period variables. filter_date type date filter apply data. group String, name group variable(s). Many fleet function allow  users create year, month, week variable group . grouping  period sub_date date null, function  stopped. facet_by String, name facetting variable(s). Many fleet function allow  users create year, month, week variable facet . splitting  period sub_date date null, function  stopped.","code":""},{"path":"/reference/sub_date_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check subset date variable — sub_date_check","text":"sub_date. used function, assign output sub_date.","code":""},{"path":"/reference/summary_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"View summary statistics — summary_stats","title":"View summary statistics — summary_stats","text":"View summary statistics table format entire dataset specific variable.","code":""},{"path":"/reference/summary_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View summary statistics — summary_stats","text":"","code":"summary_stats(dat, project, x = NULL, log_fun = TRUE)"},{"path":"/reference/summary_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View summary statistics — summary_stats","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Name project x Optional. Variable dat view summary statistics .  defined, summary stats displayed columns dataset. log_fun Logical, whether log function call (internal use).","code":""},{"path":"/reference/summary_stats.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"View summary statistics — summary_stats","text":"Prints summary statistics variable data set.    x specified, summary stats returned variable.   Numeric variables summarized minimum, median, mean, maximum,    number NA's, unique values, zeros. Non-numeric variables summarized   first value number NA's, unique values, empty values.    Function called data_check function.","code":""},{"path":"/reference/summary_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View summary statistics — summary_stats","text":"","code":"if (FALSE) { summary_stats(pcodMainDataTable, project = \"pcod\")  summary_stats(pcodMainDataTable, project = \"pcod\", x = \"HAUL\") }"},{"path":"/reference/summary_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Display dataset summary table — summary_table","title":"Display dataset summary table — summary_table","text":"Display dataset summary table","code":""},{"path":"/reference/summary_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display dataset summary table — summary_table","text":"","code":"summary_table(project, output = \"print\")"},{"path":"/reference/summary_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display dataset summary table — summary_table","text":"project Name project. output Output type. \"print\" returns formatted notes. \"table\" returns  dataframe. \"print\" recommended displaying summary table report.","code":""},{"path":"/reference/summary_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Display dataset summary table — summary_table","text":"Displays recent table created summary_stats dataframe. Can used console notebook.","code":""},{"path":"/reference/suppress_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Suppress confidential values in summary table — suppress_table","title":"Suppress confidential values in summary table — suppress_table","text":"function suppresses values summary table based suppression  conditions found check table (see link{check_confidentiality})","code":""},{"path":"/reference/suppress_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Suppress confidential values in summary table — suppress_table","text":"","code":"suppress_table(   check,   output,   value_var,   group,   rule,   type = \"code\",   as_vector = FALSE )"},{"path":"/reference/suppress_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Suppress confidential values in summary table — suppress_table","text":"check check table containing suppression conditions. output summary table edited based check table. value_var String, value variable name(s). group String, grouping variable name(s). includes `period` `facet_by` summary function. rule String, confidentiality rule apply. rule = \"n\"  suppresses values containing fewer n vessels. rule = \"k\" ( \"majority allocation rule\") suppresses values single vessel contains  k percent total catch. type String, value used replace confidential data. \"code\"  replaces values -999, \"NA\" (quotes) replaces  NA, \"zero\" replaces 0. as_vector Logical, whether return suppressed values vector. as_vector == FALSE output table returned.","code":""},{"path":"/reference/tables_database.html","id":null,"dir":"Reference","previous_headings":"","what":"View names of project tables — tables_database","title":"View names of project tables — tables_database","text":"Wrapper dbListTables. View names tables   project's FishSET database.","code":""},{"path":"/reference/tables_database.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View names of project tables — tables_database","text":"","code":"tables_database(project)"},{"path":"/reference/tables_database.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View names of project tables — tables_database","text":"project Project name","code":""},{"path":"/reference/tables_database.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View names of project tables — tables_database","text":"","code":"if (FALSE) { tables_database('pollock') }"},{"path":"/reference/table_exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if table exists in the FishSET database for the defined project — table_exists","title":"Check if table exists in the FishSET database for the defined project — table_exists","text":"Wrapper dbExistsTable. Check table    exists FishSET database.","code":""},{"path":"/reference/table_exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if table exists in the FishSET database for the defined project — table_exists","text":"","code":"table_exists(table, project)"},{"path":"/reference/table_exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if table exists in the FishSET database for the defined project — table_exists","text":"table Name table FishSET database.Table name must quotes. project Name project","code":""},{"path":"/reference/table_exists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if table exists in the FishSET database for the defined project — table_exists","text":"Returns logical statement table existence.","code":""},{"path":"/reference/table_exists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if table exists in the FishSET database for the defined project — table_exists","text":"","code":"if (FALSE) { table_exists('pollockMainDataTable', 'pollock') }"},{"path":"/reference/table_fields.html","id":null,"dir":"Reference","previous_headings":"","what":"Lists fields for FishSET database table — table_fields","title":"Lists fields for FishSET database table — table_fields","text":"Wrapper dbListFields.  View fields selected table.","code":""},{"path":"/reference/table_fields.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lists fields for FishSET database table — table_fields","text":"","code":"table_fields(table, project)"},{"path":"/reference/table_fields.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lists fields for FishSET database table — table_fields","text":"table String, name table FishSET database. Table name must quotes. project Project name","code":""},{"path":"/reference/table_fields.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lists fields for FishSET database table — table_fields","text":"","code":"if (FALSE) { table_fields('pollockMainDataTable', 'pollock') }"},{"path":"/reference/table_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Import and format saved tables to notebook file — table_format","title":"Import and format saved tables to notebook file — table_format","text":"Import format saved tables notebook file","code":""},{"path":"/reference/table_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import and format saved tables to notebook file — table_format","text":"","code":"table_format(x, project)"},{"path":"/reference/table_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import and format saved tables to notebook file — table_format","text":"x Name table saved output project project name","code":""},{"path":[]},{"path":"/reference/table_format.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import and format saved tables to notebook file — table_format","text":"","code":"if (FALSE) { table_format(\"pollock_species_catch_2020-05-29.csv\", 'pollock') table_format(pull_output(\"pollock\", \"species_catch\", type = \"table\"), 'pollock') }"},{"path":"/reference/table_remove.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove table from FishSET database — table_remove","title":"Remove table from FishSET database — table_remove","text":"Wrapper dbRemoveTable. Remove table FishSET database.","code":""},{"path":"/reference/table_remove.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove table from FishSET database — table_remove","text":"","code":"table_remove(table, project)"},{"path":"/reference/table_remove.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove table from FishSET database — table_remove","text":"table String, name table FishSET database. Table name must quotes. project Name project","code":""},{"path":"/reference/table_remove.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove table from FishSET database — table_remove","text":"Function utilizes sql functions remove tables FishSET database.","code":""},{"path":"/reference/table_remove.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove table from FishSET database — table_remove","text":"","code":"if (FALSE) { table_remove('pollockMainDataTable', 'pollock') }"},{"path":"/reference/table_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Save an existing FishSET DB table — table_save","title":"Save an existing FishSET DB table — table_save","text":"table_save() updates existing FishSET DB tables. table exist, user reminded use appropriate load_ function.","code":""},{"path":"/reference/table_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save an existing FishSET DB table — table_save","text":"","code":"table_save(table, project, type, name = NULL)"},{"path":"/reference/table_save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save an existing FishSET DB table — table_save","text":"table dataframe save FishSET Database. project Name project. type table type. Options include, \"main\" main data tables, \"port\" port tables, \"grid\" gridded tables, \"aux\" auxiliary tables. name String, table name. Applicable gridded, auxiliary, spatial tables.","code":""},{"path":"/reference/table_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect table type — table_type","title":"Detect table type — table_type","text":"Detect table type","code":""},{"path":"/reference/table_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect table type — table_type","text":"","code":"table_type(tab)"},{"path":"/reference/table_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect table type — table_type","text":"tab FishSET table.","code":""},{"path":"/reference/table_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect table type — table_type","text":"","code":"if (FALSE) { table_type(pollockMainDataTable) # returns \"main\" }"},{"path":"/reference/table_view.html","id":null,"dir":"Reference","previous_headings":"","what":"View FishSET Database table — table_view","title":"View FishSET Database table — table_view","text":"Wrapper dbGetQuery. View call    selected table FishSET database.","code":""},{"path":"/reference/table_view.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View FishSET Database table — table_view","text":"","code":"table_view(table, project)"},{"path":"/reference/table_view.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View FishSET Database table — table_view","text":"table String, name table FishSET database. Table name must quotes. project Name project.","code":""},{"path":"/reference/table_view.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"View FishSET Database table — table_view","text":"table_view() returns table project's FishSET Database.","code":""},{"path":[]},{"path":"/reference/table_view.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View FishSET Database table — table_view","text":"","code":"if (FALSE) { head(table_view('pollockMainDataTable', project = 'pollock')) }"},{"path":"/reference/temporal_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform units of date variables — temporal_mod","title":"Transform units of date variables — temporal_mod","text":"Creates new temporal variable extracting temporal unit, year, month, day date variable.","code":""},{"path":"/reference/temporal_mod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform units of date variables — temporal_mod","text":"","code":"temporal_mod(   dat,   project,   x,   define.format = NULL,   timezone = NULL,   name = NULL,   log_fun = TRUE,   ... )"},{"path":"/reference/temporal_mod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform units of date variables — temporal_mod","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project Project name. x Time variable modify dat. define.format Format temporal data. define.format NULL converting timezone x   changing format. Format can user-defined pre-defined choices. Format follows .Date format. See Details information. timezone String, defaults NULL. Returns date-time specified time zone.  Must recognizable timezone, \"UTC\", \"America/New_York\", \"Europe/Amsterdam\". name String, name created variables. Defaults `TempMod`. log_fun Logical, whether log function call (internal use). ... Additional arguments. Use tz='' specify time zone.","code":""},{"path":"/reference/temporal_mod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform units of date variables — temporal_mod","text":"Primary data set new variable added.","code":""},{"path":"/reference/temporal_mod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transform units of date variables — temporal_mod","text":"Converts date variable desired timezone units using .Date. date_parser also called ensure date variable acceptable format .Date.  define.format defines format variable take . Examples include \"%Y%m%d\", \"%Y-%m-%d %H:%M:%S\".    Users can define format use one predefined ones. Hours 0-23.     return list time-zone name Olson/IANA database paste OlsonNames() console. year: Takes format \"%Y\" returns year. month: Takes format \"%Y/%m\" returns year month. day: Takes format \"%Y/%m/%d\" returns year, month, day. hour: Takes format \"%Y/%m/%d %H\" returns year, month, day hour. minute: Takes format \"%Y/%m/%d %H:%M\" returns year, month, day, hour, minute. information formats, see https://www.stat.berkeley.edu/~s133/dates.html.","code":""},{"path":"/reference/temporal_mod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform units of date variables — temporal_mod","text":"","code":"if (FALSE) { pcodMainDataTable <- temporal_mod(pcodMainDataTable, \"pcod\",     \"DATE_LANDED\", define.format = \"%Y%m%d\") pcodMainDataTable <- temporal_mod(pcodMainDataTable, \"pcod\",     \"DATE_LANDED\", define.format = \"year\") }   # Change to Year, month, day, minutes"},{"path":"/reference/temp_obs_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of observations by temporal unit — temp_obs_table","title":"Number of observations by temporal unit — temp_obs_table","text":"View number observations year, month, zone table format","code":""},{"path":"/reference/temp_obs_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of observations by temporal unit — temp_obs_table","text":"","code":"temp_obs_table(   dat,   project,   x,   zoneid = NULL,   spat = NULL,   lon.dat = NULL,   lat.dat = NULL,   cat = NULL,   lon.spat = NULL,   lat.spat = NULL )"},{"path":"/reference/temp_obs_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of observations by temporal unit — temp_obs_table","text":"dat Primary data containing information hauls trips.  Table FishSET database contains string 'MainDataTable'. project String, name project. x Variable dat containing date variable. zoneid Variable dat identifies individual zones areas. Defaults NULL. Define  name zone identifier variable `ZoneID`. spat Spatial data containing information fishery management regulatory zones. Shape, json, geojson, csv formats supported. Required zoneid exist dat. lon.dat Longitude variable dat. Required zoneid exist dat. lat.dat Latitude variable dat. Required zoneid exist dat. cat Variable list spat identifies individual areas zones. spat class sf, cat name list containing information zones. Required zoneid exist dat. lon.spat Variable list spat containing longitude data. Required zoneid exist dat spat csv file. Leave NULL spat shape json file. lat.spat Variable list spat containing latitude data. Required zoneid exist dat spat csv file. Leave NULL spat shape json file.","code":""},{"path":"/reference/temp_obs_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Number of observations by temporal unit — temp_obs_table","text":"Prints tables displaying number observations year, month, zone. assignment_column called assign observations zones zoneid exist dat. Output saved.","code":""},{"path":"/reference/temp_obs_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of observations by temporal unit — temp_obs_table","text":"","code":"if (FALSE) { temp_obs_table(pollockMainDataTable, spat = map2, x = \"DATE_FISHING_BEGAN\",   lon.dat = \"LonLat_START_LON\", lat.dat = \"LonLat_START_LAT\", cat = \"NMFS_AREA\",   lon.spat = \"\", lat.spat = \"\"   ) }"},{"path":"/reference/temp_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot variable by month/year — temp_plot","title":"Plot variable by month/year — temp_plot","text":"Returns three plots showing variable interest time    (month month/year). Plots raw points date, number observations    date, measures representative observation date.","code":""},{"path":"/reference/temp_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot variable by month/year — temp_plot","text":"","code":"temp_plot(   dat,   project,   var.select,   len.fun = \"length\",   agg.fun = \"mean\",   date.var = NULL,   alpha = 0.5,   pages = \"single\",   text.size = 8 )"},{"path":"/reference/temp_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot variable by month/year — temp_plot","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. var.select Variable dat plot date variable. len.fun Method, \"length\" returns number observations,  \"unique\" returns number unique observations, \"percent\" returns percentage total observations. agg.fun Method aggregate var.select date. Choices  \"mean\", \"median\", \"min\", \"max\", \"sum\". date.var Date variable dat. Defaults first date variable  dat set defined. alpha opaqueness data point scatterplot. 0 total  transparency 1 total opaqueness.  Defaults .5. pages Whether output plots single page (\"single\",  default) multiple pages (\"multi\"). text.size Text size x-axes.","code":""},{"path":"/reference/temp_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot variable by month/year — temp_plot","text":"Returns plot R console saves output Output folder.","code":""},{"path":"/reference/temp_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot variable by month/year — temp_plot","text":"Returns three plots showing variable interest time (month  month/year). Plots raw points time, number observations time,  aggregated variable interest time.","code":""},{"path":"/reference/temp_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot variable by month/year — temp_plot","text":"","code":"if (FALSE) { temp_plot(pollockMainDataTable, project='pollock',            var.select = 'OFFICIAL_TOTAL_CATCH_MT', len.fun = 'percent',            agg.fun = 'mean', date.var = 'HAUL_DATE')            temp_plot(pollockMainDataTable, project='pollock',            var.select = 'OFFICIAL_TOTAL_CATCH_MT', len.fun = 'length',           agg.fun = 'max') }"},{"path":"/reference/temp_plot_helper.html","id":null,"dir":"Reference","previous_headings":"","what":"plot help function for spatial plots — temp_plot_helper","title":"plot help function for spatial plots — temp_plot_helper","text":"plot help function spatial plots","code":""},{"path":"/reference/temp_plot_helper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot help function for spatial plots — temp_plot_helper","text":"","code":"temp_plot_helper(   dataset,   len_df,   agg_df,   var.select,   date.var,   agg_per,   len.fun,   agg.fun,   plot_by_yr,   alpha,   pages,   text.size )"},{"path":"/reference/temp_plot_helper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot help function for spatial plots — temp_plot_helper","text":"dataset dataset name len_df length bar plot agg_df aggregation plot var.select variable date.var date variable agg_per character len.fun length, unique, percent agg.fun aggregation function plot_by_yr Whether plot year. alpha transparency data points. pages Whether output plots single page (\"single\",  default) multiple pages (\"multi\"). text.size Text size x-axes.","code":""},{"path":"/reference/temp_plot_helper.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"plot help function for spatial plots — temp_plot_helper","text":"Used temp_plot","code":""},{"path":"/reference/tenMNSQR.html","id":null,"dir":"Reference","previous_headings":"","what":"Northeast Ten Minute Squares — tenMNSQR","title":"Northeast Ten Minute Squares — tenMNSQR","text":"Northeast Ten Minute Squares","code":""},{"path":"/reference/tenMNSQR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Northeast Ten Minute Squares — tenMNSQR","text":"","code":"tenMNSQR"},{"path":"/reference/tenMNSQR.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Northeast Ten Minute Squares — tenMNSQR","text":"`tenMNSQR` simple feature COLLECTION 5267 features 9 fields: AREA  PERIMETER  TEN_  TEN_ID  LL  LAT  LON  TEMP  LOC","code":""},{"path":"/reference/text_filepath.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a filepath for a .txt document in the output folder — text_filepath","title":"Create a filepath for a .txt document in the output folder — text_filepath","text":"Create filepath .txt document output folder","code":""},{"path":"/reference/text_filepath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a filepath for a .txt document in the output folder — text_filepath","text":"","code":"text_filepath(project, fun_name)"},{"path":"/reference/text_filepath.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a filepath for a .txt document in the output folder — text_filepath","text":"project Name project. fun_name Name function.","code":""},{"path":"/reference/text_filepath.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a filepath for a .txt document in the output folder — text_filepath","text":"Useful saving messages generated functions.","code":""},{"path":"/reference/text_filepath.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a filepath for a .txt document in the output folder — text_filepath","text":"","code":"if (FALSE) { cat(\"message\", file = text_filepath(\"my_project\", \"qaqc_output\")) }"},{"path":"/reference/to_html_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert dataframe/matrix to html table — to_html_table","title":"Convert dataframe/matrix to html table — to_html_table","text":"Convert dataframe/matrix html table","code":""},{"path":"/reference/to_html_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert dataframe/matrix to html table — to_html_table","text":"","code":"to_html_table(x, rownames = FALSE, ...)"},{"path":"/reference/to_html_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert dataframe/matrix to html table — to_html_table","text":"x vector list object. rownames Logical, whether show rownames. ... Arguments pass shiny::renderTable","code":""},{"path":"/reference/to_html_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert dataframe/matrix to html table — to_html_table","text":"Returns HTML table (object matrix dataframe)   original object unmodified.","code":""},{"path":"/reference/trim_space.html","id":null,"dir":"Reference","previous_headings":"","what":"trim space function — trim_space","title":"trim space function — trim_space","text":"trim space function","code":""},{"path":"/reference/trim_space.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"trim space function — trim_space","text":"","code":"trim_space(   x,   what = c(\"both\", \"leading\", \"trailing\", \"none\"),   space.regex = \"[:space:]\",   ... )"},{"path":"/reference/trim_space.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"trim space function — trim_space","text":"x variable interest Choices , leading, trailing, none space.regex Default set [:space:] ... Additional arguments","code":""},{"path":"/reference/trip_duration_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Trip duration plot helper — trip_duration_plot","title":"Trip duration plot helper — trip_duration_plot","text":"Creates formats plots trip_dur_out.","code":""},{"path":"/reference/trip_duration_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trip duration plot helper — trip_duration_plot","text":"","code":"trip_duration_plot(   trip_tab,   trp_nms,   vpue,   group,   facet_by,   units,   type,   dens,   bins,   tran,   format_lab,   scale,   combine,   pages )"},{"path":"/reference/trip_duration_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trip duration plot helper — trip_duration_plot","text":"trip_tab Dataframe passed trip_dur_out. trp_nms Column names trip length vpue variables. vpue Column names vpue variable(s). group Column names grouping variable(s). facet_by Column names facet variable(s). units Units trip length. type Whether histogram frequency polygon plotted. dens Logical, whether calculate density TRUE frequency FALSE. bins Numeric, number bins sort variables . tran Transformation applied x-axis. format_lab Formatting option x-axis labels. Options include  \"decimal\" \"scientific\". scale Scale argument passed facet_grid. combine Logical, whether grouping variables combined. pages Whether output plots single page (\"single\",  default) multiple pages (\"multi\").","code":""},{"path":"/reference/trip_dur_out.html","id":null,"dir":"Reference","previous_headings":"","what":"Trip duration table and plot — trip_dur_out","title":"Trip duration table and plot — trip_dur_out","text":"Display trip duration value per unit effort","code":""},{"path":"/reference/trip_dur_out.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trip duration table and plot — trip_dur_out","text":"","code":"trip_dur_out(   dat,   project,   start,   end,   units = \"days\",   vpue = NULL,   group = NULL,   combine = TRUE,   haul_count = TRUE,   sub_date = NULL,   filter_date = NULL,   date_value = NULL,   filter_by = NULL,   filter_value = NULL,   filter_expr = NULL,   facet_by = NULL,   type = \"hist\",   bins = 30,   density = TRUE,   scale = \"fixed\",   tran = \"identity\",   format_lab = \"decimal\",   pages = \"single\",   remove_neg = FALSE,   output = \"tab_plot\",   tripID = NULL,   fun.time = NULL,   fun.numeric = NULL )"},{"path":"/reference/trip_dur_out.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trip duration table and plot — trip_dur_out","text":"dat Primary data containing information hauls trips. Table FishSET database contain string `MainDataTable`. project String, name project. start Date variable containing start vessel trip. end Date variable containing end vessel trip. units Time unit, defaults \"days\". Options include \"secs\", \"mins\", \"hours\", \"days\", \"weeks\". vpue Optional, numeric variable dat calculating value per  unit effort (VPUE). group Optional, string names variables group . default,  grouping variables combined unless combine = FALSE  type = \"freq_poly\" (frequency polygon). combine = TRUE  work type = \"hist\" (histogram). Frequency polygon plots can use  two grouping variables combine = FALSE: first variable  assigned \"color\" aesthetic second \"linetype\" aesthetic. combine Logical, whether combine variables listed group  plot. haul_count Logical, whether include hauls per trip table /plot  (can used collapsing data trip level using tripID.  data already trip level, add haul frequency variable vpue). sub_date Date variable used subsetting, grouping, splitting date. filter_date type filter apply `MainDataTable`. filter  range dates, use filter_date = \"date_range\". filter given period, use \"year-day\", \"year-week\", \"year-month\", \"year\", \"month\", \"week\",  \"day\". argument date_value must provided. date_value argument paired filter_date. filter date range, set filter_date = \"date_range\" enter  start-  end-date date_value string:  date_value = c(\"2011-01-01\", \"2011-03-15\"). filter period (e.g. \"year\", \"year-month\"), use integers (4 digits year, 1-2  digits referencing day, month, week). Use vector filtering  single period: date_filter = \"month\" date_value = c(1, 3, 5).  filter data January, March, May. Use list using year-period type filter, e.g. \"year-week\",  format: list(year, period). example, filter_date = \"year-month\" date_value = list(2011:2013, 5:7) filter data table  May July years 2011-2013. filter_by String, variable name filter `MainDataTable` . argument  filter_value must provided. filter_value vector values filter `MainDataTable` using  variable filter_by. example, filter_by = \"GEAR_TYPE\",  filter_value = 1 include observations gear type 1. filter_expr String, valid R expression filter `MainDataTable` . facet_by Variable name facet . Facetting \"year\", \"month\",  \"week\" provided date variable added sub_date. type type plot. Options include histogram (\"hist\",  default) frequency polygon (\"freq_poly\"). bins number bins used histogram/freqency polygon. density Logical, whether densities frequencies used histogram.  Defaults  TRUE. scale Scale argument passed facet_grid. Defaults  \"fixed\". options include \"free_y\", \"free_x\",  \"free_xy\". tran Transformation applied x-axis. options include  \"log\", \"log10\", \"sqrt\". See  scale_continuous complete list. format_lab Formatting option x-axis labels. Options include  \"decimal\" \"scientific\". pages Whether output plots single page (\"single\",  default) multiple pages (\"multi\"). remove_neg Logical, whether remove negative trip durations  plot table. output Options include 'table', 'plot', 'tab_plot' (table  plot, default). tripID Column(s) identify individual trip. fun.time collapse temporal data. example, min,  mean, max. sum temporal variables. fun.numeric collapse numeric temporal data. example,  min, mean, max, sum. Defaults mean.","code":""},{"path":"/reference/trip_dur_out.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trip duration table and plot — trip_dur_out","text":"trip_dur_out() calculates vessel trip duration given start end date,   converts trip duration desired unit time (e.g. weeks, days, hours),   returns table /plot. option calculating vpue (value    per unit effort) well. data can filtered date /variable.  filter_date specifies type date filter apply--date-range   period. date_value contain values filter data . filter    variable, enter name string filter_by include values    filter filter_value. multiple grouping variables given    combined one variable  unless combine = FALSE  type = \"freq_poly\". three grouping variables recommended    pages = \"single\". variable dataset can used faceting,    \"year\", \"month\", \"week\" also available. Distribution plots can    combined single page printed individually pages.","code":""},{"path":[]},{"path":"/reference/trip_dur_out.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trip duration table and plot — trip_dur_out","text":"","code":"if (FALSE) { trip_dur_out(pollockMainDataTable,   start = \"FISHING_START_DATE\", end = \"HAUL_DATE\",   units = \"days\", vpue = \"OFFICIAL_TOTAL_CATCH\", output = \"plot\",   tripID = c(\"PERMIT\", \"TRIP_SEQ\"), fun.numeric = sum, fun.time = min )  }"},{"path":"/reference/unique_closure.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for unique closure scenarios — unique_closure","title":"Check for unique closure scenarios — unique_closure","text":"Check unique closure scenarios","code":""},{"path":"/reference/unique_closure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for unique closure scenarios — unique_closure","text":"","code":"unique_closure(project, c_list, ind = TRUE)"},{"path":"/reference/unique_closure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for unique closure scenarios — unique_closure","text":"project Name project c_list List closure scenarios check. ind Logical, whether return index unique closure scenarios c_list single TRUE/FALSE value indicating one closure scenarios unique.","code":""},{"path":"/reference/unique_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Check rows are unique — unique_filter","title":"Check rows are unique — unique_filter","text":"Check remove non-unique rows primary dataset.","code":""},{"path":"/reference/unique_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check rows are unique — unique_filter","text":"","code":"unique_filter(dat, project, remove = FALSE)"},{"path":"/reference/unique_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check rows are unique — unique_filter","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. remove Logical, TRUE removes non-unique rows. Defaults  FALSE.","code":""},{"path":"/reference/unique_filter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check rows are unique — unique_filter","text":"Returns modified primary dataset non-unique rows removed  remove = TRUE.","code":""},{"path":"/reference/unique_filter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check rows are unique — unique_filter","text":"Output determined remove. remove = TRUE non-unique rows removed. remove = FALSE statement returned regarding number rows unique.","code":""},{"path":"/reference/unique_filter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check rows are unique — unique_filter","text":"","code":"if (FALSE) { # check for unique rows unique_filter(pollockMainDataTable)  # remove non-unique rows from dataset mod.dat <- unique_filter(pollockMainDataTable, remove = TRUE) }"},{"path":"/reference/unique_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for unique grid files — unique_grid","title":"Check for unique grid files — unique_grid","text":"function determines whether grid file saved project data folder based values grid_info. match found,  indicating identical grid file already saved, deleted. match found grid file saved.","code":""},{"path":"/reference/unique_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for unique grid files — unique_grid","text":"","code":"unique_grid(project, grid_info, ind = TRUE)"},{"path":"/reference/unique_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for unique grid files — unique_grid","text":"project Name project. grid_info List grid characteristics used determine whether grid saved project data folder. ind Logical, whether return index unique grid return  single logical value.","code":""},{"path":"/reference/unique_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for unique grid files — unique_grid","text":"TRUE grid unique (.e. matches current   grid log).","code":""},{"path":"/reference/unique_rows.html","id":null,"dir":"Reference","previous_headings":"","what":"Return unique rows — unique_rows","title":"Return unique rows — unique_rows","text":"Check whether rows dataset unique. , returns unique rows.","code":""},{"path":"/reference/unique_rows.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return unique rows — unique_rows","text":"","code":"unique_rows(dat)"},{"path":"/reference/unique_rows.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return unique rows — unique_rows","text":"dat Data check non-unique rows.","code":""},{"path":"/reference/unique_rows.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return unique rows — unique_rows","text":"","code":"if (FALSE) { dat <- unique_rows(dat) }"},{"path":"/reference/unserialize_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Unserialize special tables in FishSET DB — unserialize_table","title":"Unserialize special tables in FishSET DB — unserialize_table","text":"Unserialize special tables FishSET DB","code":""},{"path":"/reference/unserialize_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unserialize special tables in FishSET DB — unserialize_table","text":"","code":"unserialize_table(table, project)"},{"path":"/reference/unserialize_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unserialize special tables in FishSET DB — unserialize_table","text":"table name special table unserialize. Special tables include alternative choice matrix output, expected catch matrix output, model data list, prediction output. project Name project.","code":""},{"path":"/reference/update_folderpath.html","id":null,"dir":"Reference","previous_headings":"","what":"Update FishSETFolder location — update_folderpath","title":"Update FishSETFolder location — update_folderpath","text":"Select location FishSET folder. can helpful  switching different FishSET folders 'folderpath'  inaccurate.","code":""},{"path":"/reference/update_folderpath.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update FishSETFolder location — update_folderpath","text":"","code":"update_folderpath()"},{"path":"/reference/use_prompter.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper for prompter::use_prompt() — use_prompter","title":"Wrapper for prompter::use_prompt() — use_prompter","text":"Wrapper prompter::use_prompt()","code":""},{"path":"/reference/use_prompter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper for prompter::use_prompt() — use_prompter","text":"","code":"use_prompter()"},{"path":"/reference/vessel_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize active vessels — vessel_count","title":"Summarize active vessels — vessel_count","text":"vessel_count counts number active vessels main table. can summarize period date provided, group number  grouping variables, filter period value. several options  customizing table/plot output.","code":""},{"path":"/reference/vessel_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize active vessels — vessel_count","text":"","code":"vessel_count(   dat,   project,   v_id,   date = NULL,   period = NULL,   group = NULL,   sub_date = NULL,   filter_date = NULL,   date_value = NULL,   filter_by = NULL,   filter_value = NULL,   filter_expr = NULL,   facet_by = NULL,   combine = FALSE,   position = \"stack\",   tran = \"identity\",   format_lab = \"decimal\",   value = \"count\",   type = \"bar\",   scale = \"fixed\",   output = \"tab_plot\" )"},{"path":"/reference/vessel_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize active vessels — vessel_count","text":"dat Primary data containing information hauls trips.  Table FishSET database contains string 'MainDataTable'. project String, name project. v_id Variable dat containing vessel identifier count. date Date variable aggregate . period Time period aggregate . Options include \"year\",  \"month\", \"week\" (weeks year), \"weekday\",  \"weekday_abv\", \"day_of_month\", \"day_of_year\",  \"cal_date\" (calender date). group Names grouping variables. line plots (type = \"line\") two grouping variables can entered, first passed \"color\" second  \"linetype\". one grouping variable can used barplots  (type = \"bar\"), passed \"fill\". combine = TRUE  variables group joined. Grouping \"year\",  \"month\", \"week\" available date variable added  sub_date. sub_date Date variable used subsetting, grouping, splitting date. filter_date type filter apply `MainDataTable`. filter  range dates, use filter_date = \"date_range\". filter  given period, use \"year-day\", \"year-week\", \"year-month\", \"year\", \"month\",  \"week\", \"day\". argument date_value must provided. date_value argument paired filter_date. filter date range, set filter_date = \"date_range\" enter  start-  end-date date_value string:  date_value = c(\"2011-01-01\", \"2011-03-15\"). filter period (e.g. \"year\", \"year-month\"), use integers (4 digits year, 1-2  digits referencing day, month, week). Use vector filtering  single period: date_filter = \"month\" date_value = c(1, 3, 5).  filter data January, March, May. Use list using year-period type filter, e.g. \"year-week\",  format: list(year, period). example, filter_date = \"year-month\" date_value = list(2011:2013, 5:7) filter data table  May July years 2011-2013. filter_by String, variable name filter `MainDataTable` . argument  filter_value must provided. filter_value vector values filter `MainDataTable` using  variable filter_by. example, filter_by = \"GEAR_TYPE\",  filter_value = 1 include observations gear type 1. filter_expr String, valid R expression filter `MainDataTable`  using variable filter_by. facet_by Variable name facet . Accepts two variables.  can variables exist dat, variable created  vessel_count() \"year\", \"month\", \"week\"  date variable added sub_date. first variable facetted  row second column. combine Whether combine variables listed group. passed \"fill\" \"color\" aesthetic plots. position Positioning bar plot. Options include 'stack', 'dodge',  'fill'. tran function transform y-axis. Options include log, log2, log10,  sqrt. format_lab decimal scientific value Whether return \"count\" \"percent\" active  vessels. Defaults \"count\". type Plot type, options include \"bar\" (default) \"line\". scale Scale argument passed facet_grid.  Options include \"free\", \"free_x\", \"free_y\". Defaults  \"fixed\". output Whether display \"plot\", \"table\". Defaults  (\"tab_plot\").","code":""},{"path":"/reference/vessel_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize active vessels — vessel_count","text":"output = \"tab_plot\" list containing table plot   returned. output = \"table\" summary table returned,  output = \"plot\" plot.","code":""},{"path":"/reference/vessel_count.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize active vessels — vessel_count","text":"vessel_count gives number (percent) active vessels   using column unique vessel IDs. data can filtered date /   variable. (console users may want use separate filtering function,    like dplyr::filter, running vessel_count: note    okay lead different output using log_rerun).   filter_date specifies type date filter apply--date-range   period. date_value contain values filter data .    filter variable, enter name string filter_by   include values filter filter_value. two grouping variables can entered. Grouping variables can merged    one variable using combine = TRUE; case number variables    can joined, three recommended. faceting, variable (including ones listed group) can used,    \"year\", \"month\", \"week\" also available provided date variable    added sub_date. Currently, combined variables faceted.","code":""},{"path":"/reference/vessel_count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize active vessels — vessel_count","text":"","code":"if (FALSE) { # grouping by two variables vessel_count(pollockMainDataTable, v_id = \"VESSEL_ID\",               group = c(\"GEAR_TYPE\", \"IFQ\"))               # filter by variable vessel_count(pollockMainDataTable, v_id = \"VESSEL_ID\", group = \"GEAR_TYPE\",              filter_by = \"IFQ\", filter_value = \"Y\")               # filter by month vessel_count(pollockMainDataTable, v_id = \"VESSEL_ID\", group = \"GEAR_TYPE\",              sub_date = \"HAUL_DATE\", date_filter = \"month\", date_value = 1:5)               #' # filter by date vessel_count(pollockMainDataTable, v_id = \"VESSEL_ID\", group = \"GEAR_TYPE\",              sub_date = \"HAUL_DATE\", date_filter = \"date_range\",               date_value = c(\"2011-01-01\", \"2011-02-05\"))  # summarize by month vessel_count(pollockMainDataTable, v_id = 'VESSEL_ID', date = 'DATE_FISHING_BEGAN',               period = 'month', group = 'DISEMBARKED_PORT', position = 'dodge',               output = 'plot') }"},{"path":"/reference/vgsub.html","id":null,"dir":"Reference","previous_headings":"","what":"vgsub function — vgsub","title":"vgsub function — vgsub","text":"vgsub function","code":""},{"path":"/reference/vgsub.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"vgsub function — vgsub","text":"","code":"vgsub(pattern, replacement, x, ...)"},{"path":"/reference/vgsub.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"vgsub function — vgsub","text":"pattern pattern replacement replacement x x ... Additional arguments","code":""},{"path":"/reference/view_fleet_table.html","id":null,"dir":"Reference","previous_headings":"","what":"View the most recent fleet table by project — view_fleet_table","title":"View the most recent fleet table by project — view_fleet_table","text":"View recent fleet table project","code":""},{"path":"/reference/view_fleet_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View the most recent fleet table by project — view_fleet_table","text":"","code":"view_fleet_table(project)"},{"path":"/reference/view_fleet_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View the most recent fleet table by project — view_fleet_table","text":"project name project.","code":""},{"path":"/reference/view_fleet_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View the most recent fleet table by project — view_fleet_table","text":"","code":"if (FALSE) { view_fleet_table(\"pollock\") }"},{"path":"/reference/view_grid_dat.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize gridded data on a map — view_grid_dat","title":"Visualize gridded data on a map — view_grid_dat","text":"Visualize gridded data map","code":""},{"path":"/reference/view_grid_dat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize gridded data on a map — view_grid_dat","text":"","code":"view_grid_dat(   grid,   project,   lon,   lat,   value,   split_by = NULL,   group = NULL,   agg_fun = \"mean\" )"},{"path":"/reference/view_grid_dat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize gridded data on a map — view_grid_dat","text":"grid Gridded data table visualize. Use string visualizing  gridded data table FishSET Database. project String, project name. lon String, variable name containing longitude. lat String, variable name containing latitude. value String, variable name containing gridded values, e.g. sea surface  temperature, wind speed, etc. split_by String, variable gridded data table split . group String, variable gridded data table group value . addition variable(s) group, value also  aggregated longitude-latitude pair. string \"lonlat\"  shortcut group = c(\"lon\", \"lat\") aggregates value  longitude-latitude pair across entire dataset. agg_fun Aggregating function applied group. Defaults mean.","code":""},{"path":"/reference/view_lon_lat.html","id":null,"dir":"Reference","previous_headings":"","what":"View — view_lon_lat","title":"View — view_lon_lat","text":"View","code":""},{"path":"/reference/view_lon_lat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View — view_lon_lat","text":"","code":"view_lon_lat(dat, lon, lat, id = NULL, crs = 4326)"},{"path":"/reference/view_lon_lat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View — view_lon_lat","text":"dat Data containing lon lat columns. lon Name Longitude column. lat Name Lattitude column. id Optional, name ID variable paired lon  lat columns crs Optional, coordinate reference system use. Defaults EPSG code 4326 (WGS 84).","code":""},{"path":"/reference/view_model_design.html","id":null,"dir":"Reference","previous_headings":"","what":"View model design file in database — view_model_design","title":"View model design file in database — view_model_design","text":"View model design file database","code":""},{"path":"/reference/view_model_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View model design file in database — view_model_design","text":"","code":"view_model_design(project, date = NULL)"},{"path":"/reference/view_model_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View model design file in database — view_model_design","text":"project Project name. date String, date model design file created.","code":""},{"path":"/reference/view_spat.html","id":null,"dir":"Reference","previous_headings":"","what":"View interactive map of spatial data — view_spat","title":"View interactive map of spatial data — view_spat","text":"View interactive map spatial data","code":""},{"path":"/reference/view_spat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View interactive map of spatial data — view_spat","text":"","code":"view_spat(spat, id = NULL, type = \"polygon\")"},{"path":"/reference/view_spat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View interactive map of spatial data — view_spat","text":"spat Spatial dataset view. Must object class sf  sfc. id Optional, name spatial ID column view spatial data. type Can \"polygon\", \"line\", \"point\".","code":""},{"path":"/reference/view_spat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View interactive map of spatial data — view_spat","text":"","code":"if (FALSE) { view_spat(pollockNMFSSpatTable, id = \"NMFS_AREA\") }"},{"path":"/reference/weekly_catch.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize weekly catch — weekly_catch","title":"Summarize weekly catch — weekly_catch","text":"weekly_catch summarizes catch (numeric variables) main table week. can summarize grouping variables filter period  value. several options customizing table plot output.","code":""},{"path":"/reference/weekly_catch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize weekly catch — weekly_catch","text":"","code":"weekly_catch(   dat,   project,   species,   date,   fun = \"sum\",   group = NULL,   sub_date = NULL,   filter_date = NULL,   date_value = NULL,   filter_by = NULL,   filter_value = NULL,   filter_expr = NULL,   facet_by = NULL,   type = \"bar\",   conv = \"none\",   tran = \"identity\",   format_lab = \"decimal\",   value = \"count\",   position = \"stack\",   combine = FALSE,   scale = \"fixed\",   output = \"tab_plot\",   format_tab = \"wide\" )"},{"path":"/reference/weekly_catch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize weekly catch — weekly_catch","text":"dat Primary data containing information hauls trips.  Table FishSET database contains string 'MainDataTable'. project String, name project. species variable dat containing species catch vector species variables. date Variable dat containing dates aggregate . fun Name function aggregate . Defaults sum. group Grouping variable names(s). two grouping variables available line plots one bar plots. bar plots, one species entered first group variable passed \"fill\". multiple species entered, species passed \"fill\" grouping variable dropped. exception occurs faceting species, grouping variable passed \"fill\". line plots, first grouping variable passed \"fill\" second \"linetype\" single species column entered faceting species. Otherwise, species passed \"fill\", first group variable \"linetype\", second dropped. sub_date Date variable used subsetting, grouping, splitting date. filter_date type filter apply `MainDataTable`. filter  range dates, use filter_date = \"date_range\". filter given period, use \"year-day\", \"year-week\", \"year-month\", \"year\", \"month\", \"week\", \"day\".  argument date_value must provided. date_value argument paired filter_date. filter date range, set filter_date = \"date_range\" enter  start-  end-date date_value string:  date_value = c(\"2011-01-01\", \"2011-03-15\"). filter period (e.g. \"year\", \"year-month\"), use integers (4 digits year, 1-2  digits referencing day, month, week). Use vector filtering  single period: date_filter = \"month\" date_value = c(1, 3, 5).  filter data January, March, May. Use list using year-period type filter, e.g. \"year-week\",  format: list(year, period). example, filter_date = \"year-month\" date_value = list(2011:2013, 5:7) filter data table  May July years 2011-2013. filter_by String, variable name filter `MainDataTable` . argument  filter_value must provided. filter_value vector values filter `MainDataTable` using variable  filter_by. example, filter_by = \"GEAR_TYPE\", filter_value = 1  include observations gear type 1. filter_expr String, valid R expression filter `MainDataTable` using variable  filter_by. facet_by Variable name facet . Accepts two variables. can  variables exist dataset, variable created species_catch()  \"year\", \"month\", \"week\" date variable added  sub_date. Facetting \"species\" available multiple catch columns  included \"species\". first variable facetted row second column. type Plot type, options include \"bar\" (default) \"line\". conv Convert catch variable \"tons\", \"metric_tons\",  using function entered string. Defaults \"none\" conversion. tran function transform y-axis. Options include log, log2, log10, sqrt. format_lab Formatting option y-axis labels. Options include  \"decimal\" \"scientific\". value Whether calculate raw \"count\" \"percent\" total catch. position Positioning bar plot. Options include 'stack', 'dodge',  'fill'. combine Whether combine variables listed group. passed \"fill\" \"color\" aesthetic plots. scale Scale argument passed facet_grid. Defaults \"fixed\". output Return output \"plot\", \"table\", \"tab_plot\". Defaults  (\"tab_plot\"). format_tab table output formatted. Options include 'wide'  (default) 'long'.","code":""},{"path":"/reference/weekly_catch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize weekly catch — weekly_catch","text":"weekly_catch() aggregates catch week using one columns    catch data. multiple catch variables entered, new column \"species\"    created used group values plots.    \"species\" column can also used split (facet) plot. table output,   \"species\" column kept format_tab = \"long\", .e. column   species names (\"species\") column containing catch (\"catch\").  format_tab = \"wide\", species given column catch.     data can filtered date /variable. filter_date specifies type date filter apply--date-range period.  date_value contain values filter data . filter    variable, enter name string filter_by include    values filter filter_value. two grouping variables can    entered. Grouping variables can merged one variable using combine;    case number variables can joined, three    recommended. faceting, variable (including ones listed group)    can used, \"year\", \"month\", \"week\" also available provided date    variable added sub_date. Currently, combined variables    faceted. list containing table plot printed console    viewer default.","code":""},{"path":"/reference/weekly_catch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize weekly catch — weekly_catch","text":"","code":"if (FALSE) { weekly_catch(pollockMainDataTable,   species = c(     \"HAUL_LBS_270_POLLOCK_LBS\",     \"HAUL_LBS_110_PACIFIC_COD_LBS\",  \"HAUL_LBS_OTHER_LBS\"   ), date = \"DATE_FISHING_BEGAN\",   conv = \"tons\", year = 2011, output = \"plot\" ) }"},{"path":"/reference/weekly_effort.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize average CPUE by week — weekly_effort","title":"Summarize average CPUE by week — weekly_effort","text":"weekly_effort summarizes CPUE (numeric variables) main table week. can summarize grouping variables filter period  value. several options customizing table plot output.","code":""},{"path":"/reference/weekly_effort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize average CPUE by week — weekly_effort","text":"","code":"weekly_effort(   dat,   project,   cpue,   date,   group = NULL,   sub_date = NULL,   filter_date = NULL,   date_value = NULL,   filter_by = NULL,   filter_value = NULL,   filter_expr = NULL,   facet_by = NULL,   conv = \"none\",   tran = \"identity\",   format_lab = \"decimal\",   combine = FALSE,   scale = \"fixed\",   output = \"tab_plot\",   format_tab = \"wide\" )"},{"path":"/reference/weekly_effort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize average CPUE by week — weekly_effort","text":"dat Primary data containing information hauls trips. Table FishSET database contains string 'MainDataTable'. project String, name project. cpue Variable(s) dat containing catch per unit effort. date variable dat containing dates aggregate . group Grouping variable name(s). two grouping variables available. plotting, single CPUE column entered first grouping variable  passed \"color\" aesthetic second \"linetype\". multiple CPUE columns entered, new variable named \"species\" created passed \"fill\",  first group variable \"linetype\", second dropped. sub_date Date variable used subsetting, grouping, splitting date. filter_date type filter apply `MainDataTable`. filter  range dates, use filter_date = \"date_range\". filter given period, use \"year-day\", \"year-week\", \"year-month\", \"year\", \"month\", \"week\", \"day\".  argument date_value must provided. date_value argument paired filter_date. filter date range, set filter_date = \"date_range\" enter  start-  end-date date_value string:  date_value = c(\"2011-01-01\", \"2011-03-15\"). filter period (e.g. \"year\", \"year-month\"), use integers (4 digits year, 1-2  digits referencing day, month, week). Use vector filtering  single period: date_filter = \"month\" date_value = c(1, 3, 5).  filter data January, March, May. Use list using year-period type filter, e.g. \"year-week\",  format: list(year, period). example, filter_date = \"year-month\" date_value = list(2011:2013, 5:7) filter data table  May July years 2011-2013. filter_by String, variable name filter `MainDataTable` . argument  filter_value must provided. filter_value vector values filter `MainDataTable` using  variable filter_by. example, filter_by = \"GEAR_TYPE\",  filter_value = 1 include observations gear type 1. filter_expr String, valid R expression filter `MainDataTable`  using variable filter_by. facet_by Variable name facet . Accepts two variables. Facetting  \"year\" available date variable added sub_date.  Facetting \"species\" available multiple cpue columns included  \"cpue\". first variable facetted row second column. conv Convert catch variable \"tons\", \"metric_tons\",  using function entered string. Defaults \"none\" conversion. tran function transform y-axis. Options include log, log2, log10,  sqrt. format_lab Formatting option y-axis labels. Options include  \"decimal\" \"scientific\". combine Whether combine variables listed group. passed \"color\" aesthetic plots. scale Scale argument passed facet_grid. Defaults  \"fixed\". output Whether display \"plot\", \"table\". Defaults  (\"tab_plot\"). format_tab table output formatted. Options include 'wide'  (default) 'long'.","code":""},{"path":"/reference/weekly_effort.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize average CPUE by week — weekly_effort","text":"weekly_effort() calculates mean CPUE week. function    calculate CPUE; CPUE variable must created advance (see cpue).   multiple CPUE variables entered, new column named \"species\"    created used group values plots.    \"species\" column can also used split (facet) plot. table output,   \"species\" column kept format_tab = \"long\", .e. column   species names (\"species\") column containing mean CPUE (\"mean_cpue\").  format_tab = \"wide\", CPUE variable given value column.     data can filtered date /variable. filter_date specifies type date filter apply--date-range period.  date_value contain values filter data . filter    variable, enter name string filter_by include    values filter filter_value. two grouping variables can    entered. Grouping variables can merged one variable using combine;    case number variables can joined, three    recommended. faceting, variable (including ones listed group)    can used, \"year\" \"species\" also available. Facetting \"year\" requires date    variable added sub_date. Currently, combined variables    faceted. list containing table plot printed console    viewer default.","code":""},{"path":"/reference/weekly_effort.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize average CPUE by week — weekly_effort","text":"","code":"if (FALSE) { weekly_effort(pollockMainDataTable, \"CPUE\", \"DATE_FISHING_BEGAN\", filter_date = \"year\",                date_value = 2011, output = \"table\") }"},{"path":"/reference/week_labeller.html","id":null,"dir":"Reference","previous_headings":"","what":"X-axis scale labeller for weekly data — week_labeller","title":"X-axis scale labeller for weekly data — week_labeller","text":"X-axis scale labeller weekly data","code":""},{"path":"/reference/week_labeller.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"X-axis scale labeller for weekly data — week_labeller","text":"","code":"week_labeller(breaks, year)"},{"path":"/reference/week_labeller.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"X-axis scale labeller for weekly data — week_labeller","text":"breaks scale label breaks year vector years summary table","code":""},{"path":"/reference/welfare_outputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Welfare plots and tables — welfare_outputs","title":"Welfare plots and tables — welfare_outputs","text":"Generate plots tables welfare simulations","code":""},{"path":"/reference/welfare_outputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Welfare plots and tables — welfare_outputs","text":"","code":"welfare_outputs(   project,   mod.name,   closures,   betadraws = 1000,   zone.dat = NULL,   group_var = NULL )"},{"path":"/reference/welfare_outputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Welfare plots and tables — welfare_outputs","text":"project Name project mod.name Model name. Argument can name model name  can pulled `modelChosen` table. Leave mod.name empty use  name saved `best` model. one model saved,  mod.name numeric indicator model use. Use table_view(\"modelChosen\", project) view table saved models. closures Closure scenarios betadraws Integer indicating numer times run welfare simulation. Default value betadraws = 1000 zone.dat Variable primary data table contains unique zone ID. group_var Categorical variable primary data table group welfare outputs.","code":""},{"path":"/reference/welfare_outputs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Welfare plots and tables — welfare_outputs","text":"Returns list (1) plot showing welfare loss/gain scenarios dollars, (2) plot showing welfare   loss/gain percentage, (3) dataframe welfare summary stats dollars, (4) dataframe welfare summary   stats percentages, (5) dataframe welfare details number trips, mean loss per trip, mean    total welfare loss across trips.","code":""},{"path":"/reference/welfare_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Welfare analysis — welfare_predict","title":"Welfare analysis — welfare_predict","text":"Simulate welfare loss/gain changes policy changes factors influence fisher  location choice.","code":""},{"path":"/reference/welfare_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Welfare analysis — welfare_predict","text":"","code":"welfare_predict(   project,   mod.name,   closures,   betadraws = 1000,   marg_util_income = NULL,   income_cost = NULL,   expected.catch = NULL,   enteredPrice = NULL )"},{"path":"/reference/welfare_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Welfare analysis — welfare_predict","text":"project Name project mod.name Name selected model (mchoice) closures Closure scenarios betadraws Integer indicating numer times run welfare simulation. Default value betadraws = 1000 marg_util_income conditional zonal logit models. Name coefficient use  marginal utility income income_cost conditional zonal logit models. Logical indicating whether coefficient  marginal utility income relates cost (TRUE) revenue (FALSE) expected.catch Name expectedchatch table use enteredPrice Price welfare","code":""},{"path":"/reference/welfare_predict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Welfare analysis — welfare_predict","text":"simulate welfare loss/gain, model coefficients sampled 1000 times using multivariate random    number generator (mvgrnd) welfare loss/gain observation calculated (see section 9.3     user manual) sampled coefficients, estimated welfare values saved file    project outputs folder.     Note function called run_policy.","code":""},{"path":"/reference/windLease.html","id":null,"dir":"Reference","previous_headings":"","what":"Northeast wind closure areas — windLease","title":"Northeast wind closure areas — windLease","text":"Northeast wind closure areas","code":""},{"path":"/reference/windLease.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Northeast wind closure areas — windLease","text":"","code":"windLease"},{"path":"/reference/windLease.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Northeast wind closure areas — windLease","text":"`windLease` Simple features collection 32 features 1 field: NAME Name wind lease.","code":""},{"path":"/reference/window_cc.html","id":null,"dir":"Reference","previous_headings":"","what":"Unique values window function — window_cc","title":"Unique values window function — window_cc","text":"Used roll_catch() count unique vessels within rolling window.","code":""},{"path":"/reference/window_cc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unique values window function — window_cc","text":"","code":"window_cc(x, k)"},{"path":"/reference/window_cc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unique values window function — window_cc","text":"x List vessel IDs count k Window width.","code":""},{"path":[]},{"path":"/reference/write_dat.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a data table to local file directory — write_dat","title":"Write a data table to local file directory — write_dat","text":"Write data table local file directory","code":""},{"path":"/reference/write_dat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a data table to local file directory — write_dat","text":"","code":"write_dat(dat, project, path = NULL, file_type = \"csv\", ...)"},{"path":"/reference/write_dat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a data table to local file directory — write_dat","text":"dat Name data frame working environment save file. project String, project name. path String, path connection write . left empty, file  written dat folder project directory. file_type String, type file write . Options include \"csv\", \"txt\" (tab-separated text file), \"xlsx\" (excel), \"rdata\",  \"json\", \"stata\", \"spss\", \"sas\", \"matlab\". ... Additional arguments passed writing function. See \"details\"  list functions.","code":""},{"path":"/reference/write_dat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write a data table to local file directory — write_dat","text":"Leave path = NULL save dat data folder  project directory See write.table  csv tab-separated files,     save R data files,     write.xlsx,    read_json json files,     st_write geojson files,    read_dta Stata files,     read_spss SPSS files,     read_sas SAS files,     writeMat Matlab files,    st_write shape files.","code":""},{"path":"/reference/write_dat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a data table to local file directory — write_dat","text":"","code":"if (FALSE) { # Save to the default data folder in project directory write_dat(pollockMainDataTable, type = \"csv\", \"pollock\")  # Save to defined directory location write_dat(pollockMainDataTable, path = \"C://data/pollock_dataset.csv\",            type = \"csv\", \"pollock\")            # Save shape file write_dat(ST6, path = \"C://data//ST6.shp\", type = \"shp\", project = 'Pollock') }"},{"path":"/reference/xy_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot relationship of two variables — xy_plot","title":"Plot relationship of two variables — xy_plot","text":"Evaluate relationship two variables plot format.    Plots first variable second variable. Plot var1 var 2","code":""},{"path":"/reference/xy_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot relationship of two variables — xy_plot","text":"","code":"xy_plot(dat, project, var1, var2, regress = FALSE, alpha = 0.5)"},{"path":"/reference/xy_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot relationship of two variables — xy_plot","text":"dat Primary data containing information hauls trips. Table  FishSET database contains string 'MainDataTable'. project String, name project. var1 First variable dat. var2 Second variable dat. regress Logical, TRUE, returns plot fitted linear regression  line. Defaults FALSE. alpha opaqueness data point scatterplot. 0 total  transparency 1 total opaqueness.  Defaults .5.","code":""},{"path":"/reference/xy_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot relationship of two variables — xy_plot","text":"Returns plot output R console saves plot Output folder.","code":""},{"path":"/reference/xy_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot relationship of two variables — xy_plot","text":"","code":"if (FALSE) { xy_plot(pollockMainDataTable, var1 = 'OFFICIAL_TOTAL_CATCH_MT',         var2 = 'HAUL', regress = TRUE) }"},{"path":"/reference/zone_closure.html","id":null,"dir":"Reference","previous_headings":"","what":"Define zone closure scenarios — zone_closure","title":"Define zone closure scenarios — zone_closure","text":"Define zone closure scenarios","code":""},{"path":"/reference/zone_closure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define zone closure scenarios — zone_closure","text":"","code":"zone_closure(   project,   spatdat,   cat,   lon.spat = NULL,   lat.spat = NULL,   epsg = NULL )"},{"path":"/reference/zone_closure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define zone closure scenarios — zone_closure","text":"project Required, name project. spatdat Required, data file character.  spatdat spatial data file containing information fishery  management regulatory zones boundaries. Shape, json, geojson, csv  formats supported. geojson preferred format. json files must  converted geoson. done automatically file loaded  read_dat .map set true. spatdat  , time, loaded FishSET database. cat Variable spatdat identifies individual areas zones. lon.spat Required csv files. Variable list spatdat  containing longitude data. Leave NULL spatdat shape json file. lat.spat Required csv files. Variable list spatdat  containing latitude data.  Leave NULL spatdat shape json file. epsg EPSG number. Set epsg ensure spatdat correct projections.  epsg specified defined spatdat.    See http://spatialreference.org/ help identify optimal epsg number.","code":""},{"path":"/reference/zone_closure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define zone closure scenarios — zone_closure","text":"Returns yaml file project output folder.","code":""},{"path":"/reference/zone_closure.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define zone closure scenarios — zone_closure","text":"Define zone closure scenarios. Function opens interactive map.    Define zone closures clicking one zones clicking    'Close zones' button. define another closure scenario, unclick zones    click desired zones. Press 'Save closures' button save choices.   saved choices called policy scenario function.","code":""},{"path":"/reference/zone_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize zones, closure areas — zone_summary","title":"Summarize zones, closure areas — zone_summary","text":"`zone_summary` counts observations aggregates values `dat`  regulatory zone closure area.","code":""},{"path":"/reference/zone_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize zones, closure areas — zone_summary","text":"","code":"zone_summary(   dat,   spat,   project,   zone.dat,   zone.spat,   count = TRUE,   var = NULL,   group = NULL,   fun = NULL,   breaks = NULL,   n.breaks = 10,   bin_colors = NULL,   na.rm = TRUE,   dat.center = TRUE,   output = \"plot\" )"},{"path":"/reference/zone_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize zones, closure areas — zone_summary","text":"dat Primary data containing information hauls trips.  Table FishSET database contains string 'MainDataTable'. spat spatial data file containing information fishery management  regulatory zones boundaries. `sf` objects recommended, `sp` objects  can used well. See [dat_to_sf()] convert spatial table read  csv file `sf` object. upload spatial data FishSETFolder  see [load_spatial()]. project Name project. zone.dat Name zone ID column `dat`. zone.spat Name zone ID column `spat`. count Logical. `TRUE`, number observations per zone  returned. Can paired `fun = \"percent\"` `group`. `zone_summary` return error `var` include  `count = TRUE`. var Optional, name numeric variable aggregate zone/closure area. group Name grouping variable aggregate zone/closure area. one variable allowed. fun Function name (string) aggregate . `\"percent\"`  percentage observations given zone. options include \"sum\",  \"mean\", \"median\", \"min\", \"max\". breaks numeric vector breaks bin zone frequencies . Overrides `n.breaks` entered. n.breaks number break points create breaks given  directly. Defaults 10. bin_colors Optional, vector colors use plot. Must length breaks. Defaults `fishset_viridis(10)`. na.rm Logical, whether remove zones zero counts. dat.center Logical, whether plot center `dat`  (`TRUE`) `spat` (`FALSE`). Recommend `dat.center = TRUE` aggregating regulatory zone `dat.center = FALSE` aggregating closure area. output Output `\"plot\"`, `\"table\"`, (`\"tab_plot\"`). Defaults `\"plot\"`.","code":""},{"path":"/reference/zone_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize zones, closure areas — zone_summary","text":"Observations `dat` must assigned regulatory zones   use function. See [assignment_column()] details.   `zone_summary` can return: number observations per zone   (`count = TRUE`, `fun = NULL`, `group = NULL`), percentage  observations zone (`count = TRUE`, `fun = \"percent\"`,   `group = NULL`), percentage observations zone group   (`count = TRUE`, `fun = \"percent\"`, `group = \"group\"`), summary   numeric variable zone (`count = FALSE`, `var = \"var\"`,   `fun = \"sum\"`, `group = NULL`), summary numeric variable  zone group (`count = FALSE`, `var = \"var\"`, `fun = \"sum\"`,   `group = \"group\"`), share (percentage) numeric variable zone  (`count = FALSE`, `var = \"var\"`, `fun = \"percent\"`, `group = NULL`),   share (percentage) numeric variable zone group (`count = FALSE`,   `var = \"var\"`, `fun = \"percent\"`, `group = \"group\"`).","code":""},{"path":"/reference/zone_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize zones, closure areas — zone_summary","text":"","code":"if (FALSE) {  # count # of obs zone_summary(pollockMainTable, spat = nmfs_area, zone.dat = \"ZoneID\",              zone.spat = \"NMFS_AREA\")              # percent of obs zone_summary(pollockMainTable, spat = nmfs_area, zone.dat = \"ZoneID\",              zone.spat = \"NMFS_AREA\", count = TRUE, fun = \"percent\")  # count by group zone_summary(pollockMainTable, spat = nmfs_area, zone.dat = \"ZoneID\",              zone.spat = \"NMFS_AREA\", group = \"GEAR_TYPE\")     # total catch by zone            zone_summary(pollockMainTable, spat = nmfs_area, zone.dat = \"ZoneID\",              zone.spat = \"NMFS_AREA\", var = \"OFFICIAL_TOTAL_CATCH_MT\",             count = FALSE, fun = \"sum\")    # percent of catch by zone            zone_summary(pollockMainTable, spat = nmfs_area, zone.dat = \"ZoneID\",              zone.spat = \"NMFS_AREA\", var = \"OFFICIAL_TOTAL_CATCH_MT\",             count = FALSE, fun = \"percent\")                       }"}]
